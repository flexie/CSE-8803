{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Imaging w/ data-driven models \u2013 CSE 8803 Instructor Felix J. Herrmann Phone: +1 (404) 385-7069 CODA, room S1375B General Information Time and Location Monday/Wednesday 3:00 pm - 4:15 pm, Molecular Sciences rm 1224 Office Hours: by appointment Course Description This course concerns inverse problems as they relate to imaging. After reviewing techniques from Compressive Sensing , Sparse Approximation , and Convex Optimization by means of lectures based on Mathematical Foundations of Data Sciences and computational assignments from Numerical Tours of Data Sciences (in Matlab , Python , Julia , or R ), the course shifts towards the state of the art of \"Imaging w/ data-driven models\" as outlined in the review article Solving inverse problems using data-driven models and the references therein. The reviewed techniques are of interest to areas in Computational Science and Engineering where data is incomplete, noisy and observed indirectly. Required Textbook None required Course Material The lectures will be based on Mathematical Foundations of Data Sciences the book A Wavelet Tour of Signal Processing: The Sparse Way by Stephane Mallat Solving inverse problems using data-driven models a series of research papers on topics pertinent to this course Additional material will be made available under the tab Reading . External Links papers and tutorials from Rice Compressive Sensing Resources the blog Nuit Blanch Course Outline See Outline tab (adapted from Mathematical Foundations of Data Sciences and Solving inverse problems using data-driven models ) Overview: a Sparse Tour of Signal Processing Signal and Image Processing with Orthogonal Decompositions Fourier Processing Wavelet Processing Approximation with Orthogonal Decompositions Linear and Non-linear Denoising Variational Regularization of Inverse Problems Sparse Regularization of Inverse Problems Convex Optimization for Imaging Compressive Sensing Sparse L1 Recovery Statistical Regularization Learning in Functional Analytic Regularization Learning in Statistical Regularization Evaluation Presentation of a journal paper in class (20%) Presentation of your project (10%) Your project (40%) Computational Assignments (30%) These weights are approximate; we reserve the right to change them later. Assignments There will be Computational Assignments, which will mostly involve geophysics-related programs, computer simulations, and data analysis. These assignments is designed for each student to work by him/herself. This homework will count as 35% of your overall course grade. Project You are required to write a term paper on any topic related to geophysics. This can be a literature review of a selected topic, or research project involving calculations, data analysis, or theoretical results done in consultation with the instructor. The topic needed to be approved by the instructor before the midterm. Your paper should be written up in a journal form with length, figures and referencing in a format suitable for submission to journals like Geophysical Research Letters (GRL). Preliminary version of the final paper should be shown to the instructor for approval at least two weeks before the final due date. You will present your term paper in a 15 minute AGU-style talk; a 12 minute presentation with 3 minutes of questions. The project will count as 15% of your overall course grade. Grading for your project will be based on the 12% of the quality of the research and the written paper, and 3% of your presentation. You can find more details on the Projects page. Exams There will be a midterm (25%) and a final exam (25%). Both of them are closed book. Reference to texts or other documents such as previous semester course materials during exams is strictly forbidden. Using these materials will be considered a direct violation of academic policy and will be dealt with according to the GT Academic Honor Code. The use of electronic devices (e.g. cellular phones, computers etc.) other than non-programmable calculators during exams and quizzes is not allowed. Academic Honesty It is expected that all students are aware of their individual responsibilities under the Georgia Tech Academic Honor Code, which will be strictly adhered to in this class. The complete text of the Georgia Tech Academic Honor Code is at http://www.honor.gatech.edu/ .","title":"Imaging w/ data-driven models \u2013 CSE 8803"},{"location":"#imaging-w-data-driven-models-cse-8803","text":"","title":"Imaging w/ data-driven models \u2013 CSE 8803"},{"location":"#instructor","text":"Felix J. Herrmann Phone: +1 (404) 385-7069 CODA, room S1375B","title":"Instructor"},{"location":"#general-information","text":"Time and Location Monday/Wednesday 3:00 pm - 4:15 pm, Molecular Sciences rm 1224 Office Hours: by appointment","title":"General Information"},{"location":"#course-description","text":"This course concerns inverse problems as they relate to imaging. After reviewing techniques from Compressive Sensing , Sparse Approximation , and Convex Optimization by means of lectures based on Mathematical Foundations of Data Sciences and computational assignments from Numerical Tours of Data Sciences (in Matlab , Python , Julia , or R ), the course shifts towards the state of the art of \"Imaging w/ data-driven models\" as outlined in the review article Solving inverse problems using data-driven models and the references therein. The reviewed techniques are of interest to areas in Computational Science and Engineering where data is incomplete, noisy and observed indirectly.","title":"Course Description"},{"location":"#required-textbook","text":"None required","title":"Required Textbook"},{"location":"#course-material","text":"The lectures will be based on Mathematical Foundations of Data Sciences the book A Wavelet Tour of Signal Processing: The Sparse Way by Stephane Mallat Solving inverse problems using data-driven models a series of research papers on topics pertinent to this course Additional material will be made available under the tab Reading .","title":"Course Material"},{"location":"#external-links","text":"papers and tutorials from Rice Compressive Sensing Resources the blog Nuit Blanch","title":"External Links"},{"location":"#course-outline","text":"See Outline tab (adapted from Mathematical Foundations of Data Sciences and Solving inverse problems using data-driven models ) Overview: a Sparse Tour of Signal Processing Signal and Image Processing with Orthogonal Decompositions Fourier Processing Wavelet Processing Approximation with Orthogonal Decompositions Linear and Non-linear Denoising Variational Regularization of Inverse Problems Sparse Regularization of Inverse Problems Convex Optimization for Imaging Compressive Sensing Sparse L1 Recovery Statistical Regularization Learning in Functional Analytic Regularization Learning in Statistical Regularization","title":"Course Outline"},{"location":"#evaluation","text":"Presentation of a journal paper in class (20%) Presentation of your project (10%) Your project (40%) Computational Assignments (30%) These weights are approximate; we reserve the right to change them later.","title":"Evaluation"},{"location":"#assignments","text":"There will be Computational Assignments, which will mostly involve geophysics-related programs, computer simulations, and data analysis. These assignments is designed for each student to work by him/herself. This homework will count as 35% of your overall course grade.","title":"Assignments"},{"location":"#project","text":"You are required to write a term paper on any topic related to geophysics. This can be a literature review of a selected topic, or research project involving calculations, data analysis, or theoretical results done in consultation with the instructor. The topic needed to be approved by the instructor before the midterm. Your paper should be written up in a journal form with length, figures and referencing in a format suitable for submission to journals like Geophysical Research Letters (GRL). Preliminary version of the final paper should be shown to the instructor for approval at least two weeks before the final due date. You will present your term paper in a 15 minute AGU-style talk; a 12 minute presentation with 3 minutes of questions. The project will count as 15% of your overall course grade. Grading for your project will be based on the 12% of the quality of the research and the written paper, and 3% of your presentation. You can find more details on the Projects page.","title":"Project"},{"location":"#exams","text":"There will be a midterm (25%) and a final exam (25%). Both of them are closed book. Reference to texts or other documents such as previous semester course materials during exams is strictly forbidden. Using these materials will be considered a direct violation of academic policy and will be dealt with according to the GT Academic Honor Code. The use of electronic devices (e.g. cellular phones, computers etc.) other than non-programmable calculators during exams and quizzes is not allowed.","title":"Exams"},{"location":"#academic-honesty","text":"It is expected that all students are aware of their individual responsibilities under the Georgia Tech Academic Honor Code, which will be strictly adhered to in this class. The complete text of the Georgia Tech Academic Honor Code is at http://www.honor.gatech.edu/ .","title":"Academic Honesty"},{"location":"goals/","text":"","title":"Goals"},{"location":"homework/","text":"Assignments We will post the different assignments taken from Numerical Tours of Data Sciences here we will offer support for Python . You are free to work on your Assignments (in Matlab , Python , Julia , or R ). Handins Make a script that produces the plots and carefully describes your findings. The code itself is part of the assignment; make sure that it is readable and carefully documented. Generate a pdf file from your script. This will generate a pdf including the plots, your descriptions and code. Make sure that the lay-out is readable. Look for documentation on making up Matlab code for publication. The naming convention for this file is studentnumber_assingmentnumber.pdf. Send the pdf to Zhilong Fang, email: Fang zfang@eos.ubc.ca with subject EOSC513 Lab. For some exercises you will be asked to write separate Matlab functions. In this case include ALL the files in a zip-file named studentnumber_assingmentnumber.zip. ASSINGMENTS THAT DO NOT FOLLOW THE NAMING CONVENTIONS OR ARE SEND AFTER THE POSTED DEADLINE WILL NOT BE GRADED","title":"Assigments"},{"location":"homework/#assignments","text":"We will post the different assignments taken from Numerical Tours of Data Sciences here we will offer support for Python . You are free to work on your Assignments (in Matlab , Python , Julia , or R ).","title":"Assignments"},{"location":"homework/#handins","text":"Make a script that produces the plots and carefully describes your findings. The code itself is part of the assignment; make sure that it is readable and carefully documented. Generate a pdf file from your script. This will generate a pdf including the plots, your descriptions and code. Make sure that the lay-out is readable. Look for documentation on making up Matlab code for publication. The naming convention for this file is studentnumber_assingmentnumber.pdf. Send the pdf to Zhilong Fang, email: Fang zfang@eos.ubc.ca with subject EOSC513 Lab. For some exercises you will be asked to write separate Matlab functions. In this case include ALL the files in a zip-file named studentnumber_assingmentnumber.zip. ASSINGMENTS THAT DO NOT FOLLOW THE NAMING CONVENTIONS OR ARE SEND AFTER THE POSTED DEADLINE WILL NOT BE GRADED","title":"Handins"},{"location":"outline/","text":"Overview: a Sparse Tour of Signal Processing Signal and Image Processing with Orthogonal Decompositions Continuous signals and images Orthogonal representations decomposition energy conservation (Parseval) Fourier and wavelets 2D wavelet transform Linear and nonlinear approximations filtering thresholding compressibility and its relation to smoothness Denoising and inverse problems signal model recovery by sparsity promotion Reading material TBA Slides [Signal and Image Decomposition in Orthogonal Bases] adapted from [here]. Fourier Processing Continuous/discrete Fourier basis Sampling 2D Fourier transform Fourier Approximation Reading material TBA Assignments See assignment tab. Slides [Fourier Processing] adapted from [here]. Wavelet Processing 1D Multiresolutions detail spaces Haar wavelets 1D Wavelet transform computing wavelet coefficients discrete wavelet coefficients fast wavelet transform -inverse transform Filter banks approximation filter detail filter vanishing moments Daubechies wavelets Extension to 2D -anisotropic wavelets 2D multiresolutions 2D wavelet bases 2D discrete wavelet coefficients fast 2D wavelet transform Reading material TBA Assignments See [assignment] tab. Slides [Wavelet Processing] adapted from [here]. Approximation with Orthogonal Decompositions Linear and nonlinear approximations Sparse approximation in a basis hard thresholding decay of approximation errors (linear vs. nonlinear) Relation between decay rate coefficients and approximation error Fourier for smooth functions Fourier and singularities/edges wavelet transform for peice-wise 1D smooth functions vanishing moments magnitude of wavelet coefficients and its relation to edges decay and nonlinear approximation error for piece-wise 1D functions Piece-wise smooth 2D functions 2D approximations -decay and nonlinear approximation error for piece-wise 2D functions Geometrically regular functions space of BV functions finite elements curvelets, their construction, and properties Reading material TBA Assignments See [assignment] tab. Slides [Approximation and Coding with Orthogonal Decompositions] adapted from [here]. Linear and Nonlinear Denoising Linear denoising additative noise model linear denoising by smoothing Wiener filter and oracle estimation of optimal filter Nonlinear denoising hard thresholding optimal threshold selection nonlinear approximation and estimation hard vs. soft thresholding Translational invariant thresholding translation invariant wavelets optimal threshold Other diagonal estimators between hard and soft thresholding Non-diagonal estimators block thresholding Reading material TBA Assignments See [assignment] tab. Slides [Linear and nonlinear denoising] adapted from [here]. Variational Regularization of Inverse Problems Variational priors smooth and cartoon natural image priors discretization Variational regularization regularized inverse pseudo inverse Sobolev regularization and inpainting total variation regularization and inpainting Example from tomography with the Radon transform Reading material TBA Assignments See [assignment] tab. Slides [Inverse problems Regularization] adapted from [here]. Sparse Regularization of Inverse Problems Convex Optimization for Imaging Compressive Sensing Sparse L1 Recovery Statistical Regularization Learning in Functional Analytic Regularization Learning in Statistical Regularization","title":"Outline"},{"location":"outline/#overview-a-sparse-tour-of-signal-processing","text":"","title":"Overview: a Sparse Tour of Signal Processing"},{"location":"outline/#signal-and-image-processing-with-orthogonal-decompositions","text":"Continuous signals and images Orthogonal representations decomposition energy conservation (Parseval) Fourier and wavelets 2D wavelet transform Linear and nonlinear approximations filtering thresholding compressibility and its relation to smoothness Denoising and inverse problems signal model recovery by sparsity promotion","title":"Signal and Image Processing with Orthogonal Decompositions"},{"location":"outline/#reading-material","text":"TBA","title":"Reading material"},{"location":"outline/#slides","text":"[Signal and Image Decomposition in Orthogonal Bases] adapted from [here].","title":"Slides"},{"location":"outline/#fourier-processing","text":"Continuous/discrete Fourier basis Sampling 2D Fourier transform Fourier Approximation","title":"Fourier Processing"},{"location":"outline/#reading-material_1","text":"TBA","title":"Reading material"},{"location":"outline/#assignments","text":"See assignment tab.","title":"Assignments"},{"location":"outline/#slides_1","text":"[Fourier Processing] adapted from [here].","title":"Slides"},{"location":"outline/#wavelet-processing","text":"1D Multiresolutions detail spaces Haar wavelets 1D Wavelet transform computing wavelet coefficients discrete wavelet coefficients fast wavelet transform -inverse transform Filter banks approximation filter detail filter vanishing moments Daubechies wavelets Extension to 2D -anisotropic wavelets 2D multiresolutions 2D wavelet bases 2D discrete wavelet coefficients fast 2D wavelet transform","title":"Wavelet Processing"},{"location":"outline/#reading-material_2","text":"TBA","title":"Reading material"},{"location":"outline/#assignments_1","text":"See [assignment] tab.","title":"Assignments"},{"location":"outline/#slides_2","text":"[Wavelet Processing] adapted from [here].","title":"Slides"},{"location":"outline/#approximation-with-orthogonal-decompositions","text":"Linear and nonlinear approximations Sparse approximation in a basis hard thresholding decay of approximation errors (linear vs. nonlinear) Relation between decay rate coefficients and approximation error Fourier for smooth functions Fourier and singularities/edges wavelet transform for peice-wise 1D smooth functions vanishing moments magnitude of wavelet coefficients and its relation to edges decay and nonlinear approximation error for piece-wise 1D functions Piece-wise smooth 2D functions 2D approximations -decay and nonlinear approximation error for piece-wise 2D functions Geometrically regular functions space of BV functions finite elements curvelets, their construction, and properties","title":"Approximation with Orthogonal Decompositions"},{"location":"outline/#reading-material_3","text":"TBA","title":"Reading material"},{"location":"outline/#assignments_2","text":"See [assignment] tab.","title":"Assignments"},{"location":"outline/#slides_3","text":"[Approximation and Coding with Orthogonal Decompositions] adapted from [here].","title":"Slides"},{"location":"outline/#linear-and-nonlinear-denoising","text":"Linear denoising additative noise model linear denoising by smoothing Wiener filter and oracle estimation of optimal filter Nonlinear denoising hard thresholding optimal threshold selection nonlinear approximation and estimation hard vs. soft thresholding Translational invariant thresholding translation invariant wavelets optimal threshold Other diagonal estimators between hard and soft thresholding Non-diagonal estimators block thresholding","title":"Linear and Nonlinear Denoising"},{"location":"outline/#reading-material_4","text":"TBA","title":"Reading material"},{"location":"outline/#assignments_3","text":"See [assignment] tab.","title":"Assignments"},{"location":"outline/#slides_4","text":"[Linear and nonlinear denoising] adapted from [here].","title":"Slides"},{"location":"outline/#variational-regularization-of-inverse-problems","text":"Variational priors smooth and cartoon natural image priors discretization Variational regularization regularized inverse pseudo inverse Sobolev regularization and inpainting total variation regularization and inpainting Example from tomography with the Radon transform","title":"Variational Regularization of Inverse Problems"},{"location":"outline/#reading-material_5","text":"TBA","title":"Reading material"},{"location":"outline/#assignments_4","text":"See [assignment] tab.","title":"Assignments"},{"location":"outline/#slides_5","text":"[Inverse problems Regularization] adapted from [here].","title":"Slides"},{"location":"outline/#sparse-regularization-of-inverse-problems","text":"","title":"Sparse Regularization of Inverse Problems"},{"location":"outline/#convex-optimization-for-imaging","text":"","title":"Convex Optimization for Imaging"},{"location":"outline/#compressive-sensing","text":"","title":"Compressive Sensing"},{"location":"outline/#sparse-l1-recovery","text":"","title":"Sparse L1 Recovery"},{"location":"outline/#statistical-regularization","text":"","title":"Statistical Regularization"},{"location":"outline/#learning-in-functional-analytic-regularization","text":"","title":"Learning in Functional Analytic Regularization"},{"location":"outline/#learning-in-statistical-regularization","text":"","title":"Learning in Statistical Regularization"},{"location":"project/","text":"Class projects Data and scripts The data required for the project is in the Dropbox folder used for the assignments The projects are wrapped up in a docker image so that all the required dependencies are already installed. You will need to have docker installed. Once done run the following command docker run -p 8888:8888 -v /path/to/files:/app/judi/data philippwitte/judi_eas_project:v1.0 where /path/to/files is the absolute location of the project data on your own machine. Running this command will produce an output that looks like Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://(9d81a99a7494 or 127.0.0.1):8888/?token=7b1629792186c4e469d30eb92e8e9670d4f3bfa96c0c799f Copy paste the URL in your browser and replace (9d81a99a7494 or 127.0.0.1) by localhost . You will then be directed to a jupyter folder that contains the notebooks for the projects. Projects As part of Lab 8, we are asking the students to work on a project in four groups. The projects are on the use of compressive sensing in seismic data acquisition and processing, and we are asking the students to make a comparison between different interpolation and acquisition techniques, namely missing trace interpolation via sparsity promoting techniques missing trace interpolation via rank minimization techniques acquisition with simultaneous randomly amplitude weighted sources or phase encoded sources for 'land\u2019 Details on these different acquisition schemes will be discussed in class and during Lab 8. The goal of the project is to extend the 2D examples on common-receiver gathers to processing of a complete seismic line (for many receivers). This leads to a large problem with an unknown vector for which we need to invert with about 1 billion variables. As you do not have access to necessary resources you will need to solve the problem for each shot record or frequency slice independently and put the results back together afterward. Scientifically, the acquisition and interpolation projects will focus on defining and testing the sampling matrix that models seismic acquisition. Kronecker products will be used to extend the 2D implementations of the sampling operators for common-receiver gathers to seismic lines that can be represented as a 3D volume. Plots have to be made of the sampling artifacts in the source-receiver-time domain and in the midpoint-offset-time domain. Also a study should be made of the size of the artifacts in relation to the degree of subsampling. We also would like to see plots of rows of the sampling matrix. selection of the appropriate sparsifying transform using curvelets and our Kronecker product. We would like to see a plot of a couple of columns of the synthesis matrix. in case of rank minimization techniques, selecting an appropriate rank plays a crucial role. Extract low and high frequency slices from a given seismic line. Look into the decay of singular values in each case and select rank accordingly. recovery of the fully-sampled sequential shot data by sparse inversion or matrix completion using SPGl1. The quality of the recovery should be measured via the signal-to-noise ratio ${SNR}=-20log_{10}(\\frac{|{f}-\\hat{{f}}|_2}{|{f}|_2})$ with f the original data and $\\hat{{f}}$ the recovered data. Plots should also be made of the convergence as a function of the number of iterations. We also would like to see a plot of the residue as a function of the one-norm (sparsity case) or nuclear norm (matrix completion case) of the solution. In case of rank minimization, for a fixed sub-sampling ratio, plot SNR as a function of rank. Each group is asked to give a short seminar on their project in class for 20 minutes with 15 to 17 minutes for the presentation itself and the remaining time for questions. The students are asked to divide the topics of the seminar into two or three parts presented by two or three different students in the team. During the question period each of the students will be asked to answer questions. The seminar will be graded using the following seminar evaluation form. Please refer to the main page of the course for the date of the projection presentation in class. Papers that are relevant for the projects are: Gilles Hennenfent and Felix J. Herrmann. Simply denoise: wavefield reconstruction via jittered undersampling, Geophysics, vol. 73, p. V19-V28, 2008. In the paper, the authors explain how to use jitter sampling to optimize the recovery from random missing shots. Felix J. Herrmann Yogi Erlangga and Tim T. Y. Lin. Compressive simultaneous full-waveform simulation. Geophysics, vol. 74, p. A35, (2009). In this paper, the authors apply compressive sensing to speedup wavefield simulations by using randomly weighted simultaneous sources. Felix J. Herrmann. Randomized sampling and sparsity: getting more information from fewer samples. Geophysics 75, WB173 (2010); doi:10.1190/1.350614. In this paper, the basics of compressive sensing are explained for a geophysics audience followed by discussion of different sampling schemes. You can skip the case studies. Felix J. Herrmann, Michael P. Friedlander, Ozgur Yilmaz. Fighting the curse of dimensionality: compressive sensing in exploration seismology. In this paper, the authors give an overview of the application of compressive sensing to exploration seismology. Haneet Wason and Felix J. Herrmann. Only dither: efficient simultaneous marine acquisition. EAGE expanded abstract. 2012. In this expanded abstract, the authors describe the application of compressive sensing to simultaneous marine acquisition. Haneet Wason, Felix J. Herrmann. Time-jittered ocean bottom seismic acquisition. SEG expanded abstract. 2013. In this abstract, the author describe the application of time-jittered marine acquisition scheme. Aleksandr Y. Aravkin, Rajiv Kumar, Hassan Mansour, Ben Recht, Felix J. Herrmann. A robust SVD-free approach to matrix completion, with applications to interpolation of large scale data. arXiv submission. In this paper, the author explain how to use rank-minimization techniques to recover random missing shots. Rajiv Kumar, Aleksandr Y. Aravkin, Ernie Esser, Hassan Mansour and Felix J. Herrmann. SVD-free low-rank matrix factorization : wavefield reconstruction via jittered subsampling and reciprocity. EAGE expanded abstract. 2014. In this expanded abstract, author explain the use of jittered sampling to optimize rank minimization based missing trace interpolation techniques.","title":"Projects"},{"location":"project/#class-projects","text":"","title":"Class projects"},{"location":"project/#data-and-scripts","text":"The data required for the project is in the Dropbox folder used for the assignments The projects are wrapped up in a docker image so that all the required dependencies are already installed. You will need to have docker installed. Once done run the following command docker run -p 8888:8888 -v /path/to/files:/app/judi/data philippwitte/judi_eas_project:v1.0 where /path/to/files is the absolute location of the project data on your own machine. Running this command will produce an output that looks like Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://(9d81a99a7494 or 127.0.0.1):8888/?token=7b1629792186c4e469d30eb92e8e9670d4f3bfa96c0c799f Copy paste the URL in your browser and replace (9d81a99a7494 or 127.0.0.1) by localhost . You will then be directed to a jupyter folder that contains the notebooks for the projects.","title":"Data and scripts"},{"location":"project/#projects","text":"As part of Lab 8, we are asking the students to work on a project in four groups. The projects are on the use of compressive sensing in seismic data acquisition and processing, and we are asking the students to make a comparison between different interpolation and acquisition techniques, namely missing trace interpolation via sparsity promoting techniques missing trace interpolation via rank minimization techniques acquisition with simultaneous randomly amplitude weighted sources or phase encoded sources for 'land\u2019 Details on these different acquisition schemes will be discussed in class and during Lab 8. The goal of the project is to extend the 2D examples on common-receiver gathers to processing of a complete seismic line (for many receivers). This leads to a large problem with an unknown vector for which we need to invert with about 1 billion variables. As you do not have access to necessary resources you will need to solve the problem for each shot record or frequency slice independently and put the results back together afterward. Scientifically, the acquisition and interpolation projects will focus on defining and testing the sampling matrix that models seismic acquisition. Kronecker products will be used to extend the 2D implementations of the sampling operators for common-receiver gathers to seismic lines that can be represented as a 3D volume. Plots have to be made of the sampling artifacts in the source-receiver-time domain and in the midpoint-offset-time domain. Also a study should be made of the size of the artifacts in relation to the degree of subsampling. We also would like to see plots of rows of the sampling matrix. selection of the appropriate sparsifying transform using curvelets and our Kronecker product. We would like to see a plot of a couple of columns of the synthesis matrix. in case of rank minimization techniques, selecting an appropriate rank plays a crucial role. Extract low and high frequency slices from a given seismic line. Look into the decay of singular values in each case and select rank accordingly. recovery of the fully-sampled sequential shot data by sparse inversion or matrix completion using SPGl1. The quality of the recovery should be measured via the signal-to-noise ratio ${SNR}=-20log_{10}(\\frac{|{f}-\\hat{{f}}|_2}{|{f}|_2})$ with f the original data and $\\hat{{f}}$ the recovered data. Plots should also be made of the convergence as a function of the number of iterations. We also would like to see a plot of the residue as a function of the one-norm (sparsity case) or nuclear norm (matrix completion case) of the solution. In case of rank minimization, for a fixed sub-sampling ratio, plot SNR as a function of rank. Each group is asked to give a short seminar on their project in class for 20 minutes with 15 to 17 minutes for the presentation itself and the remaining time for questions. The students are asked to divide the topics of the seminar into two or three parts presented by two or three different students in the team. During the question period each of the students will be asked to answer questions. The seminar will be graded using the following seminar evaluation form. Please refer to the main page of the course for the date of the projection presentation in class. Papers that are relevant for the projects are: Gilles Hennenfent and Felix J. Herrmann. Simply denoise: wavefield reconstruction via jittered undersampling, Geophysics, vol. 73, p. V19-V28, 2008. In the paper, the authors explain how to use jitter sampling to optimize the recovery from random missing shots. Felix J. Herrmann Yogi Erlangga and Tim T. Y. Lin. Compressive simultaneous full-waveform simulation. Geophysics, vol. 74, p. A35, (2009). In this paper, the authors apply compressive sensing to speedup wavefield simulations by using randomly weighted simultaneous sources. Felix J. Herrmann. Randomized sampling and sparsity: getting more information from fewer samples. Geophysics 75, WB173 (2010); doi:10.1190/1.350614. In this paper, the basics of compressive sensing are explained for a geophysics audience followed by discussion of different sampling schemes. You can skip the case studies. Felix J. Herrmann, Michael P. Friedlander, Ozgur Yilmaz. Fighting the curse of dimensionality: compressive sensing in exploration seismology. In this paper, the authors give an overview of the application of compressive sensing to exploration seismology. Haneet Wason and Felix J. Herrmann. Only dither: efficient simultaneous marine acquisition. EAGE expanded abstract. 2012. In this expanded abstract, the authors describe the application of compressive sensing to simultaneous marine acquisition. Haneet Wason, Felix J. Herrmann. Time-jittered ocean bottom seismic acquisition. SEG expanded abstract. 2013. In this abstract, the author describe the application of time-jittered marine acquisition scheme. Aleksandr Y. Aravkin, Rajiv Kumar, Hassan Mansour, Ben Recht, Felix J. Herrmann. A robust SVD-free approach to matrix completion, with applications to interpolation of large scale data. arXiv submission. In this paper, the author explain how to use rank-minimization techniques to recover random missing shots. Rajiv Kumar, Aleksandr Y. Aravkin, Ernie Esser, Hassan Mansour and Felix J. Herrmann. SVD-free low-rank matrix factorization : wavefield reconstruction via jittered subsampling and reciprocity. EAGE expanded abstract. 2014. In this expanded abstract, author explain the use of jittered sampling to optimize rank minimization based missing trace interpolation techniques.","title":"Projects"},{"location":"reading/","text":"General introduction Reading material John Scales: Theory of Seismic Imaging Chapters 1, 2, 10.3 Guy Drijkoningen: Seismic Data Processing - TG001 / TA3600 Chapters 1,2,3, 4.6, 4.7. and Introduction to Reflection Seismology TA3520 Chapter 5. Yilmaz's \u201cbible\u201d Material presented in class Slides for Lecture 1: Introduction Slides for Lecture 2: Basic Seismic Data Processing 1 Slides for Lecture 3: Basic seismic data processing 2 Slides for Lecture 4: Basic seismic data processing 3 Slides for Lecture 5: Basic seismic data processing 4 Slides for Lecture 6: Basic seismic data processing 5 Slides for Lecture 7: Basic seismic data processing 6 Slides for Lecture 8: Basic seismic data processing 7 Slides for Lecture 7: Basic seismic data processing 6 Slides for Lecture 8: Basic seismic data processing 7 Slides for Lecture 9: Basic seismic data processing 8 Slides for Lecture 10: Basic seismic data processing 9 Slides for Lecture 11: Basic seismic data processing 10 Seismic data acquisition Material presented in class Slides for Lecture 12: Practical aspects of seismic acquisition Slides for Lecture 13: Practical aspects of seismic acquisition From processing to inversion Reading material Jon Claerbout: IMAGE ESTIMATION BY EXAMPLE: Geophysical Soundings Image Construction Chapter 1. John A. Scales, Martin L. Smith and Sven Treitel Introductory Geophysical Inverse Theory Chapter 4 Richard Baraniuk: More Is Less: Signal Processing and the Data Deluge Felix J. Herrmann, Michael P.Friedlander, Ozgur Yilmaz: Fighting the curse of dimensionality: compressive sensing in exploration seismology Felix J. Herrmann: Randomized sampling and sparsity: getting more information from fewer samples . Geophysics 75, WB173 (2010); doi:10.1190/1.350614 Material presented in class Slides for Lecture 14: From Processing to Inversion Slides for Lecture 15: From Processing to Inversion-Radon Compressive sensing Reading material IEEE Signal Processing Magazine Richard Baraniuk: Compressive sensing and More Is Less: Signal Processing and the Data Deluge Emmanuel Candes and Michael Wakin: An introduction to Compressive Sensing Justin Romberg: Imaging via compressive sampling Felix J. Herrmann: Randomized sampling and sparsity: getting more information from fewer samples. Geophysics 75, WB173 (2010); doi:10.1190/1.350614 Felix J. Herrmann, Michael P. Friedlander, Ozgur Yilmaz: Fighting the curse of dimensionality: compressive sensing in exploration seismology Material presented in class Slides for Lecture 16: Basics Compressive Sensing Slides for Lecture 17: Theory Compressive Sensing Slides for Lecture 18: Theory Compressive Sensing - Design Principles Sensing Slides for Lecture 19: Compressive Sensing - Latest Linearized inversion Reading material A. Gisolf. On the shortcomings of linear AVP( AVO/AVA) inversion. Material presented in class Slides for Lecture 20: Linearized inversion of amplitude-versus-offset data RTM & FWI Reading material Gerhard Pratt: Gauss-Newton and full Newton methods in frequency domain seismic waveform inversion. Geophysical Journal International, 133, 341-362. Andreas Fichtner: Full Seismic Waveform Modelling and Inversion chapter 10 and 11 Material presented in class Full-waveform inversion Review Slides for Lecture 21: Review Migration, Velocity Analyses, and AVO","title":"Reading"},{"location":"reading/#general-introduction","text":"","title":"General introduction"},{"location":"reading/#reading-material","text":"John Scales: Theory of Seismic Imaging Chapters 1, 2, 10.3 Guy Drijkoningen: Seismic Data Processing - TG001 / TA3600 Chapters 1,2,3, 4.6, 4.7. and Introduction to Reflection Seismology TA3520 Chapter 5. Yilmaz's \u201cbible\u201d","title":"Reading material"},{"location":"reading/#material-presented-in-class","text":"Slides for Lecture 1: Introduction Slides for Lecture 2: Basic Seismic Data Processing 1 Slides for Lecture 3: Basic seismic data processing 2 Slides for Lecture 4: Basic seismic data processing 3 Slides for Lecture 5: Basic seismic data processing 4 Slides for Lecture 6: Basic seismic data processing 5 Slides for Lecture 7: Basic seismic data processing 6 Slides for Lecture 8: Basic seismic data processing 7 Slides for Lecture 7: Basic seismic data processing 6 Slides for Lecture 8: Basic seismic data processing 7 Slides for Lecture 9: Basic seismic data processing 8 Slides for Lecture 10: Basic seismic data processing 9 Slides for Lecture 11: Basic seismic data processing 10","title":"Material presented in class"},{"location":"reading/#seismic-data-acquisition","text":"","title":"Seismic data acquisition"},{"location":"reading/#material-presented-in-class_1","text":"Slides for Lecture 12: Practical aspects of seismic acquisition Slides for Lecture 13: Practical aspects of seismic acquisition","title":"Material presented in class"},{"location":"reading/#from-processing-to-inversion","text":"","title":"From processing to inversion"},{"location":"reading/#reading-material_1","text":"Jon Claerbout: IMAGE ESTIMATION BY EXAMPLE: Geophysical Soundings Image Construction Chapter 1. John A. Scales, Martin L. Smith and Sven Treitel Introductory Geophysical Inverse Theory Chapter 4 Richard Baraniuk: More Is Less: Signal Processing and the Data Deluge Felix J. Herrmann, Michael P.Friedlander, Ozgur Yilmaz: Fighting the curse of dimensionality: compressive sensing in exploration seismology Felix J. Herrmann: Randomized sampling and sparsity: getting more information from fewer samples . Geophysics 75, WB173 (2010); doi:10.1190/1.350614","title":"Reading material"},{"location":"reading/#material-presented-in-class_2","text":"Slides for Lecture 14: From Processing to Inversion Slides for Lecture 15: From Processing to Inversion-Radon","title":"Material presented in class"},{"location":"reading/#compressive-sensing","text":"","title":"Compressive sensing"},{"location":"reading/#reading-material_2","text":"IEEE Signal Processing Magazine Richard Baraniuk: Compressive sensing and More Is Less: Signal Processing and the Data Deluge Emmanuel Candes and Michael Wakin: An introduction to Compressive Sensing Justin Romberg: Imaging via compressive sampling Felix J. Herrmann: Randomized sampling and sparsity: getting more information from fewer samples. Geophysics 75, WB173 (2010); doi:10.1190/1.350614 Felix J. Herrmann, Michael P. Friedlander, Ozgur Yilmaz: Fighting the curse of dimensionality: compressive sensing in exploration seismology","title":"Reading material"},{"location":"reading/#material-presented-in-class_3","text":"Slides for Lecture 16: Basics Compressive Sensing Slides for Lecture 17: Theory Compressive Sensing Slides for Lecture 18: Theory Compressive Sensing - Design Principles Sensing Slides for Lecture 19: Compressive Sensing - Latest","title":"Material presented in class"},{"location":"reading/#linearized-inversion","text":"","title":"Linearized inversion"},{"location":"reading/#reading-material_3","text":"A. Gisolf. On the shortcomings of linear AVP( AVO/AVA) inversion.","title":"Reading material"},{"location":"reading/#material-presented-in-class_4","text":"Slides for Lecture 20: Linearized inversion of amplitude-versus-offset data","title":"Material presented in class"},{"location":"reading/#rtm-fwi","text":"","title":"RTM &amp; FWI"},{"location":"reading/#reading-material_4","text":"Gerhard Pratt: Gauss-Newton and full Newton methods in frequency domain seismic waveform inversion. Geophysical Journal International, 133, 341-362. Andreas Fichtner: Full Seismic Waveform Modelling and Inversion chapter 10 and 11","title":"Reading material"},{"location":"reading/#material-presented-in-class_5","text":"Full-waveform inversion","title":"Material presented in class"},{"location":"reading/#review","text":"Slides for Lecture 21: Review Migration, Velocity Analyses, and AVO","title":"Review"},{"location":"Assignments/Exercise1/","text":"Exercise 1: a first look at seismic data In this exercise we will load some data into Julia and perform some basic operations. Seismic data are typically stored in a special binary format: SEGY. These file-formats store the data as mutliple time-series (traces) with the corresponding header information containing specific information about such as time sampling and source/receiver locations. The Julia utilities for reading SEGY data is SeisIO using SeisIO, PyPlot Scaning the dataset Thhe first step is to scan the dataset to extract header/metadat. This metadat contains the geometry and parameters of the survey such as the source/receiver locations and time sampling rate. The convention for the metadata is as follows: - The Source positions use the Source keyword such as SourceX - The receiver position use the Group keyword such as GroupX # scan the dataset dir = Pkg.dir(\"SeisIO\") data_dir = \"/src/data\" \"/src/data\" We ca nnow scans the dataset with the segy_scan functin. This function returns a SeisCOn object where each block is a shot record with its metadata. blocks = segy_scan(string(dir, data_dir), \"overthrust\", [\"GroupX\", \"GroupY\", \"ns\", \"dt\"]); Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_41_60.segy Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_21_40.segy Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_61_80.segy Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_1_20.segy Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_81_97.segy Now extract the time, source and receiver coordinates (in seconds and meters) for all the traces. The source and receiver vectors have a length equal to the number of traces, the time vector has a length equal to the number of rows in the data matrix. sx = [get_header(blocks[i], \"SourceX\") for i=1:length(blocks)]; rx = [get_header(blocks[i], \"GroupX\") for i=1:length(blocks)]; # Get the tme axis. In this case the time axis is the same for all traces so we only need to extract it from the first trace # dt needs to be corrected for the binary setup # All the times are in ms dt = get_header(blocks[1], \"dt\")[1]/1000 nt = get_header(blocks[1], \"ns\")[1] T = 0:dt:(nt-1)*dt 0.0:4.0:3000.0 Calculate the offset and midpoint for each trace. This gives you vectors m (midpoint) and h (offset) with length equal to the number of traces. h = (s - r)/2; m = (s + r)/2; h = (sx .- rx)./2; m = (sx .+ rx)./2; The fold of the data is the number of traces in each midpoint gather. This can be easily visualized by a histogram. As we have a set of blocks we need to inspect each block seperately to recover the nuique set of midpoint location and the total number fo traces for this midpoint all_m = hcat(m'...) fold = [sum(all_m .== unique(all_m)[i]) for i=1:length(unique(all_m))]; all_h = hcat(h'...); figure(); bar(unique(all_m),fold ,align=\"center\", width=100); xlabel(\"midpoint [m]\"); ylabel(\"fold\"); title(\"fold\"); Can you interpret this figure? Different gathers Extract a midpoint gather. For example, a midpoint gather at m = 2550 looks like this: Im = find(all_m .== 7500.) figure() imshow(Float32.(blocks[1:97].data[:, Im]), vmin=-1, vmax=1, cmap=\"Greys\", aspect=.05) PyObject <matplotlib.image.AxesImage object at 0x7f947ac9a550> Extract an offset-gather. For example, a zero-offset section looks like: # We need to sort it in physical units as the dataset may not be Ih = find(all_h .== 0.) inds = sortperm(all_m[Ih]') figure() imshow(Float32.(blocks[1:97].data[:, Ih[inds]]), vmin=-1, vmax=1, cmap=\"Greys\", aspect=.1) PyObject <matplotlib.image.AxesImage object at 0x7f947ab7f048> What other different gathers can you think of? Extract and plot an example of all the different gathers. What are characteristic properties of the different gathers? Do not forget to label the axis and choose a reasonable colorscale. Hint: use cmap=Greys and adjust the color-axis vmin/vmax","title":"Exercise 1: a first look at seismic data"},{"location":"Assignments/Exercise1/#exercise-1-a-first-look-at-seismic-data","text":"In this exercise we will load some data into Julia and perform some basic operations. Seismic data are typically stored in a special binary format: SEGY. These file-formats store the data as mutliple time-series (traces) with the corresponding header information containing specific information about such as time sampling and source/receiver locations. The Julia utilities for reading SEGY data is SeisIO using SeisIO, PyPlot","title":"Exercise 1: a first look at seismic data"},{"location":"Assignments/Exercise1/#scaning-the-dataset","text":"Thhe first step is to scan the dataset to extract header/metadat. This metadat contains the geometry and parameters of the survey such as the source/receiver locations and time sampling rate. The convention for the metadata is as follows: - The Source positions use the Source keyword such as SourceX - The receiver position use the Group keyword such as GroupX # scan the dataset dir = Pkg.dir(\"SeisIO\") data_dir = \"/src/data\" \"/src/data\" We ca nnow scans the dataset with the segy_scan functin. This function returns a SeisCOn object where each block is a shot record with its metadata. blocks = segy_scan(string(dir, data_dir), \"overthrust\", [\"GroupX\", \"GroupY\", \"ns\", \"dt\"]); Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_41_60.segy Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_21_40.segy Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_61_80.segy Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_1_20.segy Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_81_97.segy Now extract the time, source and receiver coordinates (in seconds and meters) for all the traces. The source and receiver vectors have a length equal to the number of traces, the time vector has a length equal to the number of rows in the data matrix. sx = [get_header(blocks[i], \"SourceX\") for i=1:length(blocks)]; rx = [get_header(blocks[i], \"GroupX\") for i=1:length(blocks)]; # Get the tme axis. In this case the time axis is the same for all traces so we only need to extract it from the first trace # dt needs to be corrected for the binary setup # All the times are in ms dt = get_header(blocks[1], \"dt\")[1]/1000 nt = get_header(blocks[1], \"ns\")[1] T = 0:dt:(nt-1)*dt 0.0:4.0:3000.0 Calculate the offset and midpoint for each trace. This gives you vectors m (midpoint) and h (offset) with length equal to the number of traces. h = (s - r)/2; m = (s + r)/2; h = (sx .- rx)./2; m = (sx .+ rx)./2; The fold of the data is the number of traces in each midpoint gather. This can be easily visualized by a histogram. As we have a set of blocks we need to inspect each block seperately to recover the nuique set of midpoint location and the total number fo traces for this midpoint all_m = hcat(m'...) fold = [sum(all_m .== unique(all_m)[i]) for i=1:length(unique(all_m))]; all_h = hcat(h'...); figure(); bar(unique(all_m),fold ,align=\"center\", width=100); xlabel(\"midpoint [m]\"); ylabel(\"fold\"); title(\"fold\"); Can you interpret this figure? Different gathers Extract a midpoint gather. For example, a midpoint gather at m = 2550 looks like this: Im = find(all_m .== 7500.) figure() imshow(Float32.(blocks[1:97].data[:, Im]), vmin=-1, vmax=1, cmap=\"Greys\", aspect=.05) PyObject <matplotlib.image.AxesImage object at 0x7f947ac9a550> Extract an offset-gather. For example, a zero-offset section looks like: # We need to sort it in physical units as the dataset may not be Ih = find(all_h .== 0.) inds = sortperm(all_m[Ih]') figure() imshow(Float32.(blocks[1:97].data[:, Ih[inds]]), vmin=-1, vmax=1, cmap=\"Greys\", aspect=.1) PyObject <matplotlib.image.AxesImage object at 0x7f947ab7f048> What other different gathers can you think of? Extract and plot an example of all the different gathers. What are characteristic properties of the different gathers? Do not forget to label the axis and choose a reasonable colorscale. Hint: use cmap=Greys and adjust the color-axis vmin/vmax","title":"Scaning the dataset"},{"location":"Assignments/Exercise2/","text":"NMO correction The traveltime as a function of offset of a reflected event can be approximated by the NMO traveltime: $ \\tau(t_0,h) = \\sqrt{t_0 + h^2/v^2} $ where $(t_0)$ is the zero-offset or vertical traveltime and $v$ is the effective or NMO velocity. We can now correct the data for the moveout via a simple coordinate transform: $ d_{NMO}(t_0,h) = d(\\tau(t_0,h),h) $ You can use the function nmo implemented below for this exercise. using Dierckx function nmo(cmp, t, off, v) # NMO correction and adjoint # # use: # out = nmo(in,t,h,v,flag) # # input: # in - data matrix of size [length(t) x length(h)], each column is a trace # t - time vector [s] # offsets - offset vector [m] # v - NMO velocity [m/s] as vector of size [length(t) x 1]. # flag - 1:forward, -1:adjoint # # output # out - data matrix of size [length(t) x length(h)], each column is a trace # size of data nt, nh = size(cmp) # make sure t and v are column vectors t = t[:] v = v[:] # initialize output out = zeros(nt, nh) # loop over offset for i = 1:nh # NMO traveltime tau = sqrt.(t.^2 + off[i].^2./v.^2); # interpolate, forward or adjoint spl = Spline1D(t, cmp[1e-3*T.-t.<1e-5, i]) out[:,i] = spl(tau) end return out end nmo (generic function with 1 method) using SeisIO, PyPlot # read the dataset blocks = segy_read(\"/data/mlouboutin3/Class_data/cube2.segy\"); sx = get_header(blocks, \"SourceX\";scale=false) rx = get_header(blocks, \"GroupX\";scale=false); # Get the time axis. In this case the time axis is the same for all traces so we only need to extract it from the first trace # dt needs to be corrected for the binary setup # All the times are in ms dt = get_header(blocks, \"dt\")[1]/1000 nt = get_header(blocks, \"ns\")[1] T = 0:dt:(nt-1)*dt 0.0:4.0:2000.0 # Midpoint and offset h = (sx .- rx); m = (sx .+ rx)./2; all_m = hcat(m'...)' fold = [sum(all_m .== unique(all_m)[i]) for i=1:length(unique(all_m))]; all_h = hcat(h'...)'; Pick a midpoint Im = find(all_m .== all_m[1000]) offsets = sort((all_h[Im])); inds = sortperm(all_h[Im]) cmp = Float32.(blocks.data[:, Im[inds]]); figure() imshow(cmp, vmin=-1, vmax=1, cmap=\"Greys\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time') Constant velocity NMO correction nmo_corrected1 = nmo(cmp, 1e-3.*T, offsets, 2000. + 0.*T); figure() imshow(nmo_corrected1, vmin=-1, vmax=1, cmap=\"Greys\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time') Windowing We can see a lot of `artifacts' in the NMO corrected gather above. To avoid some of the artifacts, the midpoint gathers are often windowed to select reflected data only. All events that arrive before the direct wave are removed. A typical window looks like this (Hint: the slope of the triangle is related to the veloctity of the direct wave). # grid tt = [1e-3*ti for ti in T for h in offsets] hh = [h for ti in T for h in offsets] # initialize window to zero and set times later than first arrival to 1. W=0.*tt;W[tt.>(.1+ abs.(hh)./1500)] = 1 W = reshape(W, size(cmp)[2], size(cmp)[1]) imshow(W', vmin=0, vmax=1, cmap=\"jet\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time') muted = W'.*cmp; figure() imshow(muted, vmin=-1e0, vmax=1e0, cmap=\"Greys\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time') Stack power To figure out which NMO velocity optimally flattens all the events, we can scan through a range of constant NMO velocities and see which events are flattened for which velocity. One way to judge flatness of an event is via the stackpower. The stackpower is just a sum along the offset direction of the values-squared of the NMO-corrected gather: $ S(t_0,v) = \\int!!\\mathrm{d}h\\, d(\\tau(t_0,h,v),h)^2 $ The function $ S(t_0,v) $ is called a semblance panel. The desired NMO velocity can be found by picking the maximum as a function of $t_0$ and $v$ from the semblance panel. An example of a semblance panel and the resulting NMO velocity is shown below. v = linspace(1000, 3000, 500) # scan over velocities S = zeros(length(T),length(v)); for k = 1:length(v) cmp_nmo = nmo(muted, 1e-3.*T, offsets, v[k] .+ 0.*T); S[:,k] = sum(cmp_nmo.^2,2); end #Plot semblance panel figure() imshow(S, vmin=0, vmax=1e3, cmap=\"jet\", aspect=1, extent=[v[1], v[end], T[end], 0]) xlabel(\"velocity\") ylabel(\"tau\") PyObject Text(24,0.5,'tau') # pick v/tau pairs tv = 1e3*[0, 0.30, 0.35, 0.46, 0.65, 1.27, 2.00]; vnmo = [1500, 1500, 1600, 1700, 2000, 2179, 3000]; spl = Spline1D(tv, vnmo; k=1) vnmo_all = spl(T); Look at the velocity profile with the picked tau/v pairs # Enable gui to have the cursor and pick v/tau pairs figure() imshow(S, vmin=0, vmax=1e3, cmap=\"jet\", aspect=1, extent=[v[1], v[end], T[end], 0]) plot(vnmo_all, T, \"-k\") xlabel(\"velocity\") ylabel(\"tau\") PyObject Text(24,0.5,'tau') nmo_corrected = nmo(muted, 1e-3.*T, offsets, vnmo_all) ; figure() imshow(nmo_corrected, vmin=-1e0, vmax=1e0, cmap=\"Greys\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time') Velocity analysis Repeat the above outline procedure for a couple of mipdoint positions xm (e.g., xm = [500 1000 2000] ). Organize the resulting NMO velocities in a matrix Vm (where column i is the NMO velocity for midpoint xm[i] ) interpolate the results to obtain a velocity for all the midpoints using Spline1D(xm, VM); spl(all_m) . Plot the velocity and discuss. Using this NMO velocity, we can produce an NMO stack. Perform an NMO correction of all the midpoint gathers using the corresponding NMO velocity derived above and sum each along the offset direction. Organize all the stacks in a matrix and plot the result. Also make a stack using a constant NMO velocity. Discuss the results.","title":"NMO correction"},{"location":"Assignments/Exercise2/#nmo-correction","text":"The traveltime as a function of offset of a reflected event can be approximated by the NMO traveltime: $ \\tau(t_0,h) = \\sqrt{t_0 + h^2/v^2} $ where $(t_0)$ is the zero-offset or vertical traveltime and $v$ is the effective or NMO velocity. We can now correct the data for the moveout via a simple coordinate transform: $ d_{NMO}(t_0,h) = d(\\tau(t_0,h),h) $ You can use the function nmo implemented below for this exercise. using Dierckx function nmo(cmp, t, off, v) # NMO correction and adjoint # # use: # out = nmo(in,t,h,v,flag) # # input: # in - data matrix of size [length(t) x length(h)], each column is a trace # t - time vector [s] # offsets - offset vector [m] # v - NMO velocity [m/s] as vector of size [length(t) x 1]. # flag - 1:forward, -1:adjoint # # output # out - data matrix of size [length(t) x length(h)], each column is a trace # size of data nt, nh = size(cmp) # make sure t and v are column vectors t = t[:] v = v[:] # initialize output out = zeros(nt, nh) # loop over offset for i = 1:nh # NMO traveltime tau = sqrt.(t.^2 + off[i].^2./v.^2); # interpolate, forward or adjoint spl = Spline1D(t, cmp[1e-3*T.-t.<1e-5, i]) out[:,i] = spl(tau) end return out end nmo (generic function with 1 method) using SeisIO, PyPlot # read the dataset blocks = segy_read(\"/data/mlouboutin3/Class_data/cube2.segy\"); sx = get_header(blocks, \"SourceX\";scale=false) rx = get_header(blocks, \"GroupX\";scale=false); # Get the time axis. In this case the time axis is the same for all traces so we only need to extract it from the first trace # dt needs to be corrected for the binary setup # All the times are in ms dt = get_header(blocks, \"dt\")[1]/1000 nt = get_header(blocks, \"ns\")[1] T = 0:dt:(nt-1)*dt 0.0:4.0:2000.0 # Midpoint and offset h = (sx .- rx); m = (sx .+ rx)./2; all_m = hcat(m'...)' fold = [sum(all_m .== unique(all_m)[i]) for i=1:length(unique(all_m))]; all_h = hcat(h'...)';","title":"NMO correction"},{"location":"Assignments/Exercise2/#pick-a-midpoint","text":"Im = find(all_m .== all_m[1000]) offsets = sort((all_h[Im])); inds = sortperm(all_h[Im]) cmp = Float32.(blocks.data[:, Im[inds]]); figure() imshow(cmp, vmin=-1, vmax=1, cmap=\"Greys\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time')","title":"Pick a midpoint"},{"location":"Assignments/Exercise2/#constant-velocity-nmo-correction","text":"nmo_corrected1 = nmo(cmp, 1e-3.*T, offsets, 2000. + 0.*T); figure() imshow(nmo_corrected1, vmin=-1, vmax=1, cmap=\"Greys\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time')","title":"Constant velocity NMO correction"},{"location":"Assignments/Exercise2/#windowing","text":"We can see a lot of `artifacts' in the NMO corrected gather above. To avoid some of the artifacts, the midpoint gathers are often windowed to select reflected data only. All events that arrive before the direct wave are removed. A typical window looks like this (Hint: the slope of the triangle is related to the veloctity of the direct wave). # grid tt = [1e-3*ti for ti in T for h in offsets] hh = [h for ti in T for h in offsets] # initialize window to zero and set times later than first arrival to 1. W=0.*tt;W[tt.>(.1+ abs.(hh)./1500)] = 1 W = reshape(W, size(cmp)[2], size(cmp)[1]) imshow(W', vmin=0, vmax=1, cmap=\"jet\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time') muted = W'.*cmp; figure() imshow(muted, vmin=-1e0, vmax=1e0, cmap=\"Greys\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time')","title":"Windowing"},{"location":"Assignments/Exercise2/#stack-power","text":"To figure out which NMO velocity optimally flattens all the events, we can scan through a range of constant NMO velocities and see which events are flattened for which velocity. One way to judge flatness of an event is via the stackpower. The stackpower is just a sum along the offset direction of the values-squared of the NMO-corrected gather: $ S(t_0,v) = \\int!!\\mathrm{d}h\\, d(\\tau(t_0,h,v),h)^2 $ The function $ S(t_0,v) $ is called a semblance panel. The desired NMO velocity can be found by picking the maximum as a function of $t_0$ and $v$ from the semblance panel. An example of a semblance panel and the resulting NMO velocity is shown below. v = linspace(1000, 3000, 500) # scan over velocities S = zeros(length(T),length(v)); for k = 1:length(v) cmp_nmo = nmo(muted, 1e-3.*T, offsets, v[k] .+ 0.*T); S[:,k] = sum(cmp_nmo.^2,2); end #Plot semblance panel figure() imshow(S, vmin=0, vmax=1e3, cmap=\"jet\", aspect=1, extent=[v[1], v[end], T[end], 0]) xlabel(\"velocity\") ylabel(\"tau\") PyObject Text(24,0.5,'tau') # pick v/tau pairs tv = 1e3*[0, 0.30, 0.35, 0.46, 0.65, 1.27, 2.00]; vnmo = [1500, 1500, 1600, 1700, 2000, 2179, 3000]; spl = Spline1D(tv, vnmo; k=1) vnmo_all = spl(T);","title":"Stack power"},{"location":"Assignments/Exercise2/#look-at-the-velocity-profile-with-the-picked-tauv-pairs","text":"# Enable gui to have the cursor and pick v/tau pairs figure() imshow(S, vmin=0, vmax=1e3, cmap=\"jet\", aspect=1, extent=[v[1], v[end], T[end], 0]) plot(vnmo_all, T, \"-k\") xlabel(\"velocity\") ylabel(\"tau\") PyObject Text(24,0.5,'tau') nmo_corrected = nmo(muted, 1e-3.*T, offsets, vnmo_all) ; figure() imshow(nmo_corrected, vmin=-1e0, vmax=1e0, cmap=\"Greys\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time')","title":"Look at the velocity profile with the picked tau/v pairs"},{"location":"Assignments/Exercise2/#velocity-analysis","text":"Repeat the above outline procedure for a couple of mipdoint positions xm (e.g., xm = [500 1000 2000] ). Organize the resulting NMO velocities in a matrix Vm (where column i is the NMO velocity for midpoint xm[i] ) interpolate the results to obtain a velocity for all the midpoints using Spline1D(xm, VM); spl(all_m) . Plot the velocity and discuss. Using this NMO velocity, we can produce an NMO stack. Perform an NMO correction of all the midpoint gathers using the corresponding NMO velocity derived above and sum each along the offset direction. Organize all the stacks in a matrix and plot the result. Also make a stack using a constant NMO velocity. Discuss the results.","title":"Velocity analysis"},{"location":"Assignments/Exercise3/","text":"Exercise 3: wavefield extrapolation and migration Contents: - Wavefield extrapolation - Zero-offset migration - Prestack migration - Wavefield extrapolation For a constant-velocity medium, we can extrapolate a wavefield at depth $z$ to depth $z+\\Delta z$ via a simple phase shift in the $f-k$ domain: $ u(\\omega,k,z + \\Delta z) = u(\\omega,k,z)\\exp[\\imath\\Delta z\\sqrt(\\omega^2/v^2 - k^2)]$ To illustrate this, we generate a source wavefield in the $t-x$ domain and extrapolate it. First, let's define an impulsive source. using PyPlot f-k domain transform function fktran function fktran(a,t,x,mode) \"\"\" f-k transform for real-values input. use: b, f, k = fktran(a,t,x,mode) input: a - matrix in t-x domain (nt x nx) t - time vector x - x vector mode - 1:forward, -1:inverse \"\"\" nt = length(t) nx = length(x) dt = t[2]-t[1] dx = x[2] - x[1] xmax = x[end] - x[1] tmax = t[end] - t[1] f = 0:1/tmax:.5/dt k = -.5/dx:1/xmax:.5/dx nf = length(f) if mode == 1 b = fft(a, 1) b = b[1:nf, :] b = ifft(b, 2) b = circshift(b,[0 ceil(Int, nx/2)-1]); elseif mode == -1 b = circshift(a,[0 floor(Int, nx/2)+1]); b = fft(b, 2) b = ifft(b, 1) b = real(b) else error(\"unknown mode\") end return b, f, k end fktran (generic function with 1 method) # time coordinate in seconds as column vector t = 0:.004:1; # spatial coordinate in meters as row vector x = 0:10:1000; # generate 2D grid: tt = [ti for ti in t, xi in x]; xx = [xi for ti in t, xi in x]; # Source wavefield is impulsive source at t=0.1 and x=500, source = (tt-.1).*exp.(-1e-3*(xx.-500).^2 .- 1e3*(tt-.1).^2); # plot it imshow(source, cmap=\"Greys\", extent=[x[1], x[end], t[end], t[1]], aspect=500) xlabel(\"x [m]\") ylabel(\"t [s]\") title(\"wavefield at z=0 m.\") PyObject Text(0.5,1,'wavefield at z=0 m.') # now, transform it to the f-k domain using fktran source_fk, f, k = fktran(source,t,x,1); Next, we define the extrapolation factor and plot it. # generate a grid for f,k ff = [fi for fi in f, ki in k] kk = [ki for fi in f, ki in k] # the extrapolation factor for a velocity v is defined as follows # (note the factor \\(2 pi\\) to go from frequency to wavenumber) v = 2000 dz = 10 kz = 2*pi*sqrt.(complex.((ff./v).^2 - kk.^2)) W = exp.(dz*im.*kz) # now plot absolute value for 10 Hz plot(k,abs.(W[ff.==10])) xlabel(\"k [1/m]\");ylabel(\"|W|\");title(\"|W| @ 10 Hz.\"); The region where the extrapolation factor is smaller than one is called the evanescent region. Waves this these wavenumbers will be damped. We have to be carefull with the sign of (k_z) in the exponentional factor and make sure that the absolute value is always smaller than one. The wavefield at z = 500 m looks like # fix sign of kz kz = -real(kz)+im*abs.(imag(kz)); W = exp.(500*im.*kz); # extrapolate and transform back to t-x source_extrap, _, _ = fktran(W.*source_fk,t,x,-1); #plot imshow(real(source_extrap), cmap=\"Greys\", vmin=-.1e-2, vmax=.1e-2, extent=[x[1], x[end], t[end], t[1]], aspect=700) xlabel(\"x [m]\") ylabel(\"t [s]\") title(\"wavefield at z=500 m.\") PyObject Text(0.5,1,'wavefield at z=500 m.') Questions What happens if the imaginary part of kz has the wrong sign? try it. same for the real part. What does the extrapolator look like in the t-x domain? How can you extraplotate the wavefield in the t-x domain directly using the extrapolator in the t-x domain? Zero-offset migration In this part of the exercise we look at zero-offset migration. This type of migration is based on the \"exploding-reflector\" concept. Zero-offset migration can be done by exptrapolating the zero-offset data with half-velocity and taking the image to be slice of the wavefield at $t=0$ for each depth step: $I(z,x) = u(z,x,t=0)$ The function wave_extrap.m takes in a wavefield u and the correspoding time/space vectors t,x, a velocity v, a depth step dz and a propagation direction dir and extrapolates the input wavefield. Load the zero-offset data data1_zero.segy (in Dropbox) and define the source, receiver and time coordinates. The units of the source and receiver coordinates are in meters for this file. The data looks like this using SeisIO # Dowload and adapt path shot = segy_read(\"data_zo.segy\") shot_data = Float32.(shot.data) sx = get_header(shot, \"SourceX\", scale=false) dt = get_header(shot, \"dt\")[1]/1e6 nt = get_header(shot, \"ns\")[1] T = 0:dt:(nt -1)*dt \u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mFixed length trace flag set in stream: IOBuffer(data=UInt8[...], readable=true, writable=false, seekable=true, append=false, size=253644, maxsize=Inf, ptr=3601, mark=-1)\u001b[39m 0.0:0.004:1.0 imshow(shot_data, vmin=-.1, vmax=.1, cmap=\"Greys\", extent=[sx[1], sx[end], T[end], T[1]], aspect=1000) xlabel(\"source position [m]\") ylabel(\"t [s]\") PyObject Text(24,0.5,'t [s]') Use the function wave_extrap to migrate the zero offset section. A reasonable depth axis is z = 0:5:1000. Use the source position as lateral position x. The correct velocity is v0 = 2000 km/s (but, remember this is zero-offset migration so adapt the velocity accordingly!). A zero-offset migration can done as follows: function wave_extrap(u,t,x,v,dz,dir) # wavefield extrapolation by phase shift # # use: # v = wave_extrap(u,t,x,v,dz,dir) # # input: # u - wavefield as matrix of size length(t) x length(x) # t - time coordinates in seconds as column vector # x - space coordinates in meters as row vector # v - velocity in m/s (scalar) # dz - depth step in meters # dir - 1: forward in time, -1 backward in time # # output: # v - extrapolated wavefield # # fk transform of the wavefield spec, f, k = fktran(u, t, x, 1) # define grid and kz ff = [fi for fi in f, ki in k] kk = [ki for fi in f, ki in k] kz = 2*pi*sqrt.(complex((ff/v).^2-kk.^2)) # set sign of real part of kz kz = -sign.(dir)*real(kz)+im*abs.(imag(kz)) # apply phase shift spec = exp.(im*abs.(dz).*kz).*spec # inverse fk transform v, _, _ = fktran(spec, f, k, -1) # take real part of wavefield v = real(v) return v end wave_extrap (generic function with 1 method) # depth axis z = 0:5:1000 dz = 5 # velocity v = 2000 # migrate for correct velocity migcorr = zeros(length(z),length(sx)) for k = 1:length(z) tmp = wave_extrap(shot_data, T, sx, v./2, z[k], -1) migcorr[k, :] = tmp[1, :] end # plot it imshow(migcorr, cmap=\"Greys\", vmin=-.1, vmax=.1, extent=[sx[1], sx[end], z[end], z[1]], aspect=1) xlabel(\"x [m]\") ylabel(\"z [m]\") title(\"correct velocity\") PyObject Text(0.5,1,'correct velocity') Questions Compare the migrated result to the zero-offset section. What do you notice? For easier comparison, you might want to transform the time axis into depth using the correct velocity. Do a zero-offset migration for too low and too high velocities. What do you notice? Repeat the same exercise for data2_zo.su. What do you notice here? Prestack migration We can also create an image by extrapolating the source wavefields and the data and correlating them at different depth levels. Read the data data_ex3.segy (in Dropbox) block = segy_read(\"data_ex3.segy\") sx = get_header(block, \"SourceX\", scale=false) rx = get_header(block, \"GroupX\", scale=false) dt = get_header(block, \"dt\")[1]/1e6 nt = get_header(block, \"ns\")[1] T = 0:dt:(nt -1)*dt # unique src/rec locations xs = unique(sx) xr = unique(rx); \u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mFixed length trace flag set in stream: IOBuffer(data=UInt8[...], readable=true, writable=false, seekable=true, append=false, size=1385684, maxsize=Inf, ptr=3601, mark=-1)\u001b[39m We extrapolate both source and receiver wavefields for one shot using wave_extrap (see comments in wave_extrap for documenation) and plot them side-by-side: # velocity v = 2000; # t-x grid tt = [ti for ti in T, xi in xr]; xx = [xi for ti in T, xi in xr]; # choose shot 6 is = 6 # source wavefield at z=0 source = (tt-.1).*exp.(-1e-3*(xx-xs[is]).^2 - 1e3*(tt-.1).^2); # receiver wavefield is data for corresponding shot receiver = Float32.(block.data[:, sx.==xs[is]]); imshow(wave_extrap(source,t,xr,v,500,1), cmap=\"Greys\", vmin=-.001, vmax=.001, extent=[xr[1], xr[end], T[end], T[1]], aspect=500) xlabel(\"x [m]\") ylabel(\"t [s]\") title(\"source wavefield at z=500 m.\") figure() imshow(wave_extrap(receiver,t,xr,v,500,-1), cmap=\"Greys\", vmin=-1, vmax=1, extent=[xr[1], xr[end], T[end], T[1]], aspect=500) xlabel(\"x [m]\") ylabel(\"t [s]\") title(\"receiver wavefield at z=500 m.\") PyObject Text(0.5,1,'receiver wavefield at z=500 m.') Question Extrapolate both source and receiver wavefields to differents depths. What do you notice? An image of the reflector can be constructed by correlating the two wavefields at zero time-lag (basically summing over time) # velocity v = 2e3 # depth dz = 10 z = 0:dz:1000 # initialize image image = zeros(length(z),length(xr)) # loop for iz = 1:length(z) shoti = wave_extrap(source, T, xr, v, z[iz], 1) reci = wave_extrap(receiver, T, xr, v, z[iz], -1) image[iz,:] = sum(shoti.*reci, 1) end figure() imshow(image, cmap=\"Greys\", vmin=-1e-2, vmax=1e-2, extent=[xr[1], xr[end], z[end], z[1]], aspect=1) xlabel(\"x [m]\") ylabel(\"z [m]\") title(\"image for one source\") PyObject Text(0.5,1,'image for one source') Questions Use the template mig_extrap below and implement migration of multiple shots based on the above outlined algorithm by filling in the gaps. You can call wave_extrap as subroutine. Use mig_extrap.m for the following exercises. Migrate a single shot for velocities that are too low and too high (say 10 percent). What do you see? Repeat this for all sources and sum the images for all sources, again also for too low/high velocity. What do you see? Describe how you would adapt the migration algorithm for a velocity that varies with depth. function mig_extrap(data, t, xr, xs, z, v) # # shot-receiver migration for constant velocity by wavefield extrapolation. # # use: # image = mig_extrap(data,t,xr,xs,v) # # input: # data - data cube of size length(t) x length(xr) x length(xs) # t - time coordinate in seconds as column vector # xr - receiver coordinate in meters as row vector # xs - source coordinate in meters as row vector # z - depth coordinate in meters as column vector # v - velocity in m/s (scalar) # # output: # image - image as matrix of size length(z) x length(xr) # initialize image image = zeros(length(z),length(xr)); # depth step dz = z[2] - z[1] # t-x grid tt = [ti for ti in t, xi in xr] xx = [xi for ti in t, xi in xr] # loop over shots for is = 1:length(xs) # construct impulsive source at source location source = (tt-.1).*exp.(-1e-3*(xx-xs[is]).^2 - 1e3*(tt-.1).^2); # select data beloning to source is receiver = # loop over depth levels for iz = 1:length(z) # use wave_extrap to advance both wavefields one depthlevel srci = reci = # update image image[iz,:] = image[iz,:] + end # end loop over depth levels end # end loop over shots return image end","title":"Exercise 3: wavefield extrapolation and migration"},{"location":"Assignments/Exercise3/#exercise-3-wavefield-extrapolation-and-migration","text":"Contents: - Wavefield extrapolation - Zero-offset migration - Prestack migration - Wavefield extrapolation For a constant-velocity medium, we can extrapolate a wavefield at depth $z$ to depth $z+\\Delta z$ via a simple phase shift in the $f-k$ domain: $ u(\\omega,k,z + \\Delta z) = u(\\omega,k,z)\\exp[\\imath\\Delta z\\sqrt(\\omega^2/v^2 - k^2)]$ To illustrate this, we generate a source wavefield in the $t-x$ domain and extrapolate it. First, let's define an impulsive source. using PyPlot","title":"Exercise 3: wavefield extrapolation and migration"},{"location":"Assignments/Exercise3/#f-k-domain-transform-function-fktran","text":"function fktran(a,t,x,mode) \"\"\" f-k transform for real-values input. use: b, f, k = fktran(a,t,x,mode) input: a - matrix in t-x domain (nt x nx) t - time vector x - x vector mode - 1:forward, -1:inverse \"\"\" nt = length(t) nx = length(x) dt = t[2]-t[1] dx = x[2] - x[1] xmax = x[end] - x[1] tmax = t[end] - t[1] f = 0:1/tmax:.5/dt k = -.5/dx:1/xmax:.5/dx nf = length(f) if mode == 1 b = fft(a, 1) b = b[1:nf, :] b = ifft(b, 2) b = circshift(b,[0 ceil(Int, nx/2)-1]); elseif mode == -1 b = circshift(a,[0 floor(Int, nx/2)+1]); b = fft(b, 2) b = ifft(b, 1) b = real(b) else error(\"unknown mode\") end return b, f, k end fktran (generic function with 1 method) # time coordinate in seconds as column vector t = 0:.004:1; # spatial coordinate in meters as row vector x = 0:10:1000; # generate 2D grid: tt = [ti for ti in t, xi in x]; xx = [xi for ti in t, xi in x]; # Source wavefield is impulsive source at t=0.1 and x=500, source = (tt-.1).*exp.(-1e-3*(xx.-500).^2 .- 1e3*(tt-.1).^2); # plot it imshow(source, cmap=\"Greys\", extent=[x[1], x[end], t[end], t[1]], aspect=500) xlabel(\"x [m]\") ylabel(\"t [s]\") title(\"wavefield at z=0 m.\") PyObject Text(0.5,1,'wavefield at z=0 m.') # now, transform it to the f-k domain using fktran source_fk, f, k = fktran(source,t,x,1); Next, we define the extrapolation factor and plot it. # generate a grid for f,k ff = [fi for fi in f, ki in k] kk = [ki for fi in f, ki in k] # the extrapolation factor for a velocity v is defined as follows # (note the factor \\(2 pi\\) to go from frequency to wavenumber) v = 2000 dz = 10 kz = 2*pi*sqrt.(complex.((ff./v).^2 - kk.^2)) W = exp.(dz*im.*kz) # now plot absolute value for 10 Hz plot(k,abs.(W[ff.==10])) xlabel(\"k [1/m]\");ylabel(\"|W|\");title(\"|W| @ 10 Hz.\"); The region where the extrapolation factor is smaller than one is called the evanescent region. Waves this these wavenumbers will be damped. We have to be carefull with the sign of (k_z) in the exponentional factor and make sure that the absolute value is always smaller than one. The wavefield at z = 500 m looks like # fix sign of kz kz = -real(kz)+im*abs.(imag(kz)); W = exp.(500*im.*kz); # extrapolate and transform back to t-x source_extrap, _, _ = fktran(W.*source_fk,t,x,-1); #plot imshow(real(source_extrap), cmap=\"Greys\", vmin=-.1e-2, vmax=.1e-2, extent=[x[1], x[end], t[end], t[1]], aspect=700) xlabel(\"x [m]\") ylabel(\"t [s]\") title(\"wavefield at z=500 m.\") PyObject Text(0.5,1,'wavefield at z=500 m.')","title":"f-k domain transform function fktran"},{"location":"Assignments/Exercise3/#questions","text":"What happens if the imaginary part of kz has the wrong sign? try it. same for the real part. What does the extrapolator look like in the t-x domain? How can you extraplotate the wavefield in the t-x domain directly using the extrapolator in the t-x domain?","title":"Questions"},{"location":"Assignments/Exercise3/#zero-offset-migration","text":"In this part of the exercise we look at zero-offset migration. This type of migration is based on the \"exploding-reflector\" concept. Zero-offset migration can be done by exptrapolating the zero-offset data with half-velocity and taking the image to be slice of the wavefield at $t=0$ for each depth step: $I(z,x) = u(z,x,t=0)$ The function wave_extrap.m takes in a wavefield u and the correspoding time/space vectors t,x, a velocity v, a depth step dz and a propagation direction dir and extrapolates the input wavefield. Load the zero-offset data data1_zero.segy (in Dropbox) and define the source, receiver and time coordinates. The units of the source and receiver coordinates are in meters for this file. The data looks like this using SeisIO # Dowload and adapt path shot = segy_read(\"data_zo.segy\") shot_data = Float32.(shot.data) sx = get_header(shot, \"SourceX\", scale=false) dt = get_header(shot, \"dt\")[1]/1e6 nt = get_header(shot, \"ns\")[1] T = 0:dt:(nt -1)*dt \u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mFixed length trace flag set in stream: IOBuffer(data=UInt8[...], readable=true, writable=false, seekable=true, append=false, size=253644, maxsize=Inf, ptr=3601, mark=-1)\u001b[39m 0.0:0.004:1.0 imshow(shot_data, vmin=-.1, vmax=.1, cmap=\"Greys\", extent=[sx[1], sx[end], T[end], T[1]], aspect=1000) xlabel(\"source position [m]\") ylabel(\"t [s]\") PyObject Text(24,0.5,'t [s]') Use the function wave_extrap to migrate the zero offset section. A reasonable depth axis is z = 0:5:1000. Use the source position as lateral position x. The correct velocity is v0 = 2000 km/s (but, remember this is zero-offset migration so adapt the velocity accordingly!). A zero-offset migration can done as follows: function wave_extrap(u,t,x,v,dz,dir) # wavefield extrapolation by phase shift # # use: # v = wave_extrap(u,t,x,v,dz,dir) # # input: # u - wavefield as matrix of size length(t) x length(x) # t - time coordinates in seconds as column vector # x - space coordinates in meters as row vector # v - velocity in m/s (scalar) # dz - depth step in meters # dir - 1: forward in time, -1 backward in time # # output: # v - extrapolated wavefield # # fk transform of the wavefield spec, f, k = fktran(u, t, x, 1) # define grid and kz ff = [fi for fi in f, ki in k] kk = [ki for fi in f, ki in k] kz = 2*pi*sqrt.(complex((ff/v).^2-kk.^2)) # set sign of real part of kz kz = -sign.(dir)*real(kz)+im*abs.(imag(kz)) # apply phase shift spec = exp.(im*abs.(dz).*kz).*spec # inverse fk transform v, _, _ = fktran(spec, f, k, -1) # take real part of wavefield v = real(v) return v end wave_extrap (generic function with 1 method) # depth axis z = 0:5:1000 dz = 5 # velocity v = 2000 # migrate for correct velocity migcorr = zeros(length(z),length(sx)) for k = 1:length(z) tmp = wave_extrap(shot_data, T, sx, v./2, z[k], -1) migcorr[k, :] = tmp[1, :] end # plot it imshow(migcorr, cmap=\"Greys\", vmin=-.1, vmax=.1, extent=[sx[1], sx[end], z[end], z[1]], aspect=1) xlabel(\"x [m]\") ylabel(\"z [m]\") title(\"correct velocity\") PyObject Text(0.5,1,'correct velocity')","title":"Zero-offset migration"},{"location":"Assignments/Exercise3/#questions_1","text":"Compare the migrated result to the zero-offset section. What do you notice? For easier comparison, you might want to transform the time axis into depth using the correct velocity. Do a zero-offset migration for too low and too high velocities. What do you notice? Repeat the same exercise for data2_zo.su. What do you notice here?","title":"Questions"},{"location":"Assignments/Exercise3/#prestack-migration","text":"We can also create an image by extrapolating the source wavefields and the data and correlating them at different depth levels. Read the data data_ex3.segy (in Dropbox) block = segy_read(\"data_ex3.segy\") sx = get_header(block, \"SourceX\", scale=false) rx = get_header(block, \"GroupX\", scale=false) dt = get_header(block, \"dt\")[1]/1e6 nt = get_header(block, \"ns\")[1] T = 0:dt:(nt -1)*dt # unique src/rec locations xs = unique(sx) xr = unique(rx); \u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mFixed length trace flag set in stream: IOBuffer(data=UInt8[...], readable=true, writable=false, seekable=true, append=false, size=1385684, maxsize=Inf, ptr=3601, mark=-1)\u001b[39m We extrapolate both source and receiver wavefields for one shot using wave_extrap (see comments in wave_extrap for documenation) and plot them side-by-side: # velocity v = 2000; # t-x grid tt = [ti for ti in T, xi in xr]; xx = [xi for ti in T, xi in xr]; # choose shot 6 is = 6 # source wavefield at z=0 source = (tt-.1).*exp.(-1e-3*(xx-xs[is]).^2 - 1e3*(tt-.1).^2); # receiver wavefield is data for corresponding shot receiver = Float32.(block.data[:, sx.==xs[is]]); imshow(wave_extrap(source,t,xr,v,500,1), cmap=\"Greys\", vmin=-.001, vmax=.001, extent=[xr[1], xr[end], T[end], T[1]], aspect=500) xlabel(\"x [m]\") ylabel(\"t [s]\") title(\"source wavefield at z=500 m.\") figure() imshow(wave_extrap(receiver,t,xr,v,500,-1), cmap=\"Greys\", vmin=-1, vmax=1, extent=[xr[1], xr[end], T[end], T[1]], aspect=500) xlabel(\"x [m]\") ylabel(\"t [s]\") title(\"receiver wavefield at z=500 m.\") PyObject Text(0.5,1,'receiver wavefield at z=500 m.')","title":"Prestack migration"},{"location":"Assignments/Exercise3/#question","text":"Extrapolate both source and receiver wavefields to differents depths. What do you notice? An image of the reflector can be constructed by correlating the two wavefields at zero time-lag (basically summing over time) # velocity v = 2e3 # depth dz = 10 z = 0:dz:1000 # initialize image image = zeros(length(z),length(xr)) # loop for iz = 1:length(z) shoti = wave_extrap(source, T, xr, v, z[iz], 1) reci = wave_extrap(receiver, T, xr, v, z[iz], -1) image[iz,:] = sum(shoti.*reci, 1) end figure() imshow(image, cmap=\"Greys\", vmin=-1e-2, vmax=1e-2, extent=[xr[1], xr[end], z[end], z[1]], aspect=1) xlabel(\"x [m]\") ylabel(\"z [m]\") title(\"image for one source\") PyObject Text(0.5,1,'image for one source')","title":"Question"},{"location":"Assignments/Exercise3/#questions_2","text":"Use the template mig_extrap below and implement migration of multiple shots based on the above outlined algorithm by filling in the gaps. You can call wave_extrap as subroutine. Use mig_extrap.m for the following exercises. Migrate a single shot for velocities that are too low and too high (say 10 percent). What do you see? Repeat this for all sources and sum the images for all sources, again also for too low/high velocity. What do you see? Describe how you would adapt the migration algorithm for a velocity that varies with depth. function mig_extrap(data, t, xr, xs, z, v) # # shot-receiver migration for constant velocity by wavefield extrapolation. # # use: # image = mig_extrap(data,t,xr,xs,v) # # input: # data - data cube of size length(t) x length(xr) x length(xs) # t - time coordinate in seconds as column vector # xr - receiver coordinate in meters as row vector # xs - source coordinate in meters as row vector # z - depth coordinate in meters as column vector # v - velocity in m/s (scalar) # # output: # image - image as matrix of size length(z) x length(xr) # initialize image image = zeros(length(z),length(xr)); # depth step dz = z[2] - z[1] # t-x grid tt = [ti for ti in t, xi in xr] xx = [xi for ti in t, xi in xr] # loop over shots for is = 1:length(xs) # construct impulsive source at source location source = (tt-.1).*exp.(-1e-3*(xx-xs[is]).^2 - 1e3*(tt-.1).^2); # select data beloning to source is receiver = # loop over depth levels for iz = 1:length(z) # use wave_extrap to advance both wavefields one depthlevel srci = reci = # update image image[iz,:] = image[iz,:] + end # end loop over depth levels end # end loop over shots return image end","title":"Questions"},{"location":"Assignments/Exercise4/","text":"Exercise 4: Fourier and Radon filtering In this exercise we will look at seismic data in different domains and investigate how we can exploit behaviour of different kinds of noise in these domains to design filters. Contents: - Data - Temporal Fourier transform - f-k filtering - Radon transform - Parabolic Radon transform using PyPlot, SeisIO Data We use a single midpoint gather of the data used in the previous exercises: shot.segy (no big endian this time). # Dowload and adapt path shot = segy_read(\"./data_segy/shot.segy\") shot_data = Float32.(shot.data) h = get_header(shot, \"SourceX\", scale=false) - get_header(shot, \"GroupX\", scale=false) dt = get_header(shot, \"dt\")[1]/1e6 nt = get_header(shot, \"ns\")[1] T = 0:dt:(nt -1)*dt BinaryFileHeader: Job: 1 Line: 1 Reel: 1 DataTracePerEnsemble: 1 AuxiliaryTracePerEnsemble: 0 dt: 4000 dtOrig: 0 ns: 1001 nsOrig: 0 DataSampleFormat: 1 EnsembleFold: 0 TraceSorting: 0 VerticalSumCode: 0 SweepFrequencyStart: 0 SweepFrequencyEnd: 0 SweepLength: 0 SweepType: 0 SweepChannel: 0 SweepTaperlengthStart: 0 SweepTaperLengthEnd: 0 TaperType: 0 CorrelatedDataTraces: 0 BinaryGain: 0 AmplitudeRecoveryMethod: 0 MeasurementSystem: 0 ImpulseSignalPolarity: 0 VibratoryPolarityCode: 0 SegyFormatRevisionNumber: 0 FixedLengthTraceFlag: 0 NumberOfExtTextualHeaders: 0 1705444 3600 1001 \u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mFixed length trace flag set in stream: IOBuffer(data=UInt8[...], readable=true, writable=false, seekable=true, append=false, size=1705444, maxsize=Inf, ptr=3601, mark=-1)\u001b[39m 0.0:0.004:4.0 imshow(shot_data, vmin=-1, vmax=1, cmap=\"Greys\", extent=[h[end], h[1], T[end], T[1]], aspect=1000) xlabel(\"offset [m]\");ylabel(\"time [s]\"); Temporal Fourier transform We can use fftrl to perform a Fourier transform along the temporal direction. The power spectrum (i.e., the absolute value of the transformed data) looks like function fftrl(a, t, mode) # fft for real-valued vectors # # Tristan van Leeuwen, 2012 # tleeuwen@eos.ubc.ca # # use: # [b,f] = fftrl(a,t,mode) # # input: # a - input data # t - time vector # mode: 1: forward, -1:inverse # # output: # b - vector nt = length(t) dt = t[2] - t[1] nf = Int(floor(nt/2)) + 1 tmax = t[end] - t[1] f = 0:1/tmax:.5/dt if mode == 1 b = fft(a,1) b = b[1:nf,:] elseif mode == -1 a = [a;conj(a[Int(ceil(nt/2)):-1:2,:])] b = ifft(a, 1) b = real(b) else error(\"Unknown mode\") end return b, f end fftrl (generic function with 1 method) Data_fh, f = fftrl(shot_data, T, 1) (Complex{Float32}[0.684434+0.0im 0.971781+0.0im \u2026 0.0969428+0.0im 0.00433278+0.0im; -0.701183-0.451787im -0.412326-0.460599im \u2026 -1.3078-0.497307im -1.40236-0.48802im; \u2026 ; -0.121274+0.000705719im -0.0863834-0.000402451im \u2026 0.157795-0.00114059im 0.110151-0.000276089im; -0.122033+0.000601768im -0.0849152-0.000236511im \u2026 0.159012-0.000580788im 0.109696-0.000192404im], 0.0:0.25:125.0) imshow(abs.(Data_fh), cmap=\"jet\", extent=[h[end], h[1], f[end], f[1]], aspect=20) xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') f-k filtering A Fourier transform along both time and offset direction is often referred to as an transform. We can use fktran. The powerspectrum looks like function fktran(a,t,x,mode) \"\"\" f-k transform for real-values input. use: b, f, k = fktran(a,t,x,mode) input: a - matrix in t-x domain (nt x nx) t - time vector x - x vector mode - 1:forward, -1:inverse \"\"\" nt = length(t) nx = length(x) dt = t[2]-t[1] dx = x[2] - x[1] xmax = x[end] - x[1] tmax = t[end] - t[1] f = 0:1/tmax:.5/dt k = -.5/dx:1/xmax:.5/dx nf = length(f) if mode == 1 b = fft(a, 1) b = b[1:nf, :] b = ifft(b, 2) b = circshift(b,[0 ceil(Int, nx/2)-1]); elseif mode == -1 b = circshift(a,[0 floor(Int, nx/2)+1]); b = fft(b, 2) b = ifft(b, 1) b = real(b) else error(\"unknown mode\") end return b, f, k end fktran (generic function with 1 method) Data_fk, fk, kx = fktran(shot_data, T, h, 1) (Complex{Float32}[0.00217381+0.375868im -0.00371527-0.375896im \u2026 -0.00371557+0.375898im 0.00217354-0.375864im; -0.0666401+0.378171im 0.0651375-0.378642im \u2026 -0.072564+0.377115im 0.0710575-0.377542im; \u2026 ; 0.00330043+0.400901im -0.00697034-0.400875im \u2026 -0.0029994+0.40092im -0.000692182-0.400906im; 0.00196619+0.400894im -0.00564895-0.400912im \u2026 -0.00433144+0.400905im 0.000641863-0.400899im], 0.0:0.25:125.0, 0.05:-0.00025:-0.05) imshow(abs.(Data_fk), cmap=\"jet\", extent=[kx[end], kx[1], f[end], f[1]], aspect=.001) xlabel(\"wavenumber [1/m\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') Questions: Subsample the data in the offset direction and look at the Fourier transform. (Hint: use Data[:,1:n:end] and h[1:n:end] where n is the number of times you want to subsample). What do you see? Why is it important to have a good receiver sampling? A filter is simply a multiplicative factor applied in some transform domain, typically (f-h) or (f-k), followed by an inverse transform. For example, a band-pass filter in the (f-h) domain filters out higher temporal frequencies by setting them to zero. A simple band-pass filter looks like this: F_hp = ones(length(f),length(h)) F_hp[(f.<5) .| (f.>20.),:] = 0 imshow(F_hp, extent=[h[end], h[1], f[end], f[1]], aspect=20) colorbar() xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') The filtered data looks like this imshow(fftrl(F_hp.*Data_fh, f, -1)[1], cmap=\"Greys\", vmin=-1, vmax=1, extent=[h[end], h[1], T[end], T[1]], aspect=1000) xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') Do you see the artifacts? A way to reduce these artifacts is to smooth the filter. We can do this by convolving the filter with a triangular smoothing kernel. This is implemented in the function smooth_2D. The result looks like this: # Pkg.add(\"Images\") of you do not alread yhave it using Images function smooth_2D(input, n1, n2) t1 = [1:n1; n1-1:-1:1]/n1^2 t2 = [1:n2; n2-1:-1:1]/n2^2 kernel = t1 * t2' return imfilter(input, centered(kernel)) end smooth_2D (generic function with 1 method) F_hp_smooth = smooth_2D(F_hp, 5, 1) imshow(F_hp_smooth, extent=[h[end], h[1], f[end], f[1]], aspect=20) colorbar() xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') imshow(fftrl(F_hp_smooth.*Data_fh, f, -1)[1], cmap=\"Greys\", vmin=-1, vmax=1, extent=[h[end], h[1], T[end], T[1]], aspect=1000) xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') A (smoothed) filter in the (f-k) domain may look like this ff = [fi for fi in f, kxi in kx] kkx = [kxi for fi in f, kxi in kx] F_kx = zeros(length(fk),length(kx)) F_kx[(ff -1e3 * abs.(kkx) .> 5) .& (ff.<60)] = 1 F_kx = smooth_2D(F_kx, 5, 5) imshow(F_kx, cmap=\"jet\", extent=[kx[end], kx[1], f[end], f[1]], aspect=.001) xlabel(\"wavenumber [1/m\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') Questions Describe how you would design filters to clean up shot gathers shot_noise1 and shot_noise2. (hint: look the f-k transform and compare to the orinigal data) Try it and compare the result with the original shot gather. Radon transform The Radon tranform performs sums along lines with different intercepts $\\tau$) and slopes $p$. Hence, it is sometimes refered to as the $\\tau-p$ transform in geophysics. $\\hat{d}(\\tau,p) = \\int\\mathrm{d}h\\, d(t + ph, h)$ The transform is implemented in the function lpradon. To get an idea of what this transform does, we consider the simple example in lines.segy. function lpradon(input, t, h, q, power, mode) # linear and parabolic Radon transform and its adjoint. # # Tristan van Leeuwen, 2012 # tleeuwen@eos.ubc.ca # # use: # out = lpradon(input,t,h,q,power,mode) # # input: # input - input matrix of size (length(t) x length(h)) for forward, (length(t) x length(q)) for adjoint) # t - time vector in seconds # h - offset vecror in meters # q - radon parameter # power - 1: linear radon, 2: parabolic radon # mode - 1: forward, -1: adjoint # # output: println(size(L)) # output matrix of size (length(t) x length(q)) for forward, (length(t) x length(h)) for adjoint) # # dt = t[2] - t[1] nt = length(t) nh = length(h) nq = length(q) nfft = 2*(nextpow2(nt)) input_padded = zeros(nfft, size(input)[2]) input_padded[1:size(input)[1], :] = input[:, :] if mode == 1 input_padded = fft(input_padded, 1) out = zeros(Complex{Float64}, nfft, nq) for k = 2:Int(floor(nfft/2)) f = 2.*pi*(k-1)/nfft/dt L = exp.(im*f*(h.^power)*q') tmp = input_padded[k,:].'*L out[k,:] = tmp out[nfft + 2 - k, :] = conj(tmp) end out = real(ifft(out, 1)) out = out[1:nt, :] else input_padded = fft(input_padded,1) out = zeros(Complex{Float64}, nfft, nh) for k = 2:Int(floor(nfft/2)) f = 2.*pi*(k-1)/nfft/dt L = exp.(im*f*(h.^power)*q') tmp = input_padded[k,:].'*L' out[k,:] = tmp out[nfft+2-k,:] = conj(tmp) end out = real(ifft(out,1)) out = out[1:nt, :] end return out end lpradon (generic function with 1 method) # Dowload and adapt path shot_radon = segy_read(\"./data_segy/lines.segy\") A = Float32.(shot_radon.data) h = get_header(shot_radon, \"SourceX\", scale=false) - get_header(shot, \"GroupX\", scale=false) dt = get_header(shot_radon, \"dt\")[1]/1e6 nt = get_header(shot_radon, \"ns\")[1] T = 0:dt:(nt -1)*dt BinaryFileHeader: Job: 1 Line: 1 Reel: 1 DataTracePerEnsemble: 1 AuxiliaryTracePerEnsemble: 0 dt: 4000 dtOrig: 0 ns: 1001 nsOrig: 0 DataSampleFormat: 1 EnsembleFold: 0 TraceSorting: 0 VerticalSumCode: 0 SweepFrequencyStart: 0 SweepFrequencyEnd: 0 SweepLength: 0 SweepType: 0 SweepChannel: 0 SweepTaperlengthStart: 0 SweepTaperLengthEnd: 0 TaperType: 0 CorrelatedDataTraces: 0 BinaryGain: 0 AmplitudeRecoveryMethod: 0 MeasurementSystem: 0 ImpulseSignalPolarity: 0 VibratoryPolarityCode: 0 SegyFormatRevisionNumber: 0 FixedLengthTraceFlag: 0 NumberOfExtTextualHeaders: 0 1705444 3600 1001 \u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mFixed length trace flag set in stream: IOBuffer(data=UInt8[...], readable=true, writable=false, seekable=true, append=false, size=1705444, maxsize=Inf, ptr=3601, mark=-1)\u001b[39m 0.0:0.004:4.0 imshow(A, vmin=-.1, vmax=.1, cmap=\"Greys\", extent=[h[end], h[1], T[end], T[1]], aspect=1000) xlabel(\"offset [m]\");ylabel(\"time [s]\"); # which p-values p = 1e-3.*(-3:.05:3) # transform A_tp = lpradon(A, T, h, p, 1, 1) 1001\u00d7121 Array{Float64,2}: 0.000378078 0.000384182 0.000384585 \u2026 0.000202505 0.000644788 0.000376368 0.000389721 0.00037549 0.000144312 0.000541559 0.000387413 0.000381872 0.000383162 0.000133913 0.000409034 0.000390602 0.000388732 0.000380008 0.000201181 0.000262995 0.00040214 0.000383436 0.000392553 0.000302437 0.000157082 0.00040122 0.000393219 0.000391394 \u2026 0.000439509 0.000100834 0.000405988 0.000390277 0.000402393 0.000551232 0.000125599 0.000398302 0.000401124 0.000397027 0.000636942 0.000208975 0.00039937 0.000397851 0.000403059 0.000648591 0.000347769 0.00039261 0.000407363 0.000394245 0.000611003 0.000491774 0.00039947 0.000402683 0.000400071 \u2026 0.000507467 0.000622865 0.000401411 0.000411663 0.000394785 0.00039216 0.000693264 0.000417296 0.000408056 0.000406892 0.000268286 0.000703196 \u22ee \u22f1 \u22ee 0.000378107 0.000381697 -0.000934809 0.000386704 0.000286472 0.000374914 0.000389452 -0.000570546 \u2026 0.000391708 5.61129e-5 0.000389898 0.000381116 -0.000301544 0.000381055 -9.33017e-5 0.000387139 0.000386579 -9.14174e-5 0.000384115 -0.000125689 0.00039709 0.000377236 4.99588e-5 0.000373351 -3.12507e-5 0.000387373 0.000383037 0.000159012 0.00037831 0.000163966 0.000389431 0.000375596 0.000224376 \u2026 0.000370853 0.000415252 0.000375596 0.000383775 0.000279658 0.000379835 0.000655951 0.000377186 0.000378578 0.00030907 0.000375911 0.0008319 0.000368403 0.00038769 0.00034119 0.000387262 0.000893315 0.000376956 0.000382018 0.000355017 0.000383702 0.000832146 0.000376036 0.000389199 0.000375041 \u2026 0.000393598 0.00065546 # plot imshow(A_tp, vmin=-.25, vmax=.25, cmap=\"Greys\", extent=[p[1], p[end], T[end], T[1]], aspect=.001) xlabel(\"slowness [s/m]\");ylabel(\"time [s]\"); Questions Can you interpret the results? Describe how you would design filters in the $\\tau-p$ domain to separate the different events. Try it. Use the adjoint option of the transform to transform back to the physical domain.","title":"Exercise 4: Fourier and Radon filtering"},{"location":"Assignments/Exercise4/#exercise-4-fourier-and-radon-filtering","text":"In this exercise we will look at seismic data in different domains and investigate how we can exploit behaviour of different kinds of noise in these domains to design filters. Contents: - Data - Temporal Fourier transform - f-k filtering - Radon transform - Parabolic Radon transform using PyPlot, SeisIO Data We use a single midpoint gather of the data used in the previous exercises: shot.segy (no big endian this time). # Dowload and adapt path shot = segy_read(\"./data_segy/shot.segy\") shot_data = Float32.(shot.data) h = get_header(shot, \"SourceX\", scale=false) - get_header(shot, \"GroupX\", scale=false) dt = get_header(shot, \"dt\")[1]/1e6 nt = get_header(shot, \"ns\")[1] T = 0:dt:(nt -1)*dt BinaryFileHeader: Job: 1 Line: 1 Reel: 1 DataTracePerEnsemble: 1 AuxiliaryTracePerEnsemble: 0 dt: 4000 dtOrig: 0 ns: 1001 nsOrig: 0 DataSampleFormat: 1 EnsembleFold: 0 TraceSorting: 0 VerticalSumCode: 0 SweepFrequencyStart: 0 SweepFrequencyEnd: 0 SweepLength: 0 SweepType: 0 SweepChannel: 0 SweepTaperlengthStart: 0 SweepTaperLengthEnd: 0 TaperType: 0 CorrelatedDataTraces: 0 BinaryGain: 0 AmplitudeRecoveryMethod: 0 MeasurementSystem: 0 ImpulseSignalPolarity: 0 VibratoryPolarityCode: 0 SegyFormatRevisionNumber: 0 FixedLengthTraceFlag: 0 NumberOfExtTextualHeaders: 0 1705444 3600 1001 \u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mFixed length trace flag set in stream: IOBuffer(data=UInt8[...], readable=true, writable=false, seekable=true, append=false, size=1705444, maxsize=Inf, ptr=3601, mark=-1)\u001b[39m 0.0:0.004:4.0 imshow(shot_data, vmin=-1, vmax=1, cmap=\"Greys\", extent=[h[end], h[1], T[end], T[1]], aspect=1000) xlabel(\"offset [m]\");ylabel(\"time [s]\"); Temporal Fourier transform We can use fftrl to perform a Fourier transform along the temporal direction. The power spectrum (i.e., the absolute value of the transformed data) looks like function fftrl(a, t, mode) # fft for real-valued vectors # # Tristan van Leeuwen, 2012 # tleeuwen@eos.ubc.ca # # use: # [b,f] = fftrl(a,t,mode) # # input: # a - input data # t - time vector # mode: 1: forward, -1:inverse # # output: # b - vector nt = length(t) dt = t[2] - t[1] nf = Int(floor(nt/2)) + 1 tmax = t[end] - t[1] f = 0:1/tmax:.5/dt if mode == 1 b = fft(a,1) b = b[1:nf,:] elseif mode == -1 a = [a;conj(a[Int(ceil(nt/2)):-1:2,:])] b = ifft(a, 1) b = real(b) else error(\"Unknown mode\") end return b, f end fftrl (generic function with 1 method) Data_fh, f = fftrl(shot_data, T, 1) (Complex{Float32}[0.684434+0.0im 0.971781+0.0im \u2026 0.0969428+0.0im 0.00433278+0.0im; -0.701183-0.451787im -0.412326-0.460599im \u2026 -1.3078-0.497307im -1.40236-0.48802im; \u2026 ; -0.121274+0.000705719im -0.0863834-0.000402451im \u2026 0.157795-0.00114059im 0.110151-0.000276089im; -0.122033+0.000601768im -0.0849152-0.000236511im \u2026 0.159012-0.000580788im 0.109696-0.000192404im], 0.0:0.25:125.0) imshow(abs.(Data_fh), cmap=\"jet\", extent=[h[end], h[1], f[end], f[1]], aspect=20) xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') f-k filtering A Fourier transform along both time and offset direction is often referred to as an transform. We can use fktran. The powerspectrum looks like function fktran(a,t,x,mode) \"\"\" f-k transform for real-values input. use: b, f, k = fktran(a,t,x,mode) input: a - matrix in t-x domain (nt x nx) t - time vector x - x vector mode - 1:forward, -1:inverse \"\"\" nt = length(t) nx = length(x) dt = t[2]-t[1] dx = x[2] - x[1] xmax = x[end] - x[1] tmax = t[end] - t[1] f = 0:1/tmax:.5/dt k = -.5/dx:1/xmax:.5/dx nf = length(f) if mode == 1 b = fft(a, 1) b = b[1:nf, :] b = ifft(b, 2) b = circshift(b,[0 ceil(Int, nx/2)-1]); elseif mode == -1 b = circshift(a,[0 floor(Int, nx/2)+1]); b = fft(b, 2) b = ifft(b, 1) b = real(b) else error(\"unknown mode\") end return b, f, k end fktran (generic function with 1 method) Data_fk, fk, kx = fktran(shot_data, T, h, 1) (Complex{Float32}[0.00217381+0.375868im -0.00371527-0.375896im \u2026 -0.00371557+0.375898im 0.00217354-0.375864im; -0.0666401+0.378171im 0.0651375-0.378642im \u2026 -0.072564+0.377115im 0.0710575-0.377542im; \u2026 ; 0.00330043+0.400901im -0.00697034-0.400875im \u2026 -0.0029994+0.40092im -0.000692182-0.400906im; 0.00196619+0.400894im -0.00564895-0.400912im \u2026 -0.00433144+0.400905im 0.000641863-0.400899im], 0.0:0.25:125.0, 0.05:-0.00025:-0.05) imshow(abs.(Data_fk), cmap=\"jet\", extent=[kx[end], kx[1], f[end], f[1]], aspect=.001) xlabel(\"wavenumber [1/m\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]')","title":"Exercise 4: Fourier and Radon filtering"},{"location":"Assignments/Exercise4/#questions","text":"Subsample the data in the offset direction and look at the Fourier transform. (Hint: use Data[:,1:n:end] and h[1:n:end] where n is the number of times you want to subsample). What do you see? Why is it important to have a good receiver sampling? A filter is simply a multiplicative factor applied in some transform domain, typically (f-h) or (f-k), followed by an inverse transform. For example, a band-pass filter in the (f-h) domain filters out higher temporal frequencies by setting them to zero. A simple band-pass filter looks like this: F_hp = ones(length(f),length(h)) F_hp[(f.<5) .| (f.>20.),:] = 0 imshow(F_hp, extent=[h[end], h[1], f[end], f[1]], aspect=20) colorbar() xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') The filtered data looks like this imshow(fftrl(F_hp.*Data_fh, f, -1)[1], cmap=\"Greys\", vmin=-1, vmax=1, extent=[h[end], h[1], T[end], T[1]], aspect=1000) xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') Do you see the artifacts? A way to reduce these artifacts is to smooth the filter. We can do this by convolving the filter with a triangular smoothing kernel. This is implemented in the function smooth_2D. The result looks like this: # Pkg.add(\"Images\") of you do not alread yhave it using Images function smooth_2D(input, n1, n2) t1 = [1:n1; n1-1:-1:1]/n1^2 t2 = [1:n2; n2-1:-1:1]/n2^2 kernel = t1 * t2' return imfilter(input, centered(kernel)) end smooth_2D (generic function with 1 method) F_hp_smooth = smooth_2D(F_hp, 5, 1) imshow(F_hp_smooth, extent=[h[end], h[1], f[end], f[1]], aspect=20) colorbar() xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') imshow(fftrl(F_hp_smooth.*Data_fh, f, -1)[1], cmap=\"Greys\", vmin=-1, vmax=1, extent=[h[end], h[1], T[end], T[1]], aspect=1000) xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') A (smoothed) filter in the (f-k) domain may look like this ff = [fi for fi in f, kxi in kx] kkx = [kxi for fi in f, kxi in kx] F_kx = zeros(length(fk),length(kx)) F_kx[(ff -1e3 * abs.(kkx) .> 5) .& (ff.<60)] = 1 F_kx = smooth_2D(F_kx, 5, 5) imshow(F_kx, cmap=\"jet\", extent=[kx[end], kx[1], f[end], f[1]], aspect=.001) xlabel(\"wavenumber [1/m\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]')","title":"Questions:"},{"location":"Assignments/Exercise4/#questions_1","text":"Describe how you would design filters to clean up shot gathers shot_noise1 and shot_noise2. (hint: look the f-k transform and compare to the orinigal data) Try it and compare the result with the original shot gather.","title":"Questions"},{"location":"Assignments/Exercise4/#radon-transform","text":"The Radon tranform performs sums along lines with different intercepts $\\tau$) and slopes $p$. Hence, it is sometimes refered to as the $\\tau-p$ transform in geophysics. $\\hat{d}(\\tau,p) = \\int\\mathrm{d}h\\, d(t + ph, h)$ The transform is implemented in the function lpradon. To get an idea of what this transform does, we consider the simple example in lines.segy. function lpradon(input, t, h, q, power, mode) # linear and parabolic Radon transform and its adjoint. # # Tristan van Leeuwen, 2012 # tleeuwen@eos.ubc.ca # # use: # out = lpradon(input,t,h,q,power,mode) # # input: # input - input matrix of size (length(t) x length(h)) for forward, (length(t) x length(q)) for adjoint) # t - time vector in seconds # h - offset vecror in meters # q - radon parameter # power - 1: linear radon, 2: parabolic radon # mode - 1: forward, -1: adjoint # # output: println(size(L)) # output matrix of size (length(t) x length(q)) for forward, (length(t) x length(h)) for adjoint) # # dt = t[2] - t[1] nt = length(t) nh = length(h) nq = length(q) nfft = 2*(nextpow2(nt)) input_padded = zeros(nfft, size(input)[2]) input_padded[1:size(input)[1], :] = input[:, :] if mode == 1 input_padded = fft(input_padded, 1) out = zeros(Complex{Float64}, nfft, nq) for k = 2:Int(floor(nfft/2)) f = 2.*pi*(k-1)/nfft/dt L = exp.(im*f*(h.^power)*q') tmp = input_padded[k,:].'*L out[k,:] = tmp out[nfft + 2 - k, :] = conj(tmp) end out = real(ifft(out, 1)) out = out[1:nt, :] else input_padded = fft(input_padded,1) out = zeros(Complex{Float64}, nfft, nh) for k = 2:Int(floor(nfft/2)) f = 2.*pi*(k-1)/nfft/dt L = exp.(im*f*(h.^power)*q') tmp = input_padded[k,:].'*L' out[k,:] = tmp out[nfft+2-k,:] = conj(tmp) end out = real(ifft(out,1)) out = out[1:nt, :] end return out end lpradon (generic function with 1 method) # Dowload and adapt path shot_radon = segy_read(\"./data_segy/lines.segy\") A = Float32.(shot_radon.data) h = get_header(shot_radon, \"SourceX\", scale=false) - get_header(shot, \"GroupX\", scale=false) dt = get_header(shot_radon, \"dt\")[1]/1e6 nt = get_header(shot_radon, \"ns\")[1] T = 0:dt:(nt -1)*dt BinaryFileHeader: Job: 1 Line: 1 Reel: 1 DataTracePerEnsemble: 1 AuxiliaryTracePerEnsemble: 0 dt: 4000 dtOrig: 0 ns: 1001 nsOrig: 0 DataSampleFormat: 1 EnsembleFold: 0 TraceSorting: 0 VerticalSumCode: 0 SweepFrequencyStart: 0 SweepFrequencyEnd: 0 SweepLength: 0 SweepType: 0 SweepChannel: 0 SweepTaperlengthStart: 0 SweepTaperLengthEnd: 0 TaperType: 0 CorrelatedDataTraces: 0 BinaryGain: 0 AmplitudeRecoveryMethod: 0 MeasurementSystem: 0 ImpulseSignalPolarity: 0 VibratoryPolarityCode: 0 SegyFormatRevisionNumber: 0 FixedLengthTraceFlag: 0 NumberOfExtTextualHeaders: 0 1705444 3600 1001 \u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mFixed length trace flag set in stream: IOBuffer(data=UInt8[...], readable=true, writable=false, seekable=true, append=false, size=1705444, maxsize=Inf, ptr=3601, mark=-1)\u001b[39m 0.0:0.004:4.0 imshow(A, vmin=-.1, vmax=.1, cmap=\"Greys\", extent=[h[end], h[1], T[end], T[1]], aspect=1000) xlabel(\"offset [m]\");ylabel(\"time [s]\"); # which p-values p = 1e-3.*(-3:.05:3) # transform A_tp = lpradon(A, T, h, p, 1, 1) 1001\u00d7121 Array{Float64,2}: 0.000378078 0.000384182 0.000384585 \u2026 0.000202505 0.000644788 0.000376368 0.000389721 0.00037549 0.000144312 0.000541559 0.000387413 0.000381872 0.000383162 0.000133913 0.000409034 0.000390602 0.000388732 0.000380008 0.000201181 0.000262995 0.00040214 0.000383436 0.000392553 0.000302437 0.000157082 0.00040122 0.000393219 0.000391394 \u2026 0.000439509 0.000100834 0.000405988 0.000390277 0.000402393 0.000551232 0.000125599 0.000398302 0.000401124 0.000397027 0.000636942 0.000208975 0.00039937 0.000397851 0.000403059 0.000648591 0.000347769 0.00039261 0.000407363 0.000394245 0.000611003 0.000491774 0.00039947 0.000402683 0.000400071 \u2026 0.000507467 0.000622865 0.000401411 0.000411663 0.000394785 0.00039216 0.000693264 0.000417296 0.000408056 0.000406892 0.000268286 0.000703196 \u22ee \u22f1 \u22ee 0.000378107 0.000381697 -0.000934809 0.000386704 0.000286472 0.000374914 0.000389452 -0.000570546 \u2026 0.000391708 5.61129e-5 0.000389898 0.000381116 -0.000301544 0.000381055 -9.33017e-5 0.000387139 0.000386579 -9.14174e-5 0.000384115 -0.000125689 0.00039709 0.000377236 4.99588e-5 0.000373351 -3.12507e-5 0.000387373 0.000383037 0.000159012 0.00037831 0.000163966 0.000389431 0.000375596 0.000224376 \u2026 0.000370853 0.000415252 0.000375596 0.000383775 0.000279658 0.000379835 0.000655951 0.000377186 0.000378578 0.00030907 0.000375911 0.0008319 0.000368403 0.00038769 0.00034119 0.000387262 0.000893315 0.000376956 0.000382018 0.000355017 0.000383702 0.000832146 0.000376036 0.000389199 0.000375041 \u2026 0.000393598 0.00065546 # plot imshow(A_tp, vmin=-.25, vmax=.25, cmap=\"Greys\", extent=[p[1], p[end], T[end], T[1]], aspect=.001) xlabel(\"slowness [s/m]\");ylabel(\"time [s]\");","title":"Radon transform"},{"location":"Assignments/Exercise4/#questions_2","text":"Can you interpret the results? Describe how you would design filters in the $\\tau-p$ domain to separate the different events. Try it. Use the adjoint option of the transform to transform back to the physical domain.","title":"Questions"},{"location":"Assignments/Exercise5/","text":"Exercise 5: From processing to inversion I Contents Linear systems SPOT Deconvolotion Linear systems A matrix is represented in Julia as follows A = [1 2;3 -1] 2\u00d72 Array{Int64,2}: 1 2 3 -1 The transpose of a matrix is obtained via A' A' 2\u00d72 Array{Int64,2}: 1 3 2 -1 In a similar manner, we can define a column vector as follows x = [2; 2] 2-element Array{Int64,1}: 2 2 Desribe two ways to define a row vector. Now, consider the matrices A1 = [1/sqrt(2) 2/3 sqrt(2)/6;0 1/3 -2*sqrt(2)/3;-1/sqrt(2) 2/3 sqrt(2)/6]; A2 = [0 2 2;2 1 -3;1 0 -2]; A3 = [3 1;1 0;2 1]; A4 = [2 4 3; 1 3 1]; Questions Look at A1'*A1, what kind of matrix is A1? What does this mean? Look at A2 [1;2;3] and A2 [3;1;4], what can you say about the matrix A2? What do you call a linear system defined by matrix A3? What do you call a linear system defined by matrix A4? If a matrix is invertible, we can explicitly find the inverse with inv find a solution of A1*x = [6;-3;0], is there only one solution? Do you really need inv here? find a solution of A2*x = [4;0;-1], is there only one solution? What characterizes the solution you found? find a solution of A3*x = [5;2;5], is there only one solution? What characterizes the solution you found? find a solution of A4*x = [10;5], is there only one solution? What characterizes the solution you found? JOLI https://github.com/slimgroup/JOLI.jl The JOLI toolbox gives a way to represent matrices implicitly. A nice example is the Fourier transform. In julia, the Fourier transform of a vector is given by fft(x). We can explicitly construct a matrix representing the Fourier transform as follows # dimension N = 10 F1 = zeros(Complex{Float64}, N,N) for k = 1:N # construct k-th unit vector ek = zeros(N,1) ek[k] = 1 # make column of matrix F1[:, k]= fft(ek) end Look at the matrix, what do you notice? Verify that it gives the same result as fft by trying on a vector We can also define the FFT using JOLI: using JOLI F2 = joDFT(N) JOLI.joLinearFunction{Float64,Complex{Float64}}(\"joDFTp\", 10, 10, JOLI.#514, Nullable{Function}(JOLI.#278), Nullable{Function}(JOLI.#515), Nullable{Function}(JOLI.#279), false, Nullable{Function}(JOLI.#516), Nullable{Function}(JOLI.#280), Nullable{Function}(JOLI.#517), Nullable{Function}(JOLI.#281), false) whos(r\"F1\"), whos(r\"F2\"); F1 1600 bytes 10\u00d710 Array{Complex{Float64},2} F2 582 bytes JOLI.joLinearFunction{Float64,Comp\u2026 And this is only a small example! The reason why we want to have such operations behave like matrices is that we can use (some) standard algorithms that where written to work with matrices to work with large scale operations. As an example we use a Gaussian matrix: N = 10000; # NxN Gaussian matrix G1 = ones(N, N); # NxN Gaussian JOLI operator (will represent a different matrix than G1 becuase it is gerenated randomly) G2 = joOnes(N); whos(r\"G1\"), whos(r\"G2\"); G1 781250 KB 10000\u00d710000 Array{Float64,2} G2 246 bytes JOLI.joMatrix{Float64,Float64} Deconvolution We some signal $f(t)$ which is a convolution of some unkown signal $g(t)$ and a known filter $w(t)$. Given $f$ and $w$ we would like to retreive $g$. For the example we use: # time axis t = 0:.001:2'; N = length(t); # true signal g has approx k spikes with random amplitudes k = 20; g = zeros(N,1); g[rand(1:N, k)] = randn(k,1); # filter w = (1-2*1e3*(t-.2).^2).*exp.(-1e3*(t-.2).^2); # plot using PyPlot figure(); plot(t,g); xlabel(\"t [s]\");ylabel(\"g(t)\"); figure(); plot(t,w); xlabel(\"t [s]\");ylabel(\"w(t)\"); First, we consider the forward problem of convolving a signal, using JOLI. Perform the convolution using the usual julia commands fft, ifft and element-wise multiplication .*. Creat a JOLI operator to do the same. You can construct an operator to do the multiplication with the filter using joDiag. - Compare the results of both. - Compare f to g, what do you notice? - Assuming that your convolution operator is called C: Now, construct the signal f using your SPOT operator and add some noise (i.e., f = C g + 1e-1 randn(N,1)). Do you think C has a null-space? If so, describe it. (Hint: look at the filter). Use the adjoint of C as an approximation to the inverse, what does this correspond to and what does the reconstruction look like? - Describe how you would invert the system. - Use lsqr to do it. (you might need to increase the number of iterations.) - Look at the signal that is predicted by your reconstruction, do you see a difference with the true signal? lsqr will give us a solution that has a small two-norm and explains the data. Alternatively, we can use another solver that will give us a spiky solution and explains the data. This solver is spgl1. Try spgl1(C,f,0,1e-2). https://github.com/slimgroup/GenSPGL.jl Is this solution closer to the true one? Look at the predicted signal for this solution, do you see a difference with the true signal? Can we really say that this is a better solution? using GenSPGL # Pkg.clone(\"https://github.com/slimgroup/GenSPGL.jl\") # FFT convolution wf = fft(w); f1 = ifft(wf.*fft(g)); # JOLI operator to perform convolution. C = joDFT(N)'*joDiag(wf)*joDFT(N); f2 = C*g; figure(); plot(t,f1) plot(t,f2) plot(t,g); xlabel(\"t [s]\");ylabel(\"f(t)\");legend([\"normal\",\"JOLI\", \"g\"]); # true signal f = C*g + 1e-3*randn(N,1); # lsqr gt = C\\f 2001\u00d71 Array{Float64,2}: 0.00666159 0.00698098 0.00728673 0.00760021 0.00786498 0.00796295 0.00801857 0.00814685 0.00807513 0.0079503 0.00779799 0.00749169 0.00719726 \u22ee 0.00508929 0.00474104 0.00452079 0.00435027 0.00431479 0.00439437 0.00467603 0.00483907 0.00517327 0.00548942 0.00585045 0.00628071 # Solve opts = spgOptions(optTol = 1e-10, verbosity = 1) #gtt, r, grads, info = spgl1(C, vec(f), tau = 0., sigma = norm(f - C*gt)) GenSPGL.spgOptions(1, 1, 100000, 3, 1.0e-6, 1.0e-6, 1.0e-10, 0.0001, 1.0e-16, 100000.0, 2, Inf, false, Nullable{Bool}(), Inf, [1], false, 3, 1, 10000, false, GenSPGL.NormL1_project, GenSPGL.NormL1_primal, GenSPGL.NormL1_dual, GenSPGL.funLS, false, false, false)","title":"Exercise 5: From processing to inversion I"},{"location":"Assignments/Exercise5/#exercise-5-from-processing-to-inversion-i","text":"","title":"Exercise 5: From processing to inversion I"},{"location":"Assignments/Exercise5/#contents","text":"Linear systems SPOT Deconvolotion","title":"Contents"},{"location":"Assignments/Exercise5/#linear-systems","text":"A matrix is represented in Julia as follows A = [1 2;3 -1] 2\u00d72 Array{Int64,2}: 1 2 3 -1 The transpose of a matrix is obtained via A' A' 2\u00d72 Array{Int64,2}: 1 3 2 -1 In a similar manner, we can define a column vector as follows x = [2; 2] 2-element Array{Int64,1}: 2 2 Desribe two ways to define a row vector. Now, consider the matrices A1 = [1/sqrt(2) 2/3 sqrt(2)/6;0 1/3 -2*sqrt(2)/3;-1/sqrt(2) 2/3 sqrt(2)/6]; A2 = [0 2 2;2 1 -3;1 0 -2]; A3 = [3 1;1 0;2 1]; A4 = [2 4 3; 1 3 1];","title":"Linear systems"},{"location":"Assignments/Exercise5/#questions","text":"Look at A1'*A1, what kind of matrix is A1? What does this mean? Look at A2 [1;2;3] and A2 [3;1;4], what can you say about the matrix A2? What do you call a linear system defined by matrix A3? What do you call a linear system defined by matrix A4? If a matrix is invertible, we can explicitly find the inverse with inv find a solution of A1*x = [6;-3;0], is there only one solution? Do you really need inv here? find a solution of A2*x = [4;0;-1], is there only one solution? What characterizes the solution you found? find a solution of A3*x = [5;2;5], is there only one solution? What characterizes the solution you found? find a solution of A4*x = [10;5], is there only one solution? What characterizes the solution you found?","title":"Questions"},{"location":"Assignments/Exercise5/#joli","text":"https://github.com/slimgroup/JOLI.jl The JOLI toolbox gives a way to represent matrices implicitly. A nice example is the Fourier transform. In julia, the Fourier transform of a vector is given by fft(x). We can explicitly construct a matrix representing the Fourier transform as follows # dimension N = 10 F1 = zeros(Complex{Float64}, N,N) for k = 1:N # construct k-th unit vector ek = zeros(N,1) ek[k] = 1 # make column of matrix F1[:, k]= fft(ek) end Look at the matrix, what do you notice? Verify that it gives the same result as fft by trying on a vector We can also define the FFT using JOLI: using JOLI F2 = joDFT(N) JOLI.joLinearFunction{Float64,Complex{Float64}}(\"joDFTp\", 10, 10, JOLI.#514, Nullable{Function}(JOLI.#278), Nullable{Function}(JOLI.#515), Nullable{Function}(JOLI.#279), false, Nullable{Function}(JOLI.#516), Nullable{Function}(JOLI.#280), Nullable{Function}(JOLI.#517), Nullable{Function}(JOLI.#281), false) whos(r\"F1\"), whos(r\"F2\"); F1 1600 bytes 10\u00d710 Array{Complex{Float64},2} F2 582 bytes JOLI.joLinearFunction{Float64,Comp\u2026 And this is only a small example! The reason why we want to have such operations behave like matrices is that we can use (some) standard algorithms that where written to work with matrices to work with large scale operations. As an example we use a Gaussian matrix: N = 10000; # NxN Gaussian matrix G1 = ones(N, N); # NxN Gaussian JOLI operator (will represent a different matrix than G1 becuase it is gerenated randomly) G2 = joOnes(N); whos(r\"G1\"), whos(r\"G2\"); G1 781250 KB 10000\u00d710000 Array{Float64,2} G2 246 bytes JOLI.joMatrix{Float64,Float64}","title":"JOLI"},{"location":"Assignments/Exercise5/#deconvolution","text":"We some signal $f(t)$ which is a convolution of some unkown signal $g(t)$ and a known filter $w(t)$. Given $f$ and $w$ we would like to retreive $g$. For the example we use: # time axis t = 0:.001:2'; N = length(t); # true signal g has approx k spikes with random amplitudes k = 20; g = zeros(N,1); g[rand(1:N, k)] = randn(k,1); # filter w = (1-2*1e3*(t-.2).^2).*exp.(-1e3*(t-.2).^2); # plot using PyPlot figure(); plot(t,g); xlabel(\"t [s]\");ylabel(\"g(t)\"); figure(); plot(t,w); xlabel(\"t [s]\");ylabel(\"w(t)\"); First, we consider the forward problem of convolving a signal, using JOLI. Perform the convolution using the usual julia commands fft, ifft and element-wise multiplication .*. Creat a JOLI operator to do the same. You can construct an operator to do the multiplication with the filter using joDiag. - Compare the results of both. - Compare f to g, what do you notice? - Assuming that your convolution operator is called C: Now, construct the signal f using your SPOT operator and add some noise (i.e., f = C g + 1e-1 randn(N,1)). Do you think C has a null-space? If so, describe it. (Hint: look at the filter). Use the adjoint of C as an approximation to the inverse, what does this correspond to and what does the reconstruction look like? - Describe how you would invert the system. - Use lsqr to do it. (you might need to increase the number of iterations.) - Look at the signal that is predicted by your reconstruction, do you see a difference with the true signal? lsqr will give us a solution that has a small two-norm and explains the data. Alternatively, we can use another solver that will give us a spiky solution and explains the data. This solver is spgl1. Try spgl1(C,f,0,1e-2). https://github.com/slimgroup/GenSPGL.jl Is this solution closer to the true one? Look at the predicted signal for this solution, do you see a difference with the true signal? Can we really say that this is a better solution? using GenSPGL # Pkg.clone(\"https://github.com/slimgroup/GenSPGL.jl\") # FFT convolution wf = fft(w); f1 = ifft(wf.*fft(g)); # JOLI operator to perform convolution. C = joDFT(N)'*joDiag(wf)*joDFT(N); f2 = C*g; figure(); plot(t,f1) plot(t,f2) plot(t,g); xlabel(\"t [s]\");ylabel(\"f(t)\");legend([\"normal\",\"JOLI\", \"g\"]); # true signal f = C*g + 1e-3*randn(N,1); # lsqr gt = C\\f 2001\u00d71 Array{Float64,2}: 0.00666159 0.00698098 0.00728673 0.00760021 0.00786498 0.00796295 0.00801857 0.00814685 0.00807513 0.0079503 0.00779799 0.00749169 0.00719726 \u22ee 0.00508929 0.00474104 0.00452079 0.00435027 0.00431479 0.00439437 0.00467603 0.00483907 0.00517327 0.00548942 0.00585045 0.00628071 # Solve opts = spgOptions(optTol = 1e-10, verbosity = 1) #gtt, r, grads, info = spgl1(C, vec(f), tau = 0., sigma = norm(f - C*gt)) GenSPGL.spgOptions(1, 1, 100000, 3, 1.0e-6, 1.0e-6, 1.0e-10, 0.0001, 1.0e-16, 100000.0, 2, Inf, false, Nullable{Bool}(), Inf, [1], false, 3, 1, 10000, false, GenSPGL.NormL1_project, GenSPGL.NormL1_primal, GenSPGL.NormL1_dual, GenSPGL.funLS, false, false, false)","title":"Deconvolution"},{"location":"Assignments/Exercise6/","text":"Exercise 6: From processing to inversion II Contents: Kronecker NMO-Stack-deconvolution Inverting the Radon transform Kronecker Given a matrix X, we often want to apply operations along both dimensions. For example, if each column is a trace we can do a temporal fourier transform of each trace as follows using JOLI, JOLI.Seismic, GenSPGL, PyPlot # dummy matrix n1 = 10 n2 = 5 X = joComplex.(randn(n1,n2)) # fft along first dimension F1 = joDFT(n1; DDT=joComplex) Y = F1*X 10\u00d75 Array{Complex{Float64},2}: -1.25777+0.0im -0.774641+0.0im \u2026 0.769853+0.0im -0.654297+0.239707im 0.237683-0.15825im 1.79616+0.309481im 0.416353+1.54421im 0.429671-0.15162im 0.630353-0.853749im -0.820058+0.909454im 0.186228+1.00521im -0.194571+0.35528im -1.24295-0.578256im 0.476904-1.38574im 0.0477609-0.885882im -1.31471+0.0im 0.647963+0.0im \u2026 1.16376+0.0im -1.24295+0.578256im 0.476904+1.38574im 0.0477609+0.885882im -0.820058-0.909454im 0.186228-1.00521im -0.194571-0.35528im 0.416353-1.54421im 0.429671+0.15162im 0.630353+0.853749im -0.654297-0.239707im 0.237683+0.15825im 1.79616-0.309481im We can do an fft along the second dimension as follows F2 = joDFT(n2; DDT=joComplex) Y = transpose(F2*transpose(X)); Finally, we can combine both in one step as follows Y = (F2*(F1*X).').'; We can do the equivalent operation on the vectorized version of X via the Kronecker product. The formula is : $ \\mathrm{vec}(AXB) = (B^T\\otimes A)\\mathrm{vec}(X) $. where $\\mathrm{vec}$ vectorizes a matrix $X(:)$. Use joKron to construct a 2D fft operator that works on a vectorized version of X, X(:). Show that the result is the same as when using the operators F1 and F2 separately. # 2D FFT operator F12 = joKron(F2,F1); # compare: F12*X(:) should be the same as Y(:) norm(F12*X[:] - Y[:]) 0.0 NMO-Stack-deconvolution We revisit the NMO and stack operations we saw a few weeks before, but we will use it backwards . Remember the conventional flow was Data -> NMO corrected data -> stack -> image We will now traverse this chain in the reverse order, each time using the adjoint of the operations. The reflectivity (image) can be represented by a convolution of a spike train with a wavelet, as we saw last week. We will build this chain of operations reflectivity -> convolved reflectivity -> NMO corrected data -> data, step-by-step. First, define a time and offset axis. # time and offset grid t = Float64.(0:.004:1); nt = length(t); h = Float64.(0.0:10.0:1000.0); nh = length(h); We make a reflectivity series with 3 spikes and define a wavelet. # reflectivity r = zeros(nt,1); r[51] = 1 r[101] = -.5 r[151] = .75 # wavelet w = (1-2*1e3*(t-.1).^2).*exp.(-1e3*(t-.1).^2) 251-element Array{Float64,1}: -0.000862599 -0.00173336 -0.00335964 -0.00627815 -0.0113054 -0.0196064 -0.0327228 -0.0525127 -0.0809414 -0.119668 -0.169407 -0.229101 -0.295059 \u22ee -8.75953e-316 -9.20212e-319 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 The convolution is done by using the FFT SPOT operators, just like in the last exercise. # convolution operator C = joDFT(nt)'*joDiag(fft(w))*joDFT(nt); Next, we need to extend the the reflectivity to be a function of time and offset. We are trying to undo the stack operation to create NMO corrected data. Let's first look at the stack. Given a matrix, we can stack the columns by multiplying with a vector of all ones: # test matrix X =[1 2; 3 4; 5 6] Y = X*[1;1] 3-element Array{Int64,1}: 3 7 11 Construct a JOLI operator that stacks a vectorized input matrix of size nt x nh along the columns. Use joDirac to define an identity operator. Apply the operators C and S to the vector r to get something that resembles NMO-corrected data. You can reshape the vector into a matrix by using reshape. Plot the result. The next step is to define the NMO operator. Use joNMO and define the operator for a constant velocity of 2000 m/s. Apply it to the result of the previous exercise and plot the result. Now, define a combined operator that predicts data given a spike train. Check that your combined operator satisfies the dottest Make data for the spike train r and add some noise. Invert the operator with both lsqr and spgl1 (see previous exercise). Inverting the Radon transform In the previous exercise we saw that the Radon transform is not unitary. This means that its adjoint is not its inverse. Here, we will set up a JOLI operator for the Radon transform and invert it using lsqr and spgl1. If the computation takes too long you can use a coarser sampling of the q axis. read the data parab.segy Set up a parabolic radon transform JOLI operator , R=joRadon(....; DDT=joFloat) Plot the data in the Radon domain, and go back to the orininal data using the adjoint. Compare to the original data. - - What do you notice? You want to obtain data in the Radon domain b for which the predicted data in the t,h domain is close to the original data. How would you do this?. Setup a damped least-squares system and invert with lsqr. Try different damping parameters and explain what you see. Hint: us lsqr(..., damp=) for a damped least square. Use the original system and invert with spgl1(A,b,0,tolerance). Describe a possible application of this technique in seismic processing Do not forget to turn your data into Float64","title":"Exercise 6: From processing to inversion II"},{"location":"Assignments/Exercise6/#exercise-6-from-processing-to-inversion-ii","text":"Contents: Kronecker NMO-Stack-deconvolution Inverting the Radon transform","title":"Exercise 6: From processing to inversion II"},{"location":"Assignments/Exercise6/#kronecker","text":"Given a matrix X, we often want to apply operations along both dimensions. For example, if each column is a trace we can do a temporal fourier transform of each trace as follows using JOLI, JOLI.Seismic, GenSPGL, PyPlot # dummy matrix n1 = 10 n2 = 5 X = joComplex.(randn(n1,n2)) # fft along first dimension F1 = joDFT(n1; DDT=joComplex) Y = F1*X 10\u00d75 Array{Complex{Float64},2}: -1.25777+0.0im -0.774641+0.0im \u2026 0.769853+0.0im -0.654297+0.239707im 0.237683-0.15825im 1.79616+0.309481im 0.416353+1.54421im 0.429671-0.15162im 0.630353-0.853749im -0.820058+0.909454im 0.186228+1.00521im -0.194571+0.35528im -1.24295-0.578256im 0.476904-1.38574im 0.0477609-0.885882im -1.31471+0.0im 0.647963+0.0im \u2026 1.16376+0.0im -1.24295+0.578256im 0.476904+1.38574im 0.0477609+0.885882im -0.820058-0.909454im 0.186228-1.00521im -0.194571-0.35528im 0.416353-1.54421im 0.429671+0.15162im 0.630353+0.853749im -0.654297-0.239707im 0.237683+0.15825im 1.79616-0.309481im We can do an fft along the second dimension as follows F2 = joDFT(n2; DDT=joComplex) Y = transpose(F2*transpose(X)); Finally, we can combine both in one step as follows Y = (F2*(F1*X).').'; We can do the equivalent operation on the vectorized version of X via the Kronecker product. The formula is : $ \\mathrm{vec}(AXB) = (B^T\\otimes A)\\mathrm{vec}(X) $. where $\\mathrm{vec}$ vectorizes a matrix $X(:)$. Use joKron to construct a 2D fft operator that works on a vectorized version of X, X(:). Show that the result is the same as when using the operators F1 and F2 separately. # 2D FFT operator F12 = joKron(F2,F1); # compare: F12*X(:) should be the same as Y(:) norm(F12*X[:] - Y[:]) 0.0","title":"Kronecker"},{"location":"Assignments/Exercise6/#nmo-stack-deconvolution","text":"We revisit the NMO and stack operations we saw a few weeks before, but we will use it backwards . Remember the conventional flow was Data -> NMO corrected data -> stack -> image We will now traverse this chain in the reverse order, each time using the adjoint of the operations. The reflectivity (image) can be represented by a convolution of a spike train with a wavelet, as we saw last week. We will build this chain of operations reflectivity -> convolved reflectivity -> NMO corrected data -> data, step-by-step. First, define a time and offset axis. # time and offset grid t = Float64.(0:.004:1); nt = length(t); h = Float64.(0.0:10.0:1000.0); nh = length(h); We make a reflectivity series with 3 spikes and define a wavelet. # reflectivity r = zeros(nt,1); r[51] = 1 r[101] = -.5 r[151] = .75 # wavelet w = (1-2*1e3*(t-.1).^2).*exp.(-1e3*(t-.1).^2) 251-element Array{Float64,1}: -0.000862599 -0.00173336 -0.00335964 -0.00627815 -0.0113054 -0.0196064 -0.0327228 -0.0525127 -0.0809414 -0.119668 -0.169407 -0.229101 -0.295059 \u22ee -8.75953e-316 -9.20212e-319 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 The convolution is done by using the FFT SPOT operators, just like in the last exercise. # convolution operator C = joDFT(nt)'*joDiag(fft(w))*joDFT(nt); Next, we need to extend the the reflectivity to be a function of time and offset. We are trying to undo the stack operation to create NMO corrected data. Let's first look at the stack. Given a matrix, we can stack the columns by multiplying with a vector of all ones: # test matrix X =[1 2; 3 4; 5 6] Y = X*[1;1] 3-element Array{Int64,1}: 3 7 11 Construct a JOLI operator that stacks a vectorized input matrix of size nt x nh along the columns. Use joDirac to define an identity operator. Apply the operators C and S to the vector r to get something that resembles NMO-corrected data. You can reshape the vector into a matrix by using reshape. Plot the result. The next step is to define the NMO operator. Use joNMO and define the operator for a constant velocity of 2000 m/s. Apply it to the result of the previous exercise and plot the result. Now, define a combined operator that predicts data given a spike train. Check that your combined operator satisfies the dottest Make data for the spike train r and add some noise. Invert the operator with both lsqr and spgl1 (see previous exercise).","title":"NMO-Stack-deconvolution"},{"location":"Assignments/Exercise6/#inverting-the-radon-transform","text":"In the previous exercise we saw that the Radon transform is not unitary. This means that its adjoint is not its inverse. Here, we will set up a JOLI operator for the Radon transform and invert it using lsqr and spgl1. If the computation takes too long you can use a coarser sampling of the q axis. read the data parab.segy Set up a parabolic radon transform JOLI operator , R=joRadon(....; DDT=joFloat) Plot the data in the Radon domain, and go back to the orininal data using the adjoint. Compare to the original data. - - What do you notice? You want to obtain data in the Radon domain b for which the predicted data in the t,h domain is close to the original data. How would you do this?. Setup a damped least-squares system and invert with lsqr. Try different damping parameters and explain what you see. Hint: us lsqr(..., damp=) for a damped least square. Use the original system and invert with spgl1(A,b,0,tolerance). Describe a possible application of this technique in seismic processing Do not forget to turn your data into Float64","title":"Inverting the Radon transform"},{"location":"Assignments/Exercise7/","text":"Exercise 7 : Waveform inversion With waveform inversion we try to find the velocity model for which the modeled data optimally fits the observed data in a least-squares sense. Mathematically, we try to solve the following optimization problem: where is the modeling operator and is the observed data. Contents: - Camambert model - Modeling - Optimization - Inversion To illustrate some key properties of the waveform inversion problem, we are going to conduct some experiments on the famous 'Camambert' model. Camambert model: The Camambert model consists of a circular perturbation, , superimposed on a homogeneous medium, , with velocity 2500 m/s. using JUDI.TimeModeling, JUDI.SLIM_optim, PyPlot, SeisIO # Velocity model # number of gridpoints n = (101, 101) # Grid spacing d = (10.0, 10.0) # Origin o = (0., 0.) x = zeros(n) z = zeros(n) for i in 0:100 x[i+1, :] = i*10 z[:, i+1] = i*10 end # vp = 2.5f0 * ones(Float32, n) vp[find(sqrt.((x-500).^2 +(z-500).^2) .<=250)]=3.0f0 m = 1f0./vp.^2f0 # v0 = 2.5f0 * ones(Float32, n) m0 = 1f0./v0.^2f0 imshow(m) PyObject <matplotlib.image.AxesImage object at 0x7fee6c4dca20> # Set up model structure w/ squared slowness model0 = Model(n, d, o, m0) model = Model(n, d, o, m) JUDI.TimeModeling.Model((101, 101), (10.0, 10.0), (0.0, 0.0), 40, Float32[0.16 0.16 \u2026 0.16 0.16; 0.16 0.16 \u2026 0.16 0.16; \u2026 ; 0.16 0.16 \u2026 0.16 0.16; 0.16 0.16 \u2026 0.16 0.16], 1) Source geometry # Sources nsrc = 10 xsrc = convertToCell(linspace(10f0, 990f0, nsrc)) ysrc = convertToCell(linspace(0f0, 0f0, nsrc)) zsrc = convertToCell(linspace(10f0, 10f0, nsrc)) # source sampling and number of time steps timeS = 1000f0 dtS = 2f0 # Set up source structure srcGeometry = Geometry(xsrc,ysrc,zsrc; dt=dtS, t=timeS) JUDI.TimeModeling.GeometryIC(Any[10.0, 118.889, 227.778, 336.667, 445.556, 554.444, 663.333, 772.222, 881.111, 990.0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]) Receiver geometry # Receievers reflection nrec = 50f0 xrec = linspace(10f0, 990f0, nrec) yrec = 0f0 zrec = linspace(10f0, 10f0, nrec) # source sampling and number of time steps timeR = 1000f0 dtR = 2f0 # Set up receiver structure recGeometry_reflection = Geometry(xrec,yrec,zrec;dt=dtR,t=timeR, nsrc=nsrc) # Receievers transmission nrec = 50f0 xrec = linspace(10f0, 990f0, nrec) yrec = 0f0 zrec = linspace(990f0, 990f0, nrec) # source sampling and number of time steps timeR = 1000f0 dtR = 2f0 # Set up receiver structure recGeometry_transmission = Geometry(xrec,yrec,zrec;dt=dtR,t=timeR, nsrc=nsrc) JUDI.TimeModeling.GeometryIC(Any[10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]) Optimization lbfgs (minConf_PQN here) can be used to solve optimization problems of the form: $\\min_{\\mathbf{m}}\\quad \\phi(\\mathbf{m})$ The method needs a function that calculates the misfit and gradient. The gradient of the LS misfit: $\\phi(\\mathbf{m}) = \\frac{1}{2}|F(\\mathbf{m}) {-} \\mathbf{d}|_2^2$ is given by $\\nabla\\phi(\\mathbf{m}) = J(\\mathbf{m})^*(F(\\mathbf{m}) {-} \\mathbf{d})$ where $J(\\mathbf{m})$ is the Jacobian matrix of $F$ and $^*# denotes the complex-conjugate-transpose (' in Julia). The Jacobian is provided by the modeling operator: J = judiJacobian(F, q) Write a julia function misfit(m) that returns the value of the misfit and the gradient for the given model m . minConf_SQP that function as an input Inversion In the following experiments we will vary acquisition setup to emulatate a reflection and a transmission experiment: Reflection setup: reflection_data.segy . Transmission setup: transmission_data.segy . define the function-handle as described above. define an initial model m0 by converting v0 to the proper units. use lbfgs| for a small amount of iterations (10, say). Compare the results of both experiments in terms of: reconstruction data-fit In order to obtain nice conergence use the following bound constraint Bound projection ProjBound(x) = boundproject(x, maximum(m), .9*minimum(m)) Setup # To setup the operator in for example the reflection case # setup wavelet f0 = 0.01f0 # 5 Hz wavelet wavelet = ricker_wavelet(timeS, dtS, f0) q = judiVector(srcGeometry, wavelet) # Set up info structure for linear operators ntComp = get_computational_nt(srcGeometry, recGeometry_reflection, model) info = Info(prod(n), nsrc, ntComp) JUDI.TimeModeling.Info(10201, 10, Any[596, 596, 596, 596, 596, 596, 596, 596, 596, 596]) F_r = judiModeling(info, model, srcGeometry, recGeometry_reflection) F_t = judiModeling(info, model, srcGeometry, recGeometry_transmission) JUDI.TimeModeling.judiPDEfull{Float32,Float32}(\"Proj*F*Proj'\", 250500, 5010, JUDI.TimeModeling.Info(10201, 10, Any[596, 596, 596, 596, 596, 596, 596, 596, 596, 596]), JUDI.TimeModeling.Model((101, 101), (10.0, 10.0), (0.0, 0.0), 40, Float32[0.16 0.16 \u2026 0.16 0.16; 0.16 0.16 \u2026 0.16 0.16; \u2026 ; 0.16 0.16 \u2026 0.16 0.16; 0.16 0.16 \u2026 0.16 0.16], 1), JUDI.TimeModeling.GeometryIC(Any[10.0, 118.889, 227.778, 336.667, 445.556, 554.444, 663.333, 772.222, 881.111, 990.0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]), JUDI.TimeModeling.GeometryIC(Any[10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]), JUDI.TimeModeling.Options(8, false, false, 1000.0, false, false, \"\", \"shot\", false, false, nothing, nothing, Any[], 1, false), JUDI.TimeModeling.#85, Nullable{Function}(JUDI.TimeModeling.#86)) d_trans = F_t * q JUDI.TimeModeling.judiVector{Float32}(\"Seismic data vector\", 250500, 1, 10, JUDI.TimeModeling.GeometryIC(Any[10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]), Array[Float32[0.0 0.0 \u2026 0.0 -0.0; -0.0 -0.0 \u2026 -0.0 0.0; \u2026 ; -0.264154 -0.289299 \u2026 0.226348 0.220771; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 0.0 \u2026 0.0 -0.0; 0.0 -0.0 \u2026 -0.0 0.0; \u2026 ; -0.149297 -0.0876982 \u2026 0.289633 0.307329; 0.0 0.0 \u2026 0.0 0.0], Float32[0.0 -0.0 \u2026 -0.0 -0.0; -0.0 0.0 \u2026 0.0 0.0; \u2026 ; 0.0364218 0.0267914 \u2026 0.200437 0.193765; 0.0 0.0 \u2026 0.0 0.0], Float32[0.0 0.0 \u2026 -0.0 -0.0; -0.0 -0.0 \u2026 0.0 0.0; \u2026 ; 0.133302 0.14125 \u2026 -0.0362351 -0.0663129; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 -0.0 \u2026 -0.0 0.0; 0.0 0.0 \u2026 0.0 -0.0; \u2026 ; 0.162256 0.161237 \u2026 0.0194431 0.0264048; 0.0 0.0 \u2026 0.0 0.0], Float32[0.0 -0.0 \u2026 -0.0 -0.0; -0.0 0.0 \u2026 0.0 0.0; \u2026 ; 0.0264062 0.0194453 \u2026 0.161238 0.162256; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 -0.0 \u2026 0.0 0.0; 0.0 0.0 \u2026 -0.0 -0.0; \u2026 ; -0.0663133 -0.0362352 \u2026 0.14125 0.133301; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 -0.0 \u2026 -0.0 0.0; 0.0 0.0 \u2026 0.0 -0.0; \u2026 ; 0.193767 0.200438 \u2026 0.0267931 0.0364229; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 0.0 \u2026 0.0 -0.0; 0.0 -0.0 \u2026 -0.0 0.0; \u2026 ; 0.307329 0.289633 \u2026 -0.0877006 -0.1493; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 0.0 \u2026 0.0 0.0; 0.0 -0.0 \u2026 -0.0 -0.0; \u2026 ; 0.22077 0.226348 \u2026 -0.2893 -0.264157; 0.0 0.0 \u2026 0.0 0.0]]) imshow(d_trans.data[10], vmin=-1, vmax=1, cmap=\"seismic\") PyObject <matplotlib.image.AxesImage object at 0x7fee6a3370b8> function f(x) # Update model model0.m = convert(Array{Float32, 2}, reshape(x, model0.n)) F0_t = judiModeling(info, model0, srcGeometry, recGeometry_transmission) J = judiJacobian(F0_t, q) # Synthetic data d_syn = F0_t*q # residual residual = d_syn - d_trans # Misfit f = .5*norm(residual)^2 # gradient grad = J'*residual return f, vec(grad) end f (generic function with 1 method) F0_t = judiModeling(info, model0, srcGeometry, recGeometry_transmission) J = judiJacobian(F0_t, q); dm = J'*d_trans 10201-element Array{Float32,1}: 4.39141 0.676352 0.361971 0.610117 -0.039682 -1.55511 -3.5738 -5.58581 -6.85017 -6.44537 -3.72911 1.01751 5.95766 \u22ee -3.40292 -2.88018 -1.61019 0.176336 1.71073 3.28438 3.77501 4.08856 3.4023 2.94257 2.24424 2.51696 imshow(d_trans.data[1], vmin=-1, vmax=1) PyObject <matplotlib.image.AxesImage object at 0x7fee68e88748> # invert options = pqn_options(verbose=3, maxIter=10, corrections=10) # Bound projection ProjBound(x) = boundproject(x, maximum(m), .9*minimum(m)) x, fsave, funEvals= minConf_PQN(f, vec(m0), ProjBound, options) Running PQN... Number of L-BFGS Corrections to store: 10 Spectral initialization of SPG: 0 Maximum number of SPG iterations: 10 SPG optimality tolerance: 1.00e-06 SPG progress tolerance: 1.00e-07 PQN optimality tolerance: 1.00e-05 PQN progress tolerance: 1.00e-07 Quadratic initialization of line search: 0 Maximum number of function evaluations: 10 Maximum number of projections: 100000 Iteration FunEvals Projections Step Length Function Val Opt Cond 1 2 4 5.91692e-04 2.33499e+05 3.00267e-01 Cubic Backtracking Interpolated value too small, Adjusting Cubic Backtracking Interpolated value too small, Adjusting Cubic Backtracking Interpolated value too small, Adjusting 2 6 11 1.00000e-09 2.33499e+05 3.00267e-01 Step size below progTol (Float32[0.444444, 0.444267, 0.444267, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444 \u2026 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444], [0.0, 2.33499e5, 2.33499e5], 6)","title":"Exercise 7 : Waveform inversion"},{"location":"Assignments/Exercise7/#exercise-7-waveform-inversion","text":"With waveform inversion we try to find the velocity model for which the modeled data optimally fits the observed data in a least-squares sense. Mathematically, we try to solve the following optimization problem: where is the modeling operator and is the observed data. Contents: - Camambert model - Modeling - Optimization - Inversion To illustrate some key properties of the waveform inversion problem, we are going to conduct some experiments on the famous 'Camambert' model.","title":"Exercise 7 : Waveform inversion"},{"location":"Assignments/Exercise7/#camambert-model","text":"The Camambert model consists of a circular perturbation, , superimposed on a homogeneous medium, , with velocity 2500 m/s. using JUDI.TimeModeling, JUDI.SLIM_optim, PyPlot, SeisIO # Velocity model # number of gridpoints n = (101, 101) # Grid spacing d = (10.0, 10.0) # Origin o = (0., 0.) x = zeros(n) z = zeros(n) for i in 0:100 x[i+1, :] = i*10 z[:, i+1] = i*10 end # vp = 2.5f0 * ones(Float32, n) vp[find(sqrt.((x-500).^2 +(z-500).^2) .<=250)]=3.0f0 m = 1f0./vp.^2f0 # v0 = 2.5f0 * ones(Float32, n) m0 = 1f0./v0.^2f0 imshow(m) PyObject <matplotlib.image.AxesImage object at 0x7fee6c4dca20> # Set up model structure w/ squared slowness model0 = Model(n, d, o, m0) model = Model(n, d, o, m) JUDI.TimeModeling.Model((101, 101), (10.0, 10.0), (0.0, 0.0), 40, Float32[0.16 0.16 \u2026 0.16 0.16; 0.16 0.16 \u2026 0.16 0.16; \u2026 ; 0.16 0.16 \u2026 0.16 0.16; 0.16 0.16 \u2026 0.16 0.16], 1)","title":"Camambert model:"},{"location":"Assignments/Exercise7/#source-geometry","text":"# Sources nsrc = 10 xsrc = convertToCell(linspace(10f0, 990f0, nsrc)) ysrc = convertToCell(linspace(0f0, 0f0, nsrc)) zsrc = convertToCell(linspace(10f0, 10f0, nsrc)) # source sampling and number of time steps timeS = 1000f0 dtS = 2f0 # Set up source structure srcGeometry = Geometry(xsrc,ysrc,zsrc; dt=dtS, t=timeS) JUDI.TimeModeling.GeometryIC(Any[10.0, 118.889, 227.778, 336.667, 445.556, 554.444, 663.333, 772.222, 881.111, 990.0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0])","title":"Source geometry"},{"location":"Assignments/Exercise7/#receiver-geometry","text":"# Receievers reflection nrec = 50f0 xrec = linspace(10f0, 990f0, nrec) yrec = 0f0 zrec = linspace(10f0, 10f0, nrec) # source sampling and number of time steps timeR = 1000f0 dtR = 2f0 # Set up receiver structure recGeometry_reflection = Geometry(xrec,yrec,zrec;dt=dtR,t=timeR, nsrc=nsrc) # Receievers transmission nrec = 50f0 xrec = linspace(10f0, 990f0, nrec) yrec = 0f0 zrec = linspace(990f0, 990f0, nrec) # source sampling and number of time steps timeR = 1000f0 dtR = 2f0 # Set up receiver structure recGeometry_transmission = Geometry(xrec,yrec,zrec;dt=dtR,t=timeR, nsrc=nsrc) JUDI.TimeModeling.GeometryIC(Any[10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0])","title":"Receiver geometry"},{"location":"Assignments/Exercise7/#optimization","text":"lbfgs (minConf_PQN here) can be used to solve optimization problems of the form: $\\min_{\\mathbf{m}}\\quad \\phi(\\mathbf{m})$ The method needs a function that calculates the misfit and gradient. The gradient of the LS misfit: $\\phi(\\mathbf{m}) = \\frac{1}{2}|F(\\mathbf{m}) {-} \\mathbf{d}|_2^2$ is given by $\\nabla\\phi(\\mathbf{m}) = J(\\mathbf{m})^*(F(\\mathbf{m}) {-} \\mathbf{d})$ where $J(\\mathbf{m})$ is the Jacobian matrix of $F$ and $^*# denotes the complex-conjugate-transpose (' in Julia). The Jacobian is provided by the modeling operator: J = judiJacobian(F, q) Write a julia function misfit(m) that returns the value of the misfit and the gradient for the given model m . minConf_SQP that function as an input","title":"Optimization"},{"location":"Assignments/Exercise7/#inversion","text":"In the following experiments we will vary acquisition setup to emulatate a reflection and a transmission experiment: Reflection setup: reflection_data.segy . Transmission setup: transmission_data.segy . define the function-handle as described above. define an initial model m0 by converting v0 to the proper units. use lbfgs| for a small amount of iterations (10, say). Compare the results of both experiments in terms of: reconstruction data-fit In order to obtain nice conergence use the following bound constraint","title":"Inversion"},{"location":"Assignments/Exercise7/#bound-projection","text":"ProjBound(x) = boundproject(x, maximum(m), .9*minimum(m))","title":"Bound projection"},{"location":"Assignments/Exercise7/#setup","text":"# To setup the operator in for example the reflection case # setup wavelet f0 = 0.01f0 # 5 Hz wavelet wavelet = ricker_wavelet(timeS, dtS, f0) q = judiVector(srcGeometry, wavelet) # Set up info structure for linear operators ntComp = get_computational_nt(srcGeometry, recGeometry_reflection, model) info = Info(prod(n), nsrc, ntComp) JUDI.TimeModeling.Info(10201, 10, Any[596, 596, 596, 596, 596, 596, 596, 596, 596, 596]) F_r = judiModeling(info, model, srcGeometry, recGeometry_reflection) F_t = judiModeling(info, model, srcGeometry, recGeometry_transmission) JUDI.TimeModeling.judiPDEfull{Float32,Float32}(\"Proj*F*Proj'\", 250500, 5010, JUDI.TimeModeling.Info(10201, 10, Any[596, 596, 596, 596, 596, 596, 596, 596, 596, 596]), JUDI.TimeModeling.Model((101, 101), (10.0, 10.0), (0.0, 0.0), 40, Float32[0.16 0.16 \u2026 0.16 0.16; 0.16 0.16 \u2026 0.16 0.16; \u2026 ; 0.16 0.16 \u2026 0.16 0.16; 0.16 0.16 \u2026 0.16 0.16], 1), JUDI.TimeModeling.GeometryIC(Any[10.0, 118.889, 227.778, 336.667, 445.556, 554.444, 663.333, 772.222, 881.111, 990.0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]), JUDI.TimeModeling.GeometryIC(Any[10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]), JUDI.TimeModeling.Options(8, false, false, 1000.0, false, false, \"\", \"shot\", false, false, nothing, nothing, Any[], 1, false), JUDI.TimeModeling.#85, Nullable{Function}(JUDI.TimeModeling.#86)) d_trans = F_t * q JUDI.TimeModeling.judiVector{Float32}(\"Seismic data vector\", 250500, 1, 10, JUDI.TimeModeling.GeometryIC(Any[10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]), Array[Float32[0.0 0.0 \u2026 0.0 -0.0; -0.0 -0.0 \u2026 -0.0 0.0; \u2026 ; -0.264154 -0.289299 \u2026 0.226348 0.220771; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 0.0 \u2026 0.0 -0.0; 0.0 -0.0 \u2026 -0.0 0.0; \u2026 ; -0.149297 -0.0876982 \u2026 0.289633 0.307329; 0.0 0.0 \u2026 0.0 0.0], Float32[0.0 -0.0 \u2026 -0.0 -0.0; -0.0 0.0 \u2026 0.0 0.0; \u2026 ; 0.0364218 0.0267914 \u2026 0.200437 0.193765; 0.0 0.0 \u2026 0.0 0.0], Float32[0.0 0.0 \u2026 -0.0 -0.0; -0.0 -0.0 \u2026 0.0 0.0; \u2026 ; 0.133302 0.14125 \u2026 -0.0362351 -0.0663129; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 -0.0 \u2026 -0.0 0.0; 0.0 0.0 \u2026 0.0 -0.0; \u2026 ; 0.162256 0.161237 \u2026 0.0194431 0.0264048; 0.0 0.0 \u2026 0.0 0.0], Float32[0.0 -0.0 \u2026 -0.0 -0.0; -0.0 0.0 \u2026 0.0 0.0; \u2026 ; 0.0264062 0.0194453 \u2026 0.161238 0.162256; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 -0.0 \u2026 0.0 0.0; 0.0 0.0 \u2026 -0.0 -0.0; \u2026 ; -0.0663133 -0.0362352 \u2026 0.14125 0.133301; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 -0.0 \u2026 -0.0 0.0; 0.0 0.0 \u2026 0.0 -0.0; \u2026 ; 0.193767 0.200438 \u2026 0.0267931 0.0364229; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 0.0 \u2026 0.0 -0.0; 0.0 -0.0 \u2026 -0.0 0.0; \u2026 ; 0.307329 0.289633 \u2026 -0.0877006 -0.1493; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 0.0 \u2026 0.0 0.0; 0.0 -0.0 \u2026 -0.0 -0.0; \u2026 ; 0.22077 0.226348 \u2026 -0.2893 -0.264157; 0.0 0.0 \u2026 0.0 0.0]]) imshow(d_trans.data[10], vmin=-1, vmax=1, cmap=\"seismic\") PyObject <matplotlib.image.AxesImage object at 0x7fee6a3370b8> function f(x) # Update model model0.m = convert(Array{Float32, 2}, reshape(x, model0.n)) F0_t = judiModeling(info, model0, srcGeometry, recGeometry_transmission) J = judiJacobian(F0_t, q) # Synthetic data d_syn = F0_t*q # residual residual = d_syn - d_trans # Misfit f = .5*norm(residual)^2 # gradient grad = J'*residual return f, vec(grad) end f (generic function with 1 method) F0_t = judiModeling(info, model0, srcGeometry, recGeometry_transmission) J = judiJacobian(F0_t, q); dm = J'*d_trans 10201-element Array{Float32,1}: 4.39141 0.676352 0.361971 0.610117 -0.039682 -1.55511 -3.5738 -5.58581 -6.85017 -6.44537 -3.72911 1.01751 5.95766 \u22ee -3.40292 -2.88018 -1.61019 0.176336 1.71073 3.28438 3.77501 4.08856 3.4023 2.94257 2.24424 2.51696 imshow(d_trans.data[1], vmin=-1, vmax=1) PyObject <matplotlib.image.AxesImage object at 0x7fee68e88748> # invert options = pqn_options(verbose=3, maxIter=10, corrections=10) # Bound projection ProjBound(x) = boundproject(x, maximum(m), .9*minimum(m)) x, fsave, funEvals= minConf_PQN(f, vec(m0), ProjBound, options) Running PQN... Number of L-BFGS Corrections to store: 10 Spectral initialization of SPG: 0 Maximum number of SPG iterations: 10 SPG optimality tolerance: 1.00e-06 SPG progress tolerance: 1.00e-07 PQN optimality tolerance: 1.00e-05 PQN progress tolerance: 1.00e-07 Quadratic initialization of line search: 0 Maximum number of function evaluations: 10 Maximum number of projections: 100000 Iteration FunEvals Projections Step Length Function Val Opt Cond 1 2 4 5.91692e-04 2.33499e+05 3.00267e-01 Cubic Backtracking Interpolated value too small, Adjusting Cubic Backtracking Interpolated value too small, Adjusting Cubic Backtracking Interpolated value too small, Adjusting 2 6 11 1.00000e-09 2.33499e+05 3.00267e-01 Step size below progTol (Float32[0.444444, 0.444267, 0.444267, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444 \u2026 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444], [0.0, 2.33499e5, 2.33499e5], 6)","title":"Setup"},{"location":"Assignments/introduction_to_julia/","text":"A quick introduction to the Julia language Getting started Start an interactive Julia session by running julia from the command line. You can quit the session with quit() . Generally, all functions in Julia are run using parenthesis, even if there are no input arguments. pwd() \"/home/philipp\" whos() Base Module Compat 19502 KB Module Core Module IJulia 19567 KB Module JSON 19384 KB Module Main Module MbedTLS 19412 KB Module Nullables 1120 bytes Module ZMQ 19357 KB Module You can define Julia scripts as regular text files that end with .jl and use your favourite text editor to code. Once you have your script, e.g.: hello-world.jl println(\"Hello world\") you can run the script with include(\"hello-world.jl\") . The Julia REPL REPL stands for Read/Evaluate/Print/Loop and refers to the interactive Julia session (it's just like a Matlab session). It's good for experimenting, but any serious coding should be done using scripts instead. 42 42 4 + 5 9 100 / 5; Unlike Matlab, you can access Julia's help functions by typing the question mark, followed by the function that you want the documention of: ? quit search: \u001b[1mq\u001b[22m\u001b[1mu\u001b[22m\u001b[1mi\u001b[22m\u001b[1mt\u001b[22m \u001b[1mQ\u001b[22m\u001b[1mu\u001b[22m\u001b[1mi\u001b[22mckSor\u001b[1mt\u001b[22m Partial\u001b[1mQ\u001b[22m\u001b[1mu\u001b[22m\u001b[1mi\u001b[22mckSor\u001b[1mt\u001b[22m \u001b[1mq\u001b[22m\u001b[1mu\u001b[22mant\u001b[1mi\u001b[22mle \u001b[1mq\u001b[22m\u001b[1mu\u001b[22mant\u001b[1mi\u001b[22mle! quit() Quit the program indicating that the processes completed successfully. This function calls exit(0) (see exit ). Similarly, you can enter the shell mode by typing ; , which gives you access to a full bash terminal. ; pwd /home/philipp In contrast to Matlab, Julia treats all operators as functions. This means you can add two numbers in either of the two ways: a = 4 + 5 9 a = +(4, 5) 9 The same applies for any other operations, such as subtraction, multiplications etc. Some math constants are defined in Julia by default, such as: print(pi) \u03c0 = 3.1415926535897... Julia was designed with the intend to write code that resembles mathematics as close as possible. For example, you can omit the multiplication operator when working with variables: x = 5 2x + 4 # which is the same as 2*x + 4 14 Just as Matlab, but different than Python, Julia comes with many built-in math functions that you would need for everyday use: sin(pi / 2) 1.0 log(100) 4.605170185988092 exp(4.3) 73.69979369959579 rand() 0.5282624241978122 Packages and Plotting Packages provide additional functionalities, that are not included in core Julia. Packages are written both by official Julia programmers, as well as anyone else who programs in Julia. Since native Julia does not include any plotting tools, we have to download a third-party package, such as PyPlot or Plots : Pkg.add(\"PyPlot\") \u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mInstalling JUDI v0.1.0 \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding Dierckx \u001b[39m make: Nothing to be done for `all'. \u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding Conda \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding PyCall \u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mPyCall is using /home/philipp/GATechBundle/Miniconda3/bin/python3 (Python 3.6.6) at /home/philipp/GATechBundle/Miniconda3/bin/python3, libpython = /home/philipp/GATechBundle/Miniconda3/lib/libpython3.6m \u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36m/home/philipp/.julia/v0.6/PyCall/deps/deps.jl has been updated \u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36m/home/philipp/.julia/v0.6/PyCall/deps/PYTHON has been updated \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPackage database updated \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mMETADATA is out-of-date \u2014 you may not have the latest version of PyPlot \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUse `Pkg.update()` to get the latest versions of your packages \u001b[39m Once you have downloaded a package, you can use it by typing: using PyPlot This plotting package is based off Python's Matplotlib package and therefore shares much of the Syntax. Some common plotting commands include: x = 1:100; f = x .^ 2; plot(x, f) 1-element Array{PyCall.PyObject,1}: PyObject <matplotlib.lines.Line2D object at 0x7f4b10781d30> A = randn(20,30); imshow(A, extent=[0,30,20,40]) PyObject <matplotlib.image.AxesImage object at 0x7f4b105585c0> Arrays and tuples Arrays are defined in a similar fashion to Matlab: x = [1, 2, 3, 4, 5] 5-element Array{Int64,1}: 1 2 3 4 5 As you can see from the output on the screen, Julia actually cares about types of variables and arrays. Since we defined our array as a collection of integers, the type of our array is `{Int64,1} y = [1., 2., 3., 4., 5.] 5-element Array{Float64,1}: 1.0 2.0 3.0 4.0 5.0 You can make a vector out of anything, not just numbers. For example, you can collect strings in a vector like this: s = [\"This\", \"is\", \"a\", \"string\", \"vector\"] 5-element Array{String,1}: \"This\" \"is\" \"a\" \"string\" \"vector\" s = [\"string\", 4.0, sin, pi] 4-element Array{Any,1}: \"string\" 4.0 sin \u03c0 = 3.1415926535897... Multi-dimensional arrays are formed as follows: A = [1 2 3 4; 5 6 7 8] 2\u00d74 Array{Int64,2}: 1 2 3 4 5 6 7 8 Note that entries of the same row are separated by spaces and rows are separated by ; You can also initialize vectors/matrices of a given dimension in various ways: B = zeros(4,5) 4\u00d75 Array{Float64,2}: 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 C = rand(2,3) 2\u00d73 Array{Float64,2}: 0.189405 0.938612 0.359612 0.553322 0.868266 0.102811 D = ones(4,2) 4\u00d72 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 Unlike Matlab, entries of matrices are accessed with square brackets, rather than parenthesis. Index counting starts at 1 (not 0). C[1,1] 0.1894051459813404 C[1,:] 3-element Array{Float64,1}: 0.189405 0.938612 0.359612 C[1,2:end] 2-element Array{Float64,1}: 0.938612 0.359612 Another useful structure, e.g. for plotting and loops, are range and linspace : r = 1:2:10 print(typeof(r)) StepRange{Int64,Int64} l = linspace(4,8.5, 7) print(typeof(l)) StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}} You can convert the vectors r and l to regular Julia arrays using the collect function: collect(r) 5-element Array{Int64,1}: 1 3 5 7 9 collect(l) 7-element Array{Float64,1}: 4.0 4.75 5.5 6.25 7.0 7.75 8.5 Similar to Matlab, it is possible to reshape arrays or stack multiple arrays to form new matrices: A = randn(3,4) 3\u00d74 Array{Float64,2}: 0.509555 -1.79653 0.842718 -0.713901 -0.0580305 0.609266 1.72787 -0.731359 0.10706 2.91134 -1.26744 -0.0453605 reshape(A, 4, 3) 4\u00d73 Array{Float64,2}: 0.509555 0.609266 -1.26744 -0.0580305 2.91134 -0.713901 0.10706 0.842718 -0.731359 -1.79653 1.72787 -0.0453605 vec(A) 12-element Array{Float64,1}: 0.509555 -0.0580305 0.10706 -1.79653 0.609266 2.91134 0.842718 1.72787 -1.26744 -0.713901 -0.731359 -0.0453605 B = [A; A] 6\u00d74 Array{Float64,2}: 0.509555 -1.79653 0.842718 -0.713901 -0.0580305 0.609266 1.72787 -0.731359 0.10706 2.91134 -1.26744 -0.0453605 0.509555 -1.79653 0.842718 -0.713901 -0.0580305 0.609266 1.72787 -0.731359 0.10706 2.91134 -1.26744 -0.0453605 One of the pitfalls of Julia is that assigning an array with the equal sign, does not copy the array, but creates a referece. A = ones(2,3) 2\u00d73 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 B = A 2\u00d73 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 A[1,:] = 2 println(A) [2.0 2.0 2.0; 1.0 1.0 1.0] show(B) [2.0 2.0 2.0; 1.0 1.0 1.0] To copy an array, use the copy function A = ones(2,3) 2\u00d73 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 B = copy(A) 2\u00d73 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 A[1,:] = 2 println(A) [2.0 2.0 2.0; 1.0 1.0 1.0] println(B) [1.0 1.0 1.0; 1.0 1.0 1.0] We see that B has not been changed! Some other differences between Matlab and Julia are min and max functions. These functions only return the min/max of two input variables: min(5,100) 5 To obtain the smallest/largest entry of a vector, use the minimum and maximum functions: x = [1,2,3,4,5,6] println(minimum(x)) println(maximum(x)) 1 6 Controll Flow Control flow in Julia, i.e. if/else statements, for loops or while loops, are similar to other programming languages. Here are some examples of different ways of controlling the flow: for j=1:2:8 println(j) end 1 3 5 7 for color in [\"red\", \"green\", \"blue\"] # an array print(color, \" \") end red green blue x = 10 while x > 1 x -= 1 println(x) end 9 8 7 6 5 4 3 2 1 name = \"Julia\" if name == \"Julia\" println(\"I like Julia\") elseif name == \"Python\" println(\"I like Python.\") println(\"But I prefer Julia.\") else println(\"I don't know what I like\") end I like Julia Functions Functions are a useful building block to structure your code and build subroutines etc. The most generic way to define functions in Julia is like this: function my_function(arg1, arg2) # do some work end my_function (generic function with 1 method) Functions can have any number of input arguments, including none: function breakfast() maketoast() brewcoffee() end breakfast (generic function with 1 method) By default, Julia functions always return the output from the last line of function. By using the return keyword, you can indicate a specific value that should be returned. function my_func(x, y) x_new = 2x y_new = 2y end z = my_func(3,4) 8 function my_func(x, y) return x_new = 2x y_new = 2y end z = my_func(3,4) 6 By grouping results as tuples, it is possible to return multiple variables: function my_func(x, y) x_new = 2x y_new = 2y return (x_new, y_new) end z = my_func(3,4) (6, 8)","title":"Introduction to julia"},{"location":"Assignments/introduction_to_julia/#a-quick-introduction-to-the-julia-language","text":"","title":"A quick introduction to the Julia language"},{"location":"Assignments/introduction_to_julia/#getting-started","text":"Start an interactive Julia session by running julia from the command line. You can quit the session with quit() . Generally, all functions in Julia are run using parenthesis, even if there are no input arguments. pwd() \"/home/philipp\" whos() Base Module Compat 19502 KB Module Core Module IJulia 19567 KB Module JSON 19384 KB Module Main Module MbedTLS 19412 KB Module Nullables 1120 bytes Module ZMQ 19357 KB Module You can define Julia scripts as regular text files that end with .jl and use your favourite text editor to code. Once you have your script, e.g.: hello-world.jl println(\"Hello world\") you can run the script with include(\"hello-world.jl\") .","title":"Getting started"},{"location":"Assignments/introduction_to_julia/#the-julia-repl","text":"REPL stands for Read/Evaluate/Print/Loop and refers to the interactive Julia session (it's just like a Matlab session). It's good for experimenting, but any serious coding should be done using scripts instead. 42 42 4 + 5 9 100 / 5; Unlike Matlab, you can access Julia's help functions by typing the question mark, followed by the function that you want the documention of: ? quit search: \u001b[1mq\u001b[22m\u001b[1mu\u001b[22m\u001b[1mi\u001b[22m\u001b[1mt\u001b[22m \u001b[1mQ\u001b[22m\u001b[1mu\u001b[22m\u001b[1mi\u001b[22mckSor\u001b[1mt\u001b[22m Partial\u001b[1mQ\u001b[22m\u001b[1mu\u001b[22m\u001b[1mi\u001b[22mckSor\u001b[1mt\u001b[22m \u001b[1mq\u001b[22m\u001b[1mu\u001b[22mant\u001b[1mi\u001b[22mle \u001b[1mq\u001b[22m\u001b[1mu\u001b[22mant\u001b[1mi\u001b[22mle! quit() Quit the program indicating that the processes completed successfully. This function calls exit(0) (see exit ). Similarly, you can enter the shell mode by typing ; , which gives you access to a full bash terminal. ; pwd /home/philipp In contrast to Matlab, Julia treats all operators as functions. This means you can add two numbers in either of the two ways: a = 4 + 5 9 a = +(4, 5) 9 The same applies for any other operations, such as subtraction, multiplications etc. Some math constants are defined in Julia by default, such as: print(pi) \u03c0 = 3.1415926535897... Julia was designed with the intend to write code that resembles mathematics as close as possible. For example, you can omit the multiplication operator when working with variables: x = 5 2x + 4 # which is the same as 2*x + 4 14 Just as Matlab, but different than Python, Julia comes with many built-in math functions that you would need for everyday use: sin(pi / 2) 1.0 log(100) 4.605170185988092 exp(4.3) 73.69979369959579 rand() 0.5282624241978122","title":"The Julia REPL"},{"location":"Assignments/introduction_to_julia/#packages-and-plotting","text":"Packages provide additional functionalities, that are not included in core Julia. Packages are written both by official Julia programmers, as well as anyone else who programs in Julia. Since native Julia does not include any plotting tools, we have to download a third-party package, such as PyPlot or Plots : Pkg.add(\"PyPlot\") \u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mInstalling JUDI v0.1.0 \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding Dierckx \u001b[39m make: Nothing to be done for `all'. \u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding Conda \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding PyCall \u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mPyCall is using /home/philipp/GATechBundle/Miniconda3/bin/python3 (Python 3.6.6) at /home/philipp/GATechBundle/Miniconda3/bin/python3, libpython = /home/philipp/GATechBundle/Miniconda3/lib/libpython3.6m \u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36m/home/philipp/.julia/v0.6/PyCall/deps/deps.jl has been updated \u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36m/home/philipp/.julia/v0.6/PyCall/deps/PYTHON has been updated \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPackage database updated \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mMETADATA is out-of-date \u2014 you may not have the latest version of PyPlot \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUse `Pkg.update()` to get the latest versions of your packages \u001b[39m Once you have downloaded a package, you can use it by typing: using PyPlot This plotting package is based off Python's Matplotlib package and therefore shares much of the Syntax. Some common plotting commands include: x = 1:100; f = x .^ 2; plot(x, f) 1-element Array{PyCall.PyObject,1}: PyObject <matplotlib.lines.Line2D object at 0x7f4b10781d30> A = randn(20,30); imshow(A, extent=[0,30,20,40]) PyObject <matplotlib.image.AxesImage object at 0x7f4b105585c0>","title":"Packages and Plotting"},{"location":"Assignments/introduction_to_julia/#arrays-and-tuples","text":"Arrays are defined in a similar fashion to Matlab: x = [1, 2, 3, 4, 5] 5-element Array{Int64,1}: 1 2 3 4 5 As you can see from the output on the screen, Julia actually cares about types of variables and arrays. Since we defined our array as a collection of integers, the type of our array is `{Int64,1} y = [1., 2., 3., 4., 5.] 5-element Array{Float64,1}: 1.0 2.0 3.0 4.0 5.0 You can make a vector out of anything, not just numbers. For example, you can collect strings in a vector like this: s = [\"This\", \"is\", \"a\", \"string\", \"vector\"] 5-element Array{String,1}: \"This\" \"is\" \"a\" \"string\" \"vector\" s = [\"string\", 4.0, sin, pi] 4-element Array{Any,1}: \"string\" 4.0 sin \u03c0 = 3.1415926535897... Multi-dimensional arrays are formed as follows: A = [1 2 3 4; 5 6 7 8] 2\u00d74 Array{Int64,2}: 1 2 3 4 5 6 7 8 Note that entries of the same row are separated by spaces and rows are separated by ; You can also initialize vectors/matrices of a given dimension in various ways: B = zeros(4,5) 4\u00d75 Array{Float64,2}: 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 C = rand(2,3) 2\u00d73 Array{Float64,2}: 0.189405 0.938612 0.359612 0.553322 0.868266 0.102811 D = ones(4,2) 4\u00d72 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 Unlike Matlab, entries of matrices are accessed with square brackets, rather than parenthesis. Index counting starts at 1 (not 0). C[1,1] 0.1894051459813404 C[1,:] 3-element Array{Float64,1}: 0.189405 0.938612 0.359612 C[1,2:end] 2-element Array{Float64,1}: 0.938612 0.359612 Another useful structure, e.g. for plotting and loops, are range and linspace : r = 1:2:10 print(typeof(r)) StepRange{Int64,Int64} l = linspace(4,8.5, 7) print(typeof(l)) StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}} You can convert the vectors r and l to regular Julia arrays using the collect function: collect(r) 5-element Array{Int64,1}: 1 3 5 7 9 collect(l) 7-element Array{Float64,1}: 4.0 4.75 5.5 6.25 7.0 7.75 8.5 Similar to Matlab, it is possible to reshape arrays or stack multiple arrays to form new matrices: A = randn(3,4) 3\u00d74 Array{Float64,2}: 0.509555 -1.79653 0.842718 -0.713901 -0.0580305 0.609266 1.72787 -0.731359 0.10706 2.91134 -1.26744 -0.0453605 reshape(A, 4, 3) 4\u00d73 Array{Float64,2}: 0.509555 0.609266 -1.26744 -0.0580305 2.91134 -0.713901 0.10706 0.842718 -0.731359 -1.79653 1.72787 -0.0453605 vec(A) 12-element Array{Float64,1}: 0.509555 -0.0580305 0.10706 -1.79653 0.609266 2.91134 0.842718 1.72787 -1.26744 -0.713901 -0.731359 -0.0453605 B = [A; A] 6\u00d74 Array{Float64,2}: 0.509555 -1.79653 0.842718 -0.713901 -0.0580305 0.609266 1.72787 -0.731359 0.10706 2.91134 -1.26744 -0.0453605 0.509555 -1.79653 0.842718 -0.713901 -0.0580305 0.609266 1.72787 -0.731359 0.10706 2.91134 -1.26744 -0.0453605 One of the pitfalls of Julia is that assigning an array with the equal sign, does not copy the array, but creates a referece. A = ones(2,3) 2\u00d73 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 B = A 2\u00d73 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 A[1,:] = 2 println(A) [2.0 2.0 2.0; 1.0 1.0 1.0] show(B) [2.0 2.0 2.0; 1.0 1.0 1.0] To copy an array, use the copy function A = ones(2,3) 2\u00d73 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 B = copy(A) 2\u00d73 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 A[1,:] = 2 println(A) [2.0 2.0 2.0; 1.0 1.0 1.0] println(B) [1.0 1.0 1.0; 1.0 1.0 1.0] We see that B has not been changed! Some other differences between Matlab and Julia are min and max functions. These functions only return the min/max of two input variables: min(5,100) 5 To obtain the smallest/largest entry of a vector, use the minimum and maximum functions: x = [1,2,3,4,5,6] println(minimum(x)) println(maximum(x)) 1 6","title":"Arrays and tuples"},{"location":"Assignments/introduction_to_julia/#controll-flow","text":"Control flow in Julia, i.e. if/else statements, for loops or while loops, are similar to other programming languages. Here are some examples of different ways of controlling the flow: for j=1:2:8 println(j) end 1 3 5 7 for color in [\"red\", \"green\", \"blue\"] # an array print(color, \" \") end red green blue x = 10 while x > 1 x -= 1 println(x) end 9 8 7 6 5 4 3 2 1 name = \"Julia\" if name == \"Julia\" println(\"I like Julia\") elseif name == \"Python\" println(\"I like Python.\") println(\"But I prefer Julia.\") else println(\"I don't know what I like\") end I like Julia","title":"Controll Flow"},{"location":"Assignments/introduction_to_julia/#functions","text":"Functions are a useful building block to structure your code and build subroutines etc. The most generic way to define functions in Julia is like this: function my_function(arg1, arg2) # do some work end my_function (generic function with 1 method) Functions can have any number of input arguments, including none: function breakfast() maketoast() brewcoffee() end breakfast (generic function with 1 method) By default, Julia functions always return the output from the last line of function. By using the return keyword, you can indicate a specific value that should be returned. function my_func(x, y) x_new = 2x y_new = 2y end z = my_func(3,4) 8 function my_func(x, y) return x_new = 2x y_new = 2y end z = my_func(3,4) 6 By grouping results as tuples, it is possible to return multiple variables: function my_func(x, y) x_new = 2x y_new = 2y return (x_new, y_new) end z = my_func(3,4) (6, 8)","title":"Functions"}]}