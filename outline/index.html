<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Topics - Imaging w/ data-driven models</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css">

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">Imaging w/ data-driven models</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem active">
                                <a href="./" class="nav-link">Topics</a>
                            </li>
                            <li class="navitem">
                                <a href="../homework/" class="nav-link">Assigments</a>
                            </li>
                            <li class="navitem">
                                <a href="../project/" class="nav-link">Projects</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" class="nav-link disabled">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../homework/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="2"><a href="#overview-a-sparse-tour-of-signal-processing" class="nav-link">Overview: a Sparse Tour of Signal Processing</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#signal-and-image-processing-with-orthogonal-decompositions" class="nav-link">Signal and Image Processing with Orthogonal Decompositions</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#fourier-processing" class="nav-link">Fourier Processing</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#wavelet-processing" class="nav-link">Wavelet Processing</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#approximation-with-orthogonal-decompositions" class="nav-link">Approximation with Orthogonal Decompositions</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#linear-and-nonlinear-denoising" class="nav-link">Linear and Nonlinear Denoising</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#variational-regularization-of-inverse-problems" class="nav-link">Variational Regularization of Inverse Problems</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#sparse-regularization-of-inverse-problems" class="nav-link">Sparse Regularization of Inverse Problems</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#compressive-sensing" class="nav-link">Compressive Sensing</a>
              <ul class="nav flex-column">
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h2 id="overview-a-sparse-tour-of-signal-processing">Overview: a Sparse Tour of Signal Processing</h2>
<hr />
<h2 id="signal-and-image-processing-with-orthogonal-decompositions">Signal and Image Processing with Orthogonal Decompositions</h2>
<ul>
<li>Continuous signals and images</li>
<li>Orthogonal representations</li>
<li>
<p>decomposition</p>
<ul>
<li>energy conservation (Parseval)</li>
<li>Fourier and wavelets</li>
<li>2D wavelet transform</li>
</ul>
</li>
<li>
<p>Linear and nonlinear approximations</p>
<ul>
<li>filtering</li>
<li>thresholding</li>
<li>compressibility and its relation to smoothness</li>
</ul>
</li>
<li>
<p>Denoising and inverse problems</p>
<ul>
<li>signal model</li>
<li>recovery by sparsity promotion</li>
</ul>
</li>
</ul>
<h3 id="reading-material">Reading material</h3>
<p>Chapter 1 from <a href="https://www.dropbox.com/s/5pd1nec1cf7e2b4/AdvancedSignalProcessingNew.pdf?dl=0">Advanced Signal, Image and Surface Processing</a></p>
<h3 id="slides">Slides</h3>
<p><a href="https://www.dropbox.com/s/efy6fghhip6y7ko/1-course-signal-orthobases-new.pdf?dl=0">Signal and Image Decomposition in Orthogonal Bases</a> adapted from <a href="https://mathematical-tours.github.io/slides/">here</a>.</p>
<h3 id="recordings">Recordings</h3>
<ul>
<li>
<p><a href="https://gtvault.sharepoint.com/:v:/r/sites/Imagingwdata-drivenmodelsCSE8803/Shared%20Documents/General/Recordings/Meeting%20in%20_General_-20220111_135930-Meeting%20Recording.mp4?csf=1&amp;web=1&amp;e=iVhGLL">Recording for Lecture 1</a></p>
</li>
<li>
<p><a href="https://gtvault.sharepoint.com/:v:/r/sites/Imagingwdata-drivenmodelsCSE8803/Shared%20Documents/General/Recordings/Meeting%20in%20_General_-20220113_135959-Meeting%20Recording.mp4?csf=1&amp;web=1&amp;e=If085B">Recording for Lecture 2</a></p>
</li>
<li>
<p><a href="https://gtvault.sharepoint.com/:v:/r/sites/Imagingwdata-drivenmodelsCSE8803/Shared%20Documents/General/Recordings/Meeting%20in%20_General_-20220118_135748-Meeting%20Recording.mp4?csf=1&amp;web=1&amp;e=UydDQV">Recording for Lecture 3</a></p>
</li>
<li>
<p><a href="https://gtvault.sharepoint.com/:v:/r/sites/Imagingwdata-drivenmodelsCSE8803/Shared%20Documents/General/Recordings/Meeting%20in%20_General_-20220125_135818-Meeting%20Recording.mp4?csf=1&amp;web=1&amp;e=Ce6ANU">Recording for Lecture 5</a></p>
</li>
<li>
<p><a href="https://gtvault.sharepoint.com/:v:/r/sites/Imagingwdata-drivenmodelsCSE8803/Shared%20Documents/General/Recordings/Meeting%20in%20_General_-20220127_135912-Meeting%20Recording.mp4?csf=1&amp;web=1&amp;e=aqTBsJ">Recording for Lecture 6</a></p>
</li>
<li>
<p><a href="https://gtvault.sharepoint.com/:v:/r/sites/Imagingwdata-drivenmodelsCSE8803/Shared%20Documents/General/Recordings/Meeting%20in%20_General_-20220201_135838-Meeting%20Recording.mp4?csf=1&amp;web=1&amp;e=ujaR71">Recording for Lecture 7</a></p>
</li>
<li>
<p><a href="https://gtvault.sharepoint.com/:v:/r/sites/Imagingwdata-drivenmodelsCSE8803/Shared%20Documents/General/Recordings/New%20channel%20meeting-20220203_135918-Meeting%20Recording.mp4?csf=1&amp;web=1&amp;e=RKoFI9">Recording for Lecture 8</a></p>
</li>
<li>
<p><a href="https://gtvault.sharepoint.com/:v:/r/sites/Imagingwdata-drivenmodelsCSE8803/Shared%20Documents/General/Recordings/Meeting%20in%20_General_-20220208_135827-Meeting%20Recording.mp4?csf=1&amp;web=1&amp;e=TOlmLs">Recording for Lecture 9</a></p>
</li>
</ul>
<hr />
<h2 id="fourier-processing">Fourier Processing</h2>
<ul>
<li>Continuous/discrete Fourier basis</li>
<li>Sampling</li>
<li>2D Fourier transform</li>
<li>Fourier Approximation</li>
</ul>
<h3 id="reading-material_1">Reading material</h3>
<p>Chapter 2 from <a href="https://www.dropbox.com/s/5pd1nec1cf7e2b4/AdvancedSignalProcessingNew.pdf?dl=0">Advanced Signal, Image and Surface Processing</a>. If you want more detail read <a href="https://mathematical-tours.github.io/book-sources/chapters-pdf/fourier.pdf">Fourier Transforms</a> from <a href="https://mathematical-tours.github.io/book/">Mathematical Foundations of Data Sciences</a>.</p>
<h3 id="assignments">Assignments</h3>
<p>See <a href="../homework/">assignment</a> tab.</p>
<h3 id="slides_1">Slides</h3>
<p><a href="https://www.dropbox.com/s/kbezzvt4b7ggh1z/2-course-signal-fourier-new.pdf?dl=0">Fourier Processing</a> adapted from <a href="https://mathematical-tours.github.io/slides/">here</a>.</p>
<hr />
<h2 id="wavelet-processing">Wavelet Processing</h2>
<ul>
<li>1D Multiresolutions</li>
<li>detail spaces<ul>
<li>Haar wavelets</li>
</ul>
</li>
<li>1D Wavelet transform<ul>
<li>computing wavelet coefficients</li>
<li>discrete wavelet coefficients</li>
<li>fast wavelet transform
-inverse transform</li>
</ul>
</li>
<li>Filter banks<ul>
<li>approximation filter</li>
<li>detail filter</li>
<li>vanishing moments</li>
<li>Daubechies wavelets</li>
</ul>
</li>
<li>Extension to 2D
    -anisotropic wavelets<ul>
<li>2D multiresolutions</li>
<li>2D wavelet bases</li>
<li>2D discrete wavelet coefficients</li>
<li>fast 2D wavelet transform</li>
</ul>
</li>
</ul>
<h3 id="reading-material_2">Reading material</h3>
<p>Chapter 3 from <a href="https://www.dropbox.com/s/5pd1nec1cf7e2b4/AdvancedSignalProcessingNew.pdf?dl=0">Advanced Signal, Image and Surface Processing</a>. If you want more detail read <a href="https://mathematical-tours.github.io/book/">Wavelets</a> from <a href="https://mathematical-tours.github.io/book/">Mathematical Foundations of Data Sciences</a>.</p>
<h3 id="assignments_1">Assignments</h3>
<p>See <a href="../homework/">assignment</a> tab.</p>
<h3 id="slides_2">Slides</h3>
<p><a href="https://www.dropbox.com/s/wudhbew83lamxfg/3-course-signal-wavelets-new.pdf?dl=0">Wavelet Processing</a> adapted from <a href="https://mathematical-tours.github.io/slides/">here</a>.</p>
<hr />
<h2 id="approximation-with-orthogonal-decompositions">Approximation with Orthogonal Decompositions</h2>
<ul>
<li>Linear and nonlinear approximations<ul>
<li>Sparse approximation in a basis</li>
<li>hard thresholding</li>
<li>decay of approximation errors (linear vs. nonlinear)</li>
<li>Relation between decay rate coefficients and approximation error</li>
<li>Fourier for smooth functions</li>
<li>Fourier and singularities/edges</li>
</ul>
</li>
<li>wavelet transform for peice-wise 1D smooth functions<ul>
<li>vanishing moments</li>
<li>magnitude of wavelet coefficients and its relation to edges</li>
<li>decay and nonlinear approximation error for piece-wise 1D functions</li>
</ul>
</li>
<li>Piece-wise smooth 2D functions<ul>
<li>2D approximations
-decay and nonlinear approximation error for piece-wise 2D functions</li>
</ul>
</li>
<li>Geometrically regular functions<ul>
<li>space of BV functions</li>
<li>finite elements</li>
<li>curvelets, their construction, and properties</li>
</ul>
</li>
</ul>
<h3 id="reading-material_3">Reading material</h3>
<p>Chapter 4 from <a href="https://www.dropbox.com/s/5pd1nec1cf7e2b4/AdvancedSignalProcessingNew.pdf?dl=0">Advanced Signal, Image and Surface Processing</a>. If you want more detail read <a href="https://mathematical-tours.github.io/book-sources/chapters-pdf/approximation.pdf">Linear and Non-linear Approximation</a> from <a href="https://mathematical-tours.github.io/book/">Mathematical Foundations of Data Sciences</a>.</p>
<h3 id="assignments_2">Assignments</h3>
<p>See <a href="../homework/">assignment</a> tab.</p>
<h3 id="slides_3">Slides</h3>
<p><a href="https://www.dropbox.com/s/2wa1nwecas2pykj/4-course-signal-approximation.pdf?dl=0">Approximation and Coding with Orthogonal Decompositions</a> adapted from <a href="https://mathematical-tours.github.io/slides/">here</a>.</p>
<hr />
<h2 id="linear-and-nonlinear-denoising">Linear and Nonlinear Denoising</h2>
<ul>
<li>Linear denoising</li>
<li>additative noise model<ul>
<li>linear denoising by smoothing</li>
<li>Wiener filter and oracle estimation of optimal filter</li>
</ul>
</li>
<li>Nonlinear denoising<ul>
<li>hard thresholding</li>
<li>optimal threshold selection</li>
<li>nonlinear approximation and estimation</li>
<li>hard vs. soft thresholding</li>
</ul>
</li>
<li>Translational invariant thresholding<ul>
<li>translation invariant wavelets</li>
<li>optimal threshold</li>
</ul>
</li>
<li>Other diagonal estimators<ul>
<li>between hard and soft thresholding</li>
</ul>
</li>
<li>Non-diagonal estimators<ul>
<li>block thresholding</li>
</ul>
</li>
</ul>
<h3 id="reading-material_4">Reading material</h3>
<p>Chapter 5 from <a href="https://www.dropbox.com/s/5pd1nec1cf7e2b4/AdvancedSignalProcessingNew.pdf?dl=0">Advanced Signal, Image and Surface Processing</a>. If you want more detail read <a href="https://mathematical-tours.github.io/book-sources/chapters-pdf/denoising.pdf">Denoising</a> from <a href="https://mathematical-tours.github.io/book/">Mathematical Foundations of Data Sciences</a>.</p>
<h3 id="assignments_3">Assignments</h3>
<p>See <a href="../homework/">assignment</a> tab.</p>
<h3 id="slides_4">Slides</h3>
<p><a href="https://www.dropbox.com/s/xhpr4a4e60v7c9k/5-course-signal-denoising-new.pdf?dl=0">Linear and nonlinear denoising</a> adapted from <a href="https://mathematical-tours.github.io/slides/">here</a>.</p>
<hr />
<h2 id="variational-regularization-of-inverse-problems">Variational Regularization of Inverse Problems</h2>
<ul>
<li>Variational priors</li>
<li>smooth and cartoon<ul>
<li>natural image priors</li>
<li>discretization</li>
</ul>
</li>
<li>Variational regularization<ul>
<li>regularized inverse</li>
<li>pseudo inverse</li>
<li>Sobolev regularization and inpainting</li>
<li>total variation regularization and inpainting</li>
</ul>
</li>
<li>Example from tomography with the Radon transform</li>
</ul>
<h3 id="reading-material_5">Reading material</h3>
<p>Chapter 6 from <a href="https://www.dropbox.com/s/5pd1nec1cf7e2b4/AdvancedSignalProcessingNew.pdf?dl=0">Advanced Signal, Image and Surface Processing</a>. If you want more detail read <a href="https://mathematical-tours.github.io/book-sources/chapters-pdf/variational-priors.pdf">Variational Priors and Regularization</a> from <a href="https://mathematical-tours.github.io/book/">Mathematical Foundations of Data Sciences</a>.</p>
<h3 id="assignments_4">Assignments</h3>
<p>See <a href="../homework/">assignment</a> tab.</p>
<h3 id="slides_5">Slides</h3>
<p><a href="https://www.dropbox.com/s/let9p1m16hyiqzj/6-course-signal-inverse-pbm-variational-new.pdf?dl=0">Inverse problems Regularization</a> adapted from <a href="https://mathematical-tours.github.io/slides/">here</a>.</p>
<hr />
<h2 id="sparse-regularization-of-inverse-problems">Sparse Regularization of Inverse Problems</h2>
<ul>
<li>Linear inverse problems<ul>
<li>denoising</li>
<li>inpainting</li>
<li>super- resolution</li>
</ul>
</li>
<li>Regularization of inverse problems<ul>
<li>regularized inverse</li>
<li>Lagrangian formulation including the the Lagrange multiplier/trade-off parameter lambda</li>
<li>smooth and cartoon priors</li>
</ul>
</li>
<li>Redundant dictionaries</li>
<li>Sparse priors<ul>
<li>convex relaxation of the $\ell_0-norm$ via the $\ell_1$-norm</li>
<li>$\ell_1$-regularization and sparse recovery</li>
<li>noise-free sparsity-promoting regularization</li>
</ul>
</li>
<li>Iterative soft thresholding</li>
</ul>
<h3 id="reading-material_6">Reading material</h3>
<p>Chapter 7 from <a href="https://www.dropbox.com/s/5pd1nec1cf7e2b4/AdvancedSignalProcessingNew.pdf?dl=0">Advanced Signal, Image and Surface Processing</a>. If you want more detail read <a href="https://mathematical-tours.github.io/book-sources/chapters-pdf/inverse-problems.pdf">Inverse Problems</a> and <a href="https://mathematical-tours.github.io/book-sources/chapters-pdf/sparse-regularization.pdf">Sparse Regularization</a> from <a href="https://mathematical-tours.github.io/book/">Mathematical Foundations of Data Sciences</a>.</p>
<p>Assignments
See <a href="../homework/">assignment</a> tab.</p>
<h3 id="slides_6">Slides</h3>
<p><a href="https://www.dropbox.com/s/idl446ja701xloe/7-course-signal-inverse-pbm-sparse-new.pdf?dl=0">Sparse regularization of Inverse Problems</a> adapted from <a href="https://mathematical-tours.github.io/slides/">here</a>.</p>
<hr />
<h2 id="compressive-sensing">Compressive Sensing</h2>
<ul>
<li>Classical sampling</li>
<li>discretization<ul>
<li>point-wise sampling and smoothness</li>
</ul>
</li>
<li>Compressive acquisition<ul>
<li>examples single pixel camera</li>
<li>physical model</li>
</ul>
</li>
<li>Inversion and sparsity<ul>
<li>$\ell_1$ prior</li>
<li>sparse CS recovery</li>
</ul>
</li>
<li>Theoretical guarantees<ul>
<li>CS with restricted isometry constants (RIP)</li>
<li>singular-value distributions</li>
<li>RIP for Gaussian matrices</li>
<li>numerics with RIP</li>
</ul>
</li>
<li>Fourier measurements<ul>
<li>MRI imaging</li>
<li>radar interferometry</li>
<li>structured measurements</li>
</ul>
</li>
</ul>
<h3 id="assignments_5">Assignments</h3>
<p>See <a href="../homework/">assignment</a> tab.</p>
<h3 id="reading-material_7">Reading material</h3>
<p><a href="https://mathematical-tours.github.io/book-sources/chapters-pdf/compressed-sensing.pdf">Compressive Sensing Chapter</a> from <a href="https://mathematical-tours.github.io/book/">Mathematical Foundations of Data Sciences</a>.</p>
<h3 id="slides_7">Slides</h3>
<p><a href="https://www.dropbox.com/s/r4vs627jdyqfcnj/8-course-signal-compressive-sensing-new.pdf?dl=0">Compressive Sensing</a> adapted from <a href="https://mathematical-tours.github.io/slides/">here</a>.</p>
<hr />
<h3 id="statistical-regularization">Statistical Regularization</h3>
<p>The review article <a href="https://www.cambridge.org/core/journals/acta-numerica/article/solving-inverse-problems-using-datadriven-models/CE5B3725869AEAF46E04874115B0AB15">Solving inverse problems using data-driven models</a> serves as the major reading material. For a mathematical description of the February 6 and 11 lectures, refer to pages 22 till 43 from this article. </p>
<h3 id="learning-in-functional-analytic-regularization">Learning in Functional Analytic Regularization</h3>
<p>During the lecture of February 13, we start by considering section 5.1.2 Deep direct Bayes estimation on page 84 of <a href="https://www.cambridge.org/core/journals/acta-numerica/article/solving-inverse-problems-using-datadriven-models/CE5B3725869AEAF46E04874115B0AB15">Solving inverse problems using data-driven models</a> untile Regularization by learning. We continue with section Deep direct estimation of higher-order moments on page 99. Next, we consider loop unrolling described in section 4.9 Data-driven optimization on page 66 until section 4.10 and later in section 5.1.4 Learned iterative schemes on page 89 until section 5.1.5. The supervised training, learned prior/regularizer, unsupervised learning, and semi-supervised learning are briefly introduced in section 5.1 Learning an estimator on page 82. </p>
<h3 id="learning-in-statistical-regularization">Learning in Statistical Regularization</h3>
<h3 id="slides_8">Slides</h3>
<p>We use a combination of slides developed mainly by Ozan Oktem and <a href="https://jonasadler.com">Jonas Adler</a> and others. The slides presented in class can be found <a href="https://www.dropbox.com/s/j6b5d0njmb7hzsj/Oktem.pdf?dl=0">here</a>. </p>
<hr />
<h3 id="papers">Papers</h3>
<ul>
<li>
<p><a href="https://arxiv.org/pdf/1510.06188.pdf">Learning-Based Compressive Subsampling</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1712.02862.pdf">MoDL: Model Based Deep Learning Architecture for Inverse Problems</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1805.01266.pdf">Learning-Based Compressive MRI</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1901.11158.pdf">NETT Regularization for Compressed Sensing Photoacoustic Tomography</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1812.10907.pdf">Divergence Triangle for Joint Training of Generator Model, Energy-based Model, and Inference Model</a></p>
</li>
<li>
<p><a href="https://papers.nips.cc/paper/8130-a-stein-variational-newton-method.pdf">A Stein variational Newton method</a></p>
</li>
<li>
<p><a href="https://papers.nips.cc/paper/7892-neural-ordinary-differential-equations.pdf">Neural Ordinary Differential Equations</a></p>
</li>
<li>
<p><a href="https://papers.nips.cc/paper/8336-invert-to-learn-to-invert.pdf">Invert to Learn to Invert</a></p>
</li>
<li>
<p><a href="https://www.ics.uci.edu/~welling/publications/papers/Submitted2016-RIM.pdf">Recurrent Inference Machines for Solving Inverse Problems</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1708.09832.pdf">Model based learning for accelerated, limited-view 3D photoacoustic tomography</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1908.00936.pdf">Multi-Scale Learned Iterative Reconstruction</a></p>
</li>
<li>
<p><a href="https://ris.utwente.nl/ws/portalfiles/portal/103725020/Boink_et_al._2018_Sensitivity_of_a_partially_learned_model_based_reconstruction_algorithm.pdf">Sensitivity of a partially learned model-based reconstruction algorithm</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1906.03742.pdf">Degrees of Freedom Analysis of Unrolled Neural Networks</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1706.00051.pdf">Deep Generative Adversarial Neural Networks for Compressive Sensing MRI</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1704.04058.pdf">Solving ill-posed inverse problems using iterative deep neural networks</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1707.06474.pdf">Learned primal-dual reconstruction</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1710.10898.pdf">Learning to solve inverse problems using Wasserstein loss</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1811.05910.pdf">Deep bayesian inversion</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1412.5492.pdf">Transport map accelerated Markov chain Monte Carlo</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1808.09379.pdf">A transport-based multifidelity preconditioner for Markov chain Monte Carlo</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1907.02392.pdf">Guided Image Generation with Conditional Invertible Neural Networks</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1902.09698.pdf">GAN-based Projector for Faster Recovery with Convergence Guarantees in Linear Inverse Problems</a></p>
</li>
<li>
<p><a href="https://arxiv.org/abs/1802.08406">Solving Linear Inverse Problems Using GAN Priors: An Algorithm with Provable Guarantees</a></p>
</li>
<li>
<p><a href="https://arxiv.org/abs/1910.10797">Low Shot Learning with Untrained Neural Networks for Imaging Inverse Problems</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1806.03720.pdf">Stochastic Seismic Waveform Inversion using Generative Adversarial Networks as a Geological Prior</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1910.10046.pdf">Uncertainty Quantification with Generative Models</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1907.09987.pdf">Bayesian Inference with Generative Adversarial Network Priors</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1904.07457.pdf">A Bayesian Perspective on the Deep Image Prior</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1904.06264v2.pdf">Variational Inference for Computational Imaging Inverse Problems</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1903.10176.pdf">DeepRED: Deep Image Prior Powered by RED</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1906.08763.pdf">Algorithmic Guarantees for Inverse Imaging with Untrained Network Priors</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1811.04026.pdf">Adversarial Uncertainty Quantification in Physics-Informed Neural Networks</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1905.10687.pdf">HINT: Hierarchical Invertible Neural Transport for General and Sequential Bayesian inference</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1808.04730.pdf">Analyzing Inverse Problems with Invertible Neural Networks</a></p>
</li>
</ul>
<hr />
<h3 id="general-information-generative-neural-networks">General information generative neural networks</h3>
<h4 id="slides-on-generative-models">Slides on generative models</h4>
<ul>
<li>
<p><a href="http://www.yisongyue.com/courses/cs155/2019_winter/lectures/Lecture_16.pdf">Lecture on Deep Generative Models by Joe Marino</a> - <a href="https://www.youtube.com/watch?v=Sb6RQfG-QQM">Video</a></p>
</li>
<li>
<p><a href="https://www.shakirm.com/slides/DeepGenModelsTutorial.pdf">Tutorial on Deep Generative Models by DeepMind</a></p>
</li>
<li>
<p><a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/03/Nowozin-Deep-Generative-Models-60-Minutes.pdf">Probabilistic Deep Learning by Microsoft</a></p>
</li>
<li>
<p><a href="http://www.cs.toronto.edu/~rsalakhu/Lecture1.pdf">Lecture on Learning Deep Generative Models by Russ Salakhutdinov</a></p>
</li>
</ul>
<h4 id="ingredients-of-convolutional-neural-networks">Ingredients of convolutional neural networks</h4>
<ul>
<li>
<p><a href="http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/slides/lec11.pdf">Lecture on Convolutional Networks by Roger Grosse</a></p>
</li>
<li>
<p><a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture5.pdf">Lecture on Convolutional Networks by Fei-Fei Li</a></p>
</li>
<li>
<p>Lectures (<a href="https://github.com/rasbt/stat479-deep-learning-ss19/blob/master/L13_intro-cnn/L13_intro-cnn-part1_slides.pdf">Part 1</a>, <a href="https://github.com/rasbt/stat479-deep-learning-ss19/blob/master/L13_intro-cnn/L13_intro-cnn-part2_slides.pdf">Part 2</a>, <a href="https://github.com/rasbt/stat479-deep-learning-ss19/blob/master/L13_intro-cnn/L13_intro-cnn-part3_slides.pdf">Part 3</a>) on Convolutional Neural Networks by Sebastian Raschka</p>
</li>
<li>
<p><a href="https://github.com/vdumoulin/conv_arithmetic">Visual guide to convolution arithmetic in the context of deep learning</a>, and <a href="https://arxiv.org/pdf/1603.07285.pdf">associated paper</a></p>
</li>
</ul>
<h4 id="tutorials-and-codes">Tutorials and codes</h4>
<ul>
<li>
<p><a href="https://poloclub.github.io/ganlab/">GAN lab, an interactive visualization for playing with GANs</a></p>
</li>
<li>
<p><a href="https://github.com/rasbt/deeplearning-models">A collection of various deep learning architectures, in TensorFlow and PyTorch (Jupyter Notebooks), by Sebastian Raschka</a></p>
</li>
<li>
<p><a href="https://github.com/wiseodd/generative-models">Super simple implementations of generative models in PyTorch and TensorFlow</a> along with related <a href="https://wiseodd.github.io/">blog posts</a></p>
</li>
<li>
<p><a href="https://github.com/znxlwm/pytorch-generative-model-collections">Collection of generative models in PyTorch</a></p>
</li>
<li>
<p><a href="https://github.com/hwalsuklee/tensorflow-generative-model-collections">Collection of generative models in TensorFlow</a></p>
</li>
</ul>
<h4 id="useful-other-material">Useful other material</h4>
<ul>
<li>
<p><a href="http://pages.stat.wisc.edu/~sraschka/teaching/stat479-ss2019/">Deep Learning course - Sebastian Raschka</a></p>
</li>
<li>
<p><a href="http://www.yisongyue.com/courses/cs155/2019_winter/">Machine Learning &amp; Data Mining course by Yisong Yue</a></p>
</li>
<li>
<p><a href="http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2020/">Introduction to Deep Learning and Generative Models course - Sebastian Raschka (Spring 2020)</a></p>
</li>
<li>
<p><a href="http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/">Intro to Neural Networks and Machine Learning course - Roger Grosse</a></p>
</li>
<li>
<p><a href="http://www.cs.toronto.edu/~rgrosse/courses/csc421_2019/">Neural Networks and Deep Learning course - Roger Grosse</a></p>
</li>
<li>
<p><a href="https://courses.engr.illinois.edu/ece598id/sp2019/">Inverse Problems and Learning course - Ivan Dokmanic</a></p>
</li>
<li>
<p><a href="https://arxiv.org/abs/1807.03341">Troubling Trends in Machine Learning Scholarship</a></p>
</li>
</ul>
<p>[assignment]:</p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
