{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Imaging w/ data-driven models \u2013 CSE 8803 Instructor Felix J. Herrmann Phone: +1 (404) 385-7069 CODA, room S1375B Time and Location Tuesday/Thursday 2:00 pm - 3:15 pm, Engineering Sci and Mechanics rm 201 Office Hours: by appointment via Microsoft Teams Course Description This course concerns inverse problems as they relate to imaging. After reviewing techniques from Compressive Sensing , Sparse Approximation , and Convex Optimization by means of lectures based on Mathematical Foundations of Data Sciences and computational assignments from Numerical Tours of Data Sciences (in Matlab , Python , Julia , or R ), the course shifts towards the state of the art of \"Imaging w/ data-driven models\" as outlined in the review article Solving inverse problems using data-driven models and the references therein. Special emphasis will be given to Bayesian Inference with Normalizing Flows, a special type of invertible neural networks. The latter forms an important development since it alows for capturing uncertainty via distribution learning. The reviewed techniques are of interest to areas in Computational Science and Engineering where data is incomplete, noisy, and observed indirectly. Topics See Topics tab (adapted from Mathematical Foundations of Data Sciences and Solving inverse problems using data-driven models ) Overview: a Sparse Tour of Signal Processing Signal and Image Processing with Orthogonal Decompositions Fourier Processing Wavelet Processing Approximation with Orthogonal Decompositions Linear and Non-linear Denoising Variational Regularization of Inverse Problems Sparse Regularization of Inverse Problems Compressive Sensing Statistical Regularization Learning in Functional Analytic Regularization Learning in Statistical Regularization COVID Georgia Tech is committed to promoting a campus community that supports holistic well-being, as well as empowering students to make choices that enable positive health outcomes. As we continue to live and learn through a pandemic, Georgia Tech strongly encourages students to utilize several tools not only to reduce their own risks of infection from Covid-19, but also to help reduce the overall levels of transmission in the community. These tools include: Getting fully vaccinated. Getting vaccinated at Tech is easy and free. Wearing face coverings consistently in all indoor settings and also in outdoor settings when in close proximity to others. Getting tested on a regular basis, regardless of whether you are vaccinated or asymptomatic. No appointment is needed for Georgia Tech\u2019s asymptomatic testing, and it is free. Avoiding touching your face until you have cleaned your hands with soap and water or used hand sanitizer. Immediately self-quarantining or self-isolating if you experience any symptoms that could be related to Covid-19 or if you have tested positive for Covid-19. Additional information and resources are available on the Tech Moving Forward website . Information Related to Covid-19 Students are expected to be familiar with and abide by the Institute guidelines, information, and updates related to Covid-19. Find campus operational updates, Frequently Asked Questions, and details on campus surveillance testing and vaccine appointments on the Tech Moving Forward website . Recordings of Class Sessions and Required Permissions Classes may not be recorded by students without the express consent of the instructor unless it is pursuant to an accommodation granted by the Office of Disability services. Class recordings, lectures, presentations, and other materials posted on Canvas are for the sole purpose of educating the students currently enrolled in the course. Students may not record or share the materials or recordings, including screen capturing or automated bots, unless the instructor gives permission. Digitally proctored exams may require students to engage the video camera, but those recordings will not be shared with or disclosed to others without consent unless legally permitted. For classes where participation is voluntary, students who participate with their camera engaged or utilize a profile image are agreeing to have their video or image recorded. For classes requiring class participation, if students are identifiable by their names, facial images, voices, and/ or comments, written consent must be obtained before sharing the recording with persons outside of currently enrolled students in the class. Course Material Textbook none required Lectures The lectures will be based on Mathematical Foundations of Data Sciences the book A Wavelet Tour of Signal Processing: The Sparse Way by Stephane Mallat Solving inverse problems using data-driven models a series of research papers on topics pertinent to this course External Links papers and tutorials from Rice Compressive Sensing Resources the blog Nuit Blanch Assignments There will be Computational Assignments, which will mostly involve geophysics-related programs, computer simulations, and data analysis. These assignments is designed for each student to work by him/herself. This assignments will count as 30% of your overall course grade. Project You are required to propose, complete and write up a term project on any topic related to the class. This project will count for 50% of the final course grade. The project grade will be based on a proposal stage (10% of project grade) where you quickly present and receive feedback from the class and instructor on the project and its scope. Then upon completion of the project you will be graded on an in-class presentation with slides (30% of project grade). Finally, the bulk of the project grade will be given on a written report (60% of project grade). Your written report should be written up in a journal form with length, figures and referencing in a format suitable for a conference or research letter submission. You can find more details on the Projects page. Evaluation Assignments (30%) Presentation of a journal paper in class (20%) Final project + in-class presentation (50%) These weights are approximate; we reserve the right to change them later. Prerequisites Numerical Linear Algebra, Statistics. Experience w/ matlab, python, or julia Academic Honesty It is expected that all students are aware of their individual responsibilities under the Georgia Tech Academic Honor Code, which will be strictly adhered to in this class. The complete text of the Georgia Tech Academic Honor Code is at http://www.honor.gatech.edu/ .","title":"Imaging w/ data-driven models \u2013 CSE 8803"},{"location":"#imaging-w-data-driven-models-cse-8803","text":"","title":"Imaging w/ data-driven models \u2013 CSE 8803"},{"location":"#instructor","text":"Felix J. Herrmann Phone: +1 (404) 385-7069 CODA, room S1375B Time and Location Tuesday/Thursday 2:00 pm - 3:15 pm, Engineering Sci and Mechanics rm 201 Office Hours: by appointment via Microsoft Teams","title":"Instructor"},{"location":"#course-description","text":"This course concerns inverse problems as they relate to imaging. After reviewing techniques from Compressive Sensing , Sparse Approximation , and Convex Optimization by means of lectures based on Mathematical Foundations of Data Sciences and computational assignments from Numerical Tours of Data Sciences (in Matlab , Python , Julia , or R ), the course shifts towards the state of the art of \"Imaging w/ data-driven models\" as outlined in the review article Solving inverse problems using data-driven models and the references therein. Special emphasis will be given to Bayesian Inference with Normalizing Flows, a special type of invertible neural networks. The latter forms an important development since it alows for capturing uncertainty via distribution learning. The reviewed techniques are of interest to areas in Computational Science and Engineering where data is incomplete, noisy, and observed indirectly.","title":"Course Description"},{"location":"#topics","text":"See Topics tab (adapted from Mathematical Foundations of Data Sciences and Solving inverse problems using data-driven models ) Overview: a Sparse Tour of Signal Processing Signal and Image Processing with Orthogonal Decompositions Fourier Processing Wavelet Processing Approximation with Orthogonal Decompositions Linear and Non-linear Denoising Variational Regularization of Inverse Problems Sparse Regularization of Inverse Problems Compressive Sensing Statistical Regularization Learning in Functional Analytic Regularization Learning in Statistical Regularization","title":"Topics"},{"location":"#covid","text":"Georgia Tech is committed to promoting a campus community that supports holistic well-being, as well as empowering students to make choices that enable positive health outcomes. As we continue to live and learn through a pandemic, Georgia Tech strongly encourages students to utilize several tools not only to reduce their own risks of infection from Covid-19, but also to help reduce the overall levels of transmission in the community. These tools include: Getting fully vaccinated. Getting vaccinated at Tech is easy and free. Wearing face coverings consistently in all indoor settings and also in outdoor settings when in close proximity to others. Getting tested on a regular basis, regardless of whether you are vaccinated or asymptomatic. No appointment is needed for Georgia Tech\u2019s asymptomatic testing, and it is free. Avoiding touching your face until you have cleaned your hands with soap and water or used hand sanitizer. Immediately self-quarantining or self-isolating if you experience any symptoms that could be related to Covid-19 or if you have tested positive for Covid-19. Additional information and resources are available on the Tech Moving Forward website .","title":"COVID"},{"location":"#information-related-to-covid-19","text":"Students are expected to be familiar with and abide by the Institute guidelines, information, and updates related to Covid-19. Find campus operational updates, Frequently Asked Questions, and details on campus surveillance testing and vaccine appointments on the Tech Moving Forward website .","title":"Information Related to Covid-19"},{"location":"#recordings-of-class-sessions-and-required-permissions","text":"Classes may not be recorded by students without the express consent of the instructor unless it is pursuant to an accommodation granted by the Office of Disability services. Class recordings, lectures, presentations, and other materials posted on Canvas are for the sole purpose of educating the students currently enrolled in the course. Students may not record or share the materials or recordings, including screen capturing or automated bots, unless the instructor gives permission. Digitally proctored exams may require students to engage the video camera, but those recordings will not be shared with or disclosed to others without consent unless legally permitted. For classes where participation is voluntary, students who participate with their camera engaged or utilize a profile image are agreeing to have their video or image recorded. For classes requiring class participation, if students are identifiable by their names, facial images, voices, and/ or comments, written consent must be obtained before sharing the recording with persons outside of currently enrolled students in the class.","title":"Recordings of Class Sessions and Required Permissions"},{"location":"#course-material","text":"","title":"Course Material"},{"location":"#textbook","text":"none required","title":"Textbook"},{"location":"#lectures","text":"The lectures will be based on Mathematical Foundations of Data Sciences the book A Wavelet Tour of Signal Processing: The Sparse Way by Stephane Mallat Solving inverse problems using data-driven models a series of research papers on topics pertinent to this course","title":"Lectures"},{"location":"#external-links","text":"papers and tutorials from Rice Compressive Sensing Resources the blog Nuit Blanch","title":"External Links"},{"location":"#assignments","text":"There will be Computational Assignments, which will mostly involve geophysics-related programs, computer simulations, and data analysis. These assignments is designed for each student to work by him/herself. This assignments will count as 30% of your overall course grade.","title":"Assignments"},{"location":"#project","text":"You are required to propose, complete and write up a term project on any topic related to the class. This project will count for 50% of the final course grade. The project grade will be based on a proposal stage (10% of project grade) where you quickly present and receive feedback from the class and instructor on the project and its scope. Then upon completion of the project you will be graded on an in-class presentation with slides (30% of project grade). Finally, the bulk of the project grade will be given on a written report (60% of project grade). Your written report should be written up in a journal form with length, figures and referencing in a format suitable for a conference or research letter submission. You can find more details on the Projects page.","title":"Project"},{"location":"#evaluation","text":"Assignments (30%) Presentation of a journal paper in class (20%) Final project + in-class presentation (50%) These weights are approximate; we reserve the right to change them later.","title":"Evaluation"},{"location":"#prerequisites","text":"Numerical Linear Algebra, Statistics. Experience w/ matlab, python, or julia","title":"Prerequisites"},{"location":"#academic-honesty","text":"It is expected that all students are aware of their individual responsibilities under the Georgia Tech Academic Honor Code, which will be strictly adhered to in this class. The complete text of the Georgia Tech Academic Honor Code is at http://www.honor.gatech.edu/ .","title":"Academic Honesty"},{"location":"goals/","text":"","title":"Goals"},{"location":"homework/","text":"Assignments We will post the different assignments taken from Numerical Tours of Data Sciences here. We will offer support for Python . You are free to work on your Assignments in Matlab , Julia , or R but you are more on your own. To get the the recently tested Jupyter notebooks in Python, please clone the Numerical Tours from this fork . Follow the instructions in the README.md file to install required libraries. Posted assignments: Note : The homework notebooks come with a runnable script for the solution of each exercise. That is not taken away in order for you to get an idea of what the output of the solution should look like. The source code for the solution is also inside the repo. We don\u2019t attempt to hide this as these numerical tours are extensively used and it would be easy for you to find these solutions regardless. For optimal learning, do not look at the source code of the solution and give it an honest attempt in writing your own source code from scratch. A large portion of the grade comes from responding the prompts that the exercises ask so make sure to respond them as clearly as you can. Reminder : Make sure you pull the latest commits in the fork after each assignment is posted. Exercises 1 and 2 from Introduction to Image Processing , exercises 1-4 from Image Approximation with Fourier and Wavelets , and exercises 1-3 from 2-D Daubechies Wavelets . Due date : Thursday, January 20, at 2:00 PM. Exercises 1-5 from Volumetric wavelet Data Processing , exercises 1 and 2 from Linear Image Denoising , exercises 1-3 from Wavelet Denoising , exercises 1-4 from Wavelet Block Thresholding , and exercises 1-6 from Stein Unbiased Risk Estimator . Due date : Thursday, February 10, at 2:00 PM. Exercises 1-4 from Image Deconvolution using Variational Method , exercises 1-5 from Inpainting using Sparse Regularization , and exercises 1-6 from Performance of Sparse Recovery Using L1 Minimization . Due date : Thursday, February 24, at 3:00 PM. Handins Make a script that produces the plots and carefully describes your findings. The code itself is part of the assignment; make sure that it is readable and carefully documented. Generate a pdf or HTML file from your script. You may do this by exporting the Jupyter notebook that contains your answers/codes. Make sure that the lay-out is readable. Look for documentation on making up your code for publication. The naming convention for this file is GTID_assignmentnumber.[pdf/html]. Send the file to Rafael Orozco with subject CSE 8803 . For some exercises you will be asked to write separate functions. In this case include ALL the files in a zip-file named GTID_assignmentnumber.zip.","title":"Assigments"},{"location":"homework/#assignments","text":"We will post the different assignments taken from Numerical Tours of Data Sciences here. We will offer support for Python . You are free to work on your Assignments in Matlab , Julia , or R but you are more on your own. To get the the recently tested Jupyter notebooks in Python, please clone the Numerical Tours from this fork . Follow the instructions in the README.md file to install required libraries.","title":"Assignments"},{"location":"homework/#posted-assignments","text":"Note : The homework notebooks come with a runnable script for the solution of each exercise. That is not taken away in order for you to get an idea of what the output of the solution should look like. The source code for the solution is also inside the repo. We don\u2019t attempt to hide this as these numerical tours are extensively used and it would be easy for you to find these solutions regardless. For optimal learning, do not look at the source code of the solution and give it an honest attempt in writing your own source code from scratch. A large portion of the grade comes from responding the prompts that the exercises ask so make sure to respond them as clearly as you can. Reminder : Make sure you pull the latest commits in the fork after each assignment is posted. Exercises 1 and 2 from Introduction to Image Processing , exercises 1-4 from Image Approximation with Fourier and Wavelets , and exercises 1-3 from 2-D Daubechies Wavelets . Due date : Thursday, January 20, at 2:00 PM. Exercises 1-5 from Volumetric wavelet Data Processing , exercises 1 and 2 from Linear Image Denoising , exercises 1-3 from Wavelet Denoising , exercises 1-4 from Wavelet Block Thresholding , and exercises 1-6 from Stein Unbiased Risk Estimator . Due date : Thursday, February 10, at 2:00 PM. Exercises 1-4 from Image Deconvolution using Variational Method , exercises 1-5 from Inpainting using Sparse Regularization , and exercises 1-6 from Performance of Sparse Recovery Using L1 Minimization . Due date : Thursday, February 24, at 3:00 PM.","title":"Posted assignments:"},{"location":"homework/#handins","text":"Make a script that produces the plots and carefully describes your findings. The code itself is part of the assignment; make sure that it is readable and carefully documented. Generate a pdf or HTML file from your script. You may do this by exporting the Jupyter notebook that contains your answers/codes. Make sure that the lay-out is readable. Look for documentation on making up your code for publication. The naming convention for this file is GTID_assignmentnumber.[pdf/html]. Send the file to Rafael Orozco with subject CSE 8803 . For some exercises you will be asked to write separate functions. In this case include ALL the files in a zip-file named GTID_assignmentnumber.zip.","title":"Handins"},{"location":"outline/","text":"Overview: a Sparse Tour of Signal Processing Signal and Image Processing with Orthogonal Decompositions Continuous signals and images Orthogonal representations decomposition energy conservation (Parseval) Fourier and wavelets 2D wavelet transform Linear and nonlinear approximations filtering thresholding compressibility and its relation to smoothness Denoising and inverse problems signal model recovery by sparsity promotion Reading material Chapter 1 from Advanced Signal, Image and Surface Processing Slides Signal and Image Decomposition in Orthogonal Bases adapted from here . Recordings Recording for Lecture 1 Recording for Lecture 2 Recording for Lecture 3 Recording for Lecture 5 Recording for Lecture 6 Recording for Lecture 7 Recording for Lecture 8 Recording for Lecture 9 Recording for Lecture 10 Recording for Lecture 11 Fourier Processing Continuous/discrete Fourier basis Sampling 2D Fourier transform Fourier Approximation Reading material Chapter 2 from Advanced Signal, Image and Surface Processing . If you want more detail read Fourier Transforms from Mathematical Foundations of Data Sciences . Assignments See assignment tab. Slides Fourier Processing adapted from here . Wavelet Processing 1D Multiresolutions detail spaces Haar wavelets 1D Wavelet transform computing wavelet coefficients discrete wavelet coefficients fast wavelet transform -inverse transform Filter banks approximation filter detail filter vanishing moments Daubechies wavelets Extension to 2D -anisotropic wavelets 2D multiresolutions 2D wavelet bases 2D discrete wavelet coefficients fast 2D wavelet transform Reading material Chapter 3 from Advanced Signal, Image and Surface Processing . If you want more detail read Wavelets from Mathematical Foundations of Data Sciences . Assignments See assignment tab. Slides Wavelet Processing adapted from here . Approximation with Orthogonal Decompositions Linear and nonlinear approximations Sparse approximation in a basis hard thresholding decay of approximation errors (linear vs. nonlinear) Relation between decay rate coefficients and approximation error Fourier for smooth functions Fourier and singularities/edges wavelet transform for peice-wise 1D smooth functions vanishing moments magnitude of wavelet coefficients and its relation to edges decay and nonlinear approximation error for piece-wise 1D functions Piece-wise smooth 2D functions 2D approximations -decay and nonlinear approximation error for piece-wise 2D functions Geometrically regular functions space of BV functions finite elements curvelets, their construction, and properties Reading material Chapter 4 from Advanced Signal, Image and Surface Processing . If you want more detail read Linear and Non-linear Approximation from Mathematical Foundations of Data Sciences . Assignments See assignment tab. Slides Approximation and Coding with Orthogonal Decompositions adapted from here . Linear and Nonlinear Denoising Linear denoising additative noise model linear denoising by smoothing Wiener filter and oracle estimation of optimal filter Nonlinear denoising hard thresholding optimal threshold selection nonlinear approximation and estimation hard vs. soft thresholding Translational invariant thresholding translation invariant wavelets optimal threshold Other diagonal estimators between hard and soft thresholding Non-diagonal estimators block thresholding Reading material Chapter 5 from Advanced Signal, Image and Surface Processing . If you want more detail read Denoising from Mathematical Foundations of Data Sciences . Assignments See assignment tab. Slides Linear and nonlinear denoising adapted from here . Variational Regularization of Inverse Problems Variational priors smooth and cartoon natural image priors discretization Variational regularization regularized inverse pseudo inverse Sobolev regularization and inpainting total variation regularization and inpainting Example from tomography with the Radon transform Reading material Chapter 6 from Advanced Signal, Image and Surface Processing . If you want more detail read Variational Priors and Regularization from Mathematical Foundations of Data Sciences . Assignments See assignment tab. Slides Inverse problems Regularization adapted from here . Sparse Regularization of Inverse Problems Linear inverse problems denoising inpainting super- resolution Regularization of inverse problems regularized inverse Lagrangian formulation including the the Lagrange multiplier/trade-off parameter lambda smooth and cartoon priors Redundant dictionaries Sparse priors convex relaxation of the \\(\\ell_0-norm\\) via the \\(\\ell_1\\) -norm \\(\\ell_1\\) -regularization and sparse recovery noise-free sparsity-promoting regularization Iterative soft thresholding Reading material Chapter 7 from Advanced Signal, Image and Surface Processing . If you want more detail read Inverse Problems and Sparse Regularization from Mathematical Foundations of Data Sciences . Assignments See assignment tab. Slides Sparse regularization of Inverse Problems adapted from here . Compressive Sensing Classical sampling discretization point-wise sampling and smoothness Compressive acquisition examples single pixel camera physical model Inversion and sparsity \\(\\ell_1\\) prior sparse CS recovery Theoretical guarantees CS with restricted isometry constants (RIP) singular-value distributions RIP for Gaussian matrices numerics with RIP Fourier measurements MRI imaging radar interferometry structured measurements Assignments See assignment tab. Reading material Compressive Sensing Chapter from Mathematical Foundations of Data Sciences . Slides Compressive Sensing adapted from here . Statistical Regularization The review article Solving inverse problems using data-driven models serves as the major reading material. For a mathematical description of the February 6 and 11 lectures, refer to pages 22 till 43 from this article. Learning in Functional Analytic Regularization During the lecture of February 13, we start by considering section 5.1.2 Deep direct Bayes estimation on page 84 of Solving inverse problems using data-driven models untile Regularization by learning. We continue with section Deep direct estimation of higher-order moments on page 99. Next, we consider loop unrolling described in section 4.9 Data-driven optimization on page 66 until section 4.10 and later in section 5.1.4 Learned iterative schemes on page 89 until section 5.1.5. The supervised training, learned prior/regularizer, unsupervised learning, and semi-supervised learning are briefly introduced in section 5.1 Learning an estimator on page 82. Learning in Statistical Regularization Slides We use a combination of slides developed mainly by Ozan Oktem and Jonas Adler and others. The slides presented in class can be found here . Papers Untrained Neural Networks Deep Image Prior A Bayesian Perspective on the Deep Image Prior DeepRED: Deep Image Prior Powered by RED Algorithmic Guarantees for Inverse Imaging with Untrained Network Priors Loop-Unrolled Neural Networks Learning to learn by gradient descent by gradient descent Invert to Learn to Invert Recurrent Inference Machines for Solving Inverse Problems Model based learning for accelerated, limited-view 3D photoacoustic tomography Multi-Scale Learned Iterative Reconstruction Learned primal-dual reconstruction Deep bayesian inversion Solving ill-posed inverse problems using iterative deep neural networks Low Shot Learning with Untrained Neural Networks for Imaging Inverse Problems Normalizing Flows First Papers NICE: NON-LINEAR INDEPENDENT COMPONENTS ESTIMATION (2015) Variational Inference with Normalizing Flows (2016) DENSITY ESTIMATION USING REAL NVP (2017) Glow: Generative Flow with Invertible 1\u00d71 Convolutions (2018) Conditional Normalizing Flows HINT: Hierarchical Invertible Neural Transport for General and Sequential Bayesian inference GUIDED IMAGE GENERATION WITH CONDITIONAL INVERTIBLE NEURAL NETWORKS LEARNING LIKELIHOODS WITH CONDITIONAL NORMALIZING FLOWS Continuous Normalizing Flows Neural Ordinary Differential Equations FFJORD: FREE-FORM CONTINUOUS DYNAMICS FOR SCALABLE REVERSIBLE GENERATIVE MODELS Applications Invertible generative models for inverse problems: mitigating representation error and dataset bias Analyzing Inverse Problems with Invertible Neural Networks Compressible Latent-Space Invertible Networks for Generative Model-Constrained Image Reconstruction Review papers Normalizing Flows: An Introduction and Review of Current Methods Normalizing Flows for Probabilistic Modeling and Inference SOTA Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design Densely connected normalizing flows Neural Spline Flows Diffusion Models (Equivalent to certain SDE models) Denoising Diffusion Probabilistic Models Diffusion Models Beat GANs on Image Synthesis Deblurring via Stochastic Refinement Stochastic Differential Equations Generative Models (Equivalent to certain Diffusion models) Neural Ordinary Differential Equations FFJORD: FREE-FORM CONTINUOUS DYNAMICS FOR SCALABLE REVERSIBLE GENERATIVE MODELS SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS SOLVING INVERSE PROBLEMS IN MEDICAL IMAGING WITH SCORE-BASED GENERATIVE MODELS GANs Bayesian Inference with Generative Adversarial Network Priors Deep Generative Adversarial Neural Networks for Compressive Sensing MRI GAN-based Projector for Faster Recovery with Convergence Guarantees in Linear Inverse Problems Solving Linear Inverse Problems Using GAN Priors: An Algorithm with Provable Guarantees Stochastic Seismic Waveform Inversion using Generative Adversarial Networks as a Geological Prior Compressed Sensing Learning-Based Compressive Subsampling Learning-Based Compressive MRI NETT Regularization for Compressed Sensing Photoacoustic Tomography Misc Stein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm Divergence Triangle for Joint Training of Generator Model, Energy-based Model, and Inference Model Transport map accelerated Markov chain Monte Carlo A transport-based multifidelity preconditioner for Markov chain Monte Carlo Uncertainty Quantification with Generative Models Variational Inference for Computational Imaging Inverse Problems Adversarial Uncertainty Quantification in Physics-Informed Neural Networks General information generative neural networks Slides on generative models Lecture on Deep Generative Models by Joe Marino - Video Tutorial on Deep Generative Models by DeepMind Probabilistic Deep Learning by Microsoft Lecture on Learning Deep Generative Models by Russ Salakhutdinov Ingredients of convolutional neural networks Lecture on Convolutional Networks by Roger Grosse Lecture on Convolutional Networks by Fei-Fei Li Lectures ( Part 1 , Part 2 , Part 3 ) on Convolutional Neural Networks by Sebastian Raschka Visual guide to convolution arithmetic in the context of deep learning , and associated paper Tutorials and codes GAN lab, an interactive visualization for playing with GANs A collection of various deep learning architectures, in TensorFlow and PyTorch (Jupyter Notebooks), by Sebastian Raschka Super simple implementations of generative models in PyTorch and TensorFlow along with related blog posts Collection of generative models in PyTorch Collection of generative models in TensorFlow Useful other material Deep Learning course - Sebastian Raschka Machine Learning & Data Mining course by Yisong Yue Introduction to Deep Learning and Generative Models course - Sebastian Raschka (Spring 2020) Intro to Neural Networks and Machine Learning course - Roger Grosse Neural Networks and Deep Learning course - Roger Grosse Inverse Problems and Learning course - Ivan Dokmanic Troubling Trends in Machine Learning Scholarship [assignment]:","title":"Topics"},{"location":"outline/#overview-a-sparse-tour-of-signal-processing","text":"","title":"Overview: a Sparse Tour of Signal Processing"},{"location":"outline/#signal-and-image-processing-with-orthogonal-decompositions","text":"Continuous signals and images Orthogonal representations decomposition energy conservation (Parseval) Fourier and wavelets 2D wavelet transform Linear and nonlinear approximations filtering thresholding compressibility and its relation to smoothness Denoising and inverse problems signal model recovery by sparsity promotion","title":"Signal and Image Processing with Orthogonal Decompositions"},{"location":"outline/#reading-material","text":"Chapter 1 from Advanced Signal, Image and Surface Processing","title":"Reading material"},{"location":"outline/#slides","text":"Signal and Image Decomposition in Orthogonal Bases adapted from here .","title":"Slides"},{"location":"outline/#recordings","text":"Recording for Lecture 1 Recording for Lecture 2 Recording for Lecture 3 Recording for Lecture 5 Recording for Lecture 6 Recording for Lecture 7 Recording for Lecture 8 Recording for Lecture 9 Recording for Lecture 10 Recording for Lecture 11","title":"Recordings"},{"location":"outline/#fourier-processing","text":"Continuous/discrete Fourier basis Sampling 2D Fourier transform Fourier Approximation","title":"Fourier Processing"},{"location":"outline/#reading-material_1","text":"Chapter 2 from Advanced Signal, Image and Surface Processing . If you want more detail read Fourier Transforms from Mathematical Foundations of Data Sciences .","title":"Reading material"},{"location":"outline/#assignments","text":"See assignment tab.","title":"Assignments"},{"location":"outline/#slides_1","text":"Fourier Processing adapted from here .","title":"Slides"},{"location":"outline/#wavelet-processing","text":"1D Multiresolutions detail spaces Haar wavelets 1D Wavelet transform computing wavelet coefficients discrete wavelet coefficients fast wavelet transform -inverse transform Filter banks approximation filter detail filter vanishing moments Daubechies wavelets Extension to 2D -anisotropic wavelets 2D multiresolutions 2D wavelet bases 2D discrete wavelet coefficients fast 2D wavelet transform","title":"Wavelet Processing"},{"location":"outline/#reading-material_2","text":"Chapter 3 from Advanced Signal, Image and Surface Processing . If you want more detail read Wavelets from Mathematical Foundations of Data Sciences .","title":"Reading material"},{"location":"outline/#assignments_1","text":"See assignment tab.","title":"Assignments"},{"location":"outline/#slides_2","text":"Wavelet Processing adapted from here .","title":"Slides"},{"location":"outline/#approximation-with-orthogonal-decompositions","text":"Linear and nonlinear approximations Sparse approximation in a basis hard thresholding decay of approximation errors (linear vs. nonlinear) Relation between decay rate coefficients and approximation error Fourier for smooth functions Fourier and singularities/edges wavelet transform for peice-wise 1D smooth functions vanishing moments magnitude of wavelet coefficients and its relation to edges decay and nonlinear approximation error for piece-wise 1D functions Piece-wise smooth 2D functions 2D approximations -decay and nonlinear approximation error for piece-wise 2D functions Geometrically regular functions space of BV functions finite elements curvelets, their construction, and properties","title":"Approximation with Orthogonal Decompositions"},{"location":"outline/#reading-material_3","text":"Chapter 4 from Advanced Signal, Image and Surface Processing . If you want more detail read Linear and Non-linear Approximation from Mathematical Foundations of Data Sciences .","title":"Reading material"},{"location":"outline/#assignments_2","text":"See assignment tab.","title":"Assignments"},{"location":"outline/#slides_3","text":"Approximation and Coding with Orthogonal Decompositions adapted from here .","title":"Slides"},{"location":"outline/#linear-and-nonlinear-denoising","text":"Linear denoising additative noise model linear denoising by smoothing Wiener filter and oracle estimation of optimal filter Nonlinear denoising hard thresholding optimal threshold selection nonlinear approximation and estimation hard vs. soft thresholding Translational invariant thresholding translation invariant wavelets optimal threshold Other diagonal estimators between hard and soft thresholding Non-diagonal estimators block thresholding","title":"Linear and Nonlinear Denoising"},{"location":"outline/#reading-material_4","text":"Chapter 5 from Advanced Signal, Image and Surface Processing . If you want more detail read Denoising from Mathematical Foundations of Data Sciences .","title":"Reading material"},{"location":"outline/#assignments_3","text":"See assignment tab.","title":"Assignments"},{"location":"outline/#slides_4","text":"Linear and nonlinear denoising adapted from here .","title":"Slides"},{"location":"outline/#variational-regularization-of-inverse-problems","text":"Variational priors smooth and cartoon natural image priors discretization Variational regularization regularized inverse pseudo inverse Sobolev regularization and inpainting total variation regularization and inpainting Example from tomography with the Radon transform","title":"Variational Regularization of Inverse Problems"},{"location":"outline/#reading-material_5","text":"Chapter 6 from Advanced Signal, Image and Surface Processing . If you want more detail read Variational Priors and Regularization from Mathematical Foundations of Data Sciences .","title":"Reading material"},{"location":"outline/#assignments_4","text":"See assignment tab.","title":"Assignments"},{"location":"outline/#slides_5","text":"Inverse problems Regularization adapted from here .","title":"Slides"},{"location":"outline/#sparse-regularization-of-inverse-problems","text":"Linear inverse problems denoising inpainting super- resolution Regularization of inverse problems regularized inverse Lagrangian formulation including the the Lagrange multiplier/trade-off parameter lambda smooth and cartoon priors Redundant dictionaries Sparse priors convex relaxation of the \\(\\ell_0-norm\\) via the \\(\\ell_1\\) -norm \\(\\ell_1\\) -regularization and sparse recovery noise-free sparsity-promoting regularization Iterative soft thresholding","title":"Sparse Regularization of Inverse Problems"},{"location":"outline/#reading-material_6","text":"Chapter 7 from Advanced Signal, Image and Surface Processing . If you want more detail read Inverse Problems and Sparse Regularization from Mathematical Foundations of Data Sciences . Assignments See assignment tab.","title":"Reading material"},{"location":"outline/#slides_6","text":"Sparse regularization of Inverse Problems adapted from here .","title":"Slides"},{"location":"outline/#compressive-sensing","text":"Classical sampling discretization point-wise sampling and smoothness Compressive acquisition examples single pixel camera physical model Inversion and sparsity \\(\\ell_1\\) prior sparse CS recovery Theoretical guarantees CS with restricted isometry constants (RIP) singular-value distributions RIP for Gaussian matrices numerics with RIP Fourier measurements MRI imaging radar interferometry structured measurements","title":"Compressive Sensing"},{"location":"outline/#assignments_5","text":"See assignment tab.","title":"Assignments"},{"location":"outline/#reading-material_7","text":"Compressive Sensing Chapter from Mathematical Foundations of Data Sciences .","title":"Reading material"},{"location":"outline/#slides_7","text":"Compressive Sensing adapted from here .","title":"Slides"},{"location":"outline/#statistical-regularization","text":"The review article Solving inverse problems using data-driven models serves as the major reading material. For a mathematical description of the February 6 and 11 lectures, refer to pages 22 till 43 from this article.","title":"Statistical Regularization"},{"location":"outline/#learning-in-functional-analytic-regularization","text":"During the lecture of February 13, we start by considering section 5.1.2 Deep direct Bayes estimation on page 84 of Solving inverse problems using data-driven models untile Regularization by learning. We continue with section Deep direct estimation of higher-order moments on page 99. Next, we consider loop unrolling described in section 4.9 Data-driven optimization on page 66 until section 4.10 and later in section 5.1.4 Learned iterative schemes on page 89 until section 5.1.5. The supervised training, learned prior/regularizer, unsupervised learning, and semi-supervised learning are briefly introduced in section 5.1 Learning an estimator on page 82.","title":"Learning in Functional Analytic Regularization"},{"location":"outline/#learning-in-statistical-regularization","text":"","title":"Learning in Statistical Regularization"},{"location":"outline/#slides_8","text":"We use a combination of slides developed mainly by Ozan Oktem and Jonas Adler and others. The slides presented in class can be found here .","title":"Slides"},{"location":"outline/#papers","text":"","title":"Papers"},{"location":"outline/#untrained-neural-networks","text":"Deep Image Prior A Bayesian Perspective on the Deep Image Prior DeepRED: Deep Image Prior Powered by RED Algorithmic Guarantees for Inverse Imaging with Untrained Network Priors","title":"Untrained Neural Networks"},{"location":"outline/#loop-unrolled-neural-networks","text":"Learning to learn by gradient descent by gradient descent Invert to Learn to Invert Recurrent Inference Machines for Solving Inverse Problems Model based learning for accelerated, limited-view 3D photoacoustic tomography Multi-Scale Learned Iterative Reconstruction Learned primal-dual reconstruction Deep bayesian inversion Solving ill-posed inverse problems using iterative deep neural networks Low Shot Learning with Untrained Neural Networks for Imaging Inverse Problems","title":"Loop-Unrolled Neural Networks"},{"location":"outline/#normalizing-flows","text":"First Papers NICE: NON-LINEAR INDEPENDENT COMPONENTS ESTIMATION (2015) Variational Inference with Normalizing Flows (2016) DENSITY ESTIMATION USING REAL NVP (2017) Glow: Generative Flow with Invertible 1\u00d71 Convolutions (2018) Conditional Normalizing Flows HINT: Hierarchical Invertible Neural Transport for General and Sequential Bayesian inference GUIDED IMAGE GENERATION WITH CONDITIONAL INVERTIBLE NEURAL NETWORKS LEARNING LIKELIHOODS WITH CONDITIONAL NORMALIZING FLOWS Continuous Normalizing Flows Neural Ordinary Differential Equations FFJORD: FREE-FORM CONTINUOUS DYNAMICS FOR SCALABLE REVERSIBLE GENERATIVE MODELS Applications Invertible generative models for inverse problems: mitigating representation error and dataset bias Analyzing Inverse Problems with Invertible Neural Networks Compressible Latent-Space Invertible Networks for Generative Model-Constrained Image Reconstruction Review papers Normalizing Flows: An Introduction and Review of Current Methods Normalizing Flows for Probabilistic Modeling and Inference SOTA Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design Densely connected normalizing flows Neural Spline Flows","title":"Normalizing Flows"},{"location":"outline/#diffusion-models-equivalent-to-certain-sde-models","text":"Denoising Diffusion Probabilistic Models Diffusion Models Beat GANs on Image Synthesis Deblurring via Stochastic Refinement","title":"Diffusion Models (Equivalent to certain SDE models)"},{"location":"outline/#stochastic-differential-equations-generative-models-equivalent-to-certain-diffusion-models","text":"Neural Ordinary Differential Equations FFJORD: FREE-FORM CONTINUOUS DYNAMICS FOR SCALABLE REVERSIBLE GENERATIVE MODELS SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS SOLVING INVERSE PROBLEMS IN MEDICAL IMAGING WITH SCORE-BASED GENERATIVE MODELS","title":"Stochastic Differential Equations Generative Models (Equivalent to certain Diffusion models)"},{"location":"outline/#gans","text":"Bayesian Inference with Generative Adversarial Network Priors Deep Generative Adversarial Neural Networks for Compressive Sensing MRI GAN-based Projector for Faster Recovery with Convergence Guarantees in Linear Inverse Problems Solving Linear Inverse Problems Using GAN Priors: An Algorithm with Provable Guarantees Stochastic Seismic Waveform Inversion using Generative Adversarial Networks as a Geological Prior","title":"GANs"},{"location":"outline/#compressed-sensing","text":"Learning-Based Compressive Subsampling Learning-Based Compressive MRI NETT Regularization for Compressed Sensing Photoacoustic Tomography","title":"Compressed Sensing"},{"location":"outline/#misc","text":"Stein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm Divergence Triangle for Joint Training of Generator Model, Energy-based Model, and Inference Model Transport map accelerated Markov chain Monte Carlo A transport-based multifidelity preconditioner for Markov chain Monte Carlo Uncertainty Quantification with Generative Models Variational Inference for Computational Imaging Inverse Problems Adversarial Uncertainty Quantification in Physics-Informed Neural Networks","title":"Misc"},{"location":"outline/#general-information-generative-neural-networks","text":"","title":"General information generative neural networks"},{"location":"outline/#slides-on-generative-models","text":"Lecture on Deep Generative Models by Joe Marino - Video Tutorial on Deep Generative Models by DeepMind Probabilistic Deep Learning by Microsoft Lecture on Learning Deep Generative Models by Russ Salakhutdinov","title":"Slides on generative models"},{"location":"outline/#ingredients-of-convolutional-neural-networks","text":"Lecture on Convolutional Networks by Roger Grosse Lecture on Convolutional Networks by Fei-Fei Li Lectures ( Part 1 , Part 2 , Part 3 ) on Convolutional Neural Networks by Sebastian Raschka Visual guide to convolution arithmetic in the context of deep learning , and associated paper","title":"Ingredients of convolutional neural networks"},{"location":"outline/#tutorials-and-codes","text":"GAN lab, an interactive visualization for playing with GANs A collection of various deep learning architectures, in TensorFlow and PyTorch (Jupyter Notebooks), by Sebastian Raschka Super simple implementations of generative models in PyTorch and TensorFlow along with related blog posts Collection of generative models in PyTorch Collection of generative models in TensorFlow","title":"Tutorials and codes"},{"location":"outline/#useful-other-material","text":"Deep Learning course - Sebastian Raschka Machine Learning & Data Mining course by Yisong Yue Introduction to Deep Learning and Generative Models course - Sebastian Raschka (Spring 2020) Intro to Neural Networks and Machine Learning course - Roger Grosse Neural Networks and Deep Learning course - Roger Grosse Inverse Problems and Learning course - Ivan Dokmanic Troubling Trends in Machine Learning Scholarship [assignment]:","title":"Useful other material"},{"location":"project/","text":"Goal The goal of your project is to give the students the opportunity to apply and further develop his or her understanding of the application of Imaging w/ data-driven models to a topic close to his or her graduate research interests. Requirements Each student is required to finish a project related to the above subject areas. Students are encouraged to choose a topic close to their research. The projects consist of three parts Proposal consisting of a \u201cone pager\u201d + \"5 min pitch\" Project presentation of 20 minutes with 5 minutes questions, presented at the end of the term A final report One pager + 5 min pitch On March 1th, everybody needs to give a 5 minute pitch on their project proposal. That same day, the \"one pager\" outlining the project is due by 6:00 PM. See description below. Your seminar will be evaluated with this form . Proposal Concise description of the work to be undertaken. The description should not exceed two pages and should contain Title of the project Problem statement Relevance Identification of methodology that will be used to solve the problem Proposal should be submitted in PDF format or a link to an html page. The project proposals are due February 25 at 6:00 PM and presentations are scheduled for that same day during class. The presentations are five minutes each for each person. Project presentation at the end of the term Each project presentation will be allotted 20 minutes precisely with 5 minutes of questions. The seminar should reflect the current status of the project, which may be subject to change when the project is finalized. The seminar will be evaluated using the following form2 . Final Report The report needs to be written as a short journal paper. Students will be required to use the IEEE template in two-column mode. The paper should be four-to-six pages including abstract, body text, figures, and bibliography. Reports should consist of abstract introduction problem statement methodology results conclusions references appendices Grading (project alone) 10% Proposal plus speed presentation 30% Seminar 60% Final Report Late policy Late submission is unacceptable and will lead to deductions in your grade. The deadline for submission will be communicate in class. Calendar for events","title":"Projects"},{"location":"project/#goal","text":"The goal of your project is to give the students the opportunity to apply and further develop his or her understanding of the application of Imaging w/ data-driven models to a topic close to his or her graduate research interests.","title":"Goal"},{"location":"project/#requirements","text":"Each student is required to finish a project related to the above subject areas. Students are encouraged to choose a topic close to their research. The projects consist of three parts Proposal consisting of a \u201cone pager\u201d + \"5 min pitch\" Project presentation of 20 minutes with 5 minutes questions, presented at the end of the term A final report","title":"Requirements"},{"location":"project/#one-pager-5-min-pitch","text":"On March 1th, everybody needs to give a 5 minute pitch on their project proposal. That same day, the \"one pager\" outlining the project is due by 6:00 PM. See description below. Your seminar will be evaluated with this form .","title":"One pager + 5 min pitch"},{"location":"project/#proposal","text":"Concise description of the work to be undertaken. The description should not exceed two pages and should contain Title of the project Problem statement Relevance Identification of methodology that will be used to solve the problem Proposal should be submitted in PDF format or a link to an html page. The project proposals are due February 25 at 6:00 PM and presentations are scheduled for that same day during class. The presentations are five minutes each for each person.","title":"Proposal"},{"location":"project/#project-presentation-at-the-end-of-the-term","text":"Each project presentation will be allotted 20 minutes precisely with 5 minutes of questions. The seminar should reflect the current status of the project, which may be subject to change when the project is finalized. The seminar will be evaluated using the following form2 .","title":"Project presentation at the end of the term"},{"location":"project/#final-report","text":"The report needs to be written as a short journal paper. Students will be required to use the IEEE template in two-column mode. The paper should be four-to-six pages including abstract, body text, figures, and bibliography. Reports should consist of abstract introduction problem statement methodology results conclusions references appendices","title":"Final Report"},{"location":"project/#grading-project-alone","text":"10% Proposal plus speed presentation 30% Seminar 60% Final Report","title":"Grading (project alone)"},{"location":"project/#late-policy","text":"Late submission is unacceptable and will lead to deductions in your grade. The deadline for submission will be communicate in class.","title":"Late policy"},{"location":"project/#calendar-for-events","text":"","title":"Calendar for events"},{"location":"reading/","text":"","title":"Reading"},{"location":"Assignments/Exercise1/","text":"Exercise 1: a first look at seismic data In this exercise we will load some data into Julia and perform some basic operations. Seismic data are typically stored in a special binary format: SEGY. These file-formats store the data as mutliple time-series (traces) with the corresponding header information containing specific information about such as time sampling and source/receiver locations. The Julia utilities for reading SEGY data is SeisIO using SeisIO, PyPlot Scaning the dataset Thhe first step is to scan the dataset to extract header/metadat. This metadat contains the geometry and parameters of the survey such as the source/receiver locations and time sampling rate. The convention for the metadata is as follows: - The Source positions use the Source keyword such as SourceX - The receiver position use the Group keyword such as GroupX # scan the dataset dir = Pkg.dir(\"SeisIO\") data_dir = \"/src/data\" \"/src/data\" We ca nnow scans the dataset with the segy_scan functin. This function returns a SeisCOn object where each block is a shot record with its metadata. blocks = segy_scan(string(dir, data_dir), \"overthrust\", [\"GroupX\", \"GroupY\", \"ns\", \"dt\"]); Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_41_60.segy Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_21_40.segy Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_61_80.segy Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_1_20.segy Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_81_97.segy Now extract the time, source and receiver coordinates (in seconds and meters) for all the traces. The source and receiver vectors have a length equal to the number of traces, the time vector has a length equal to the number of rows in the data matrix. sx = [get_header(blocks[i], \"SourceX\") for i=1:length(blocks)]; rx = [get_header(blocks[i], \"GroupX\") for i=1:length(blocks)]; # Get the tme axis. In this case the time axis is the same for all traces so we only need to extract it from the first trace # dt needs to be corrected for the binary setup # All the times are in ms dt = get_header(blocks[1], \"dt\")[1]/1000 nt = get_header(blocks[1], \"ns\")[1] T = 0:dt:(nt-1)*dt 0.0:4.0:3000.0 Calculate the offset and midpoint for each trace. This gives you vectors m (midpoint) and h (offset) with length equal to the number of traces. h = (s - r)/2; m = (s + r)/2; h = (sx .- rx)./2; m = (sx .+ rx)./2; The fold of the data is the number of traces in each midpoint gather. This can be easily visualized by a histogram. As we have a set of blocks we need to inspect each block seperately to recover the nuique set of midpoint location and the total number fo traces for this midpoint all_m = hcat(m'...) fold = [sum(all_m .== unique(all_m)[i]) for i=1:length(unique(all_m))]; all_h = hcat(h'...); figure(); bar(unique(all_m),fold ,align=\"center\", width=100); xlabel(\"midpoint [m]\"); ylabel(\"fold\"); title(\"fold\"); Can you interpret this figure? Different gathers Extract a midpoint gather. For example, a midpoint gather at m = 2550 looks like this: Im = find(all_m .== 7500.) figure() imshow(Float32.(blocks[1:97].data[:, Im]), vmin=-1, vmax=1, cmap=\"Greys\", aspect=.05) PyObject <matplotlib.image.AxesImage object at 0x7f947ac9a550> Extract an offset-gather. For example, a zero-offset section looks like: # We need to sort it in physical units as the dataset may not be Ih = find(all_h .== 0.) inds = sortperm(all_m[Ih]') figure() imshow(Float32.(blocks[1:97].data[:, Ih[inds]]), vmin=-1, vmax=1, cmap=\"Greys\", aspect=.1) PyObject <matplotlib.image.AxesImage object at 0x7f947ab7f048> What other different gathers can you think of? Extract and plot an example of all the different gathers. What are characteristic properties of the different gathers? Do not forget to label the axis and choose a reasonable colorscale. Hint: use cmap=Greys and adjust the color-axis vmin/vmax","title":"Exercise 1: a first look at seismic data"},{"location":"Assignments/Exercise1/#exercise-1-a-first-look-at-seismic-data","text":"In this exercise we will load some data into Julia and perform some basic operations. Seismic data are typically stored in a special binary format: SEGY. These file-formats store the data as mutliple time-series (traces) with the corresponding header information containing specific information about such as time sampling and source/receiver locations. The Julia utilities for reading SEGY data is SeisIO using SeisIO, PyPlot","title":"Exercise 1: a first look at seismic data"},{"location":"Assignments/Exercise1/#scaning-the-dataset","text":"Thhe first step is to scan the dataset to extract header/metadat. This metadat contains the geometry and parameters of the survey such as the source/receiver locations and time sampling rate. The convention for the metadata is as follows: - The Source positions use the Source keyword such as SourceX - The receiver position use the Group keyword such as GroupX # scan the dataset dir = Pkg.dir(\"SeisIO\") data_dir = \"/src/data\" \"/src/data\" We ca nnow scans the dataset with the segy_scan functin. This function returns a SeisCOn object where each block is a shot record with its metadata. blocks = segy_scan(string(dir, data_dir), \"overthrust\", [\"GroupX\", \"GroupY\", \"ns\", \"dt\"]); Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_41_60.segy Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_21_40.segy Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_61_80.segy Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_1_20.segy Scanning ... /nethome/mlouboutin3/.julia/v0.6/SeisIO/src/data/overthrust_2D_shot_81_97.segy Now extract the time, source and receiver coordinates (in seconds and meters) for all the traces. The source and receiver vectors have a length equal to the number of traces, the time vector has a length equal to the number of rows in the data matrix. sx = [get_header(blocks[i], \"SourceX\") for i=1:length(blocks)]; rx = [get_header(blocks[i], \"GroupX\") for i=1:length(blocks)]; # Get the tme axis. In this case the time axis is the same for all traces so we only need to extract it from the first trace # dt needs to be corrected for the binary setup # All the times are in ms dt = get_header(blocks[1], \"dt\")[1]/1000 nt = get_header(blocks[1], \"ns\")[1] T = 0:dt:(nt-1)*dt 0.0:4.0:3000.0 Calculate the offset and midpoint for each trace. This gives you vectors m (midpoint) and h (offset) with length equal to the number of traces. h = (s - r)/2; m = (s + r)/2; h = (sx .- rx)./2; m = (sx .+ rx)./2; The fold of the data is the number of traces in each midpoint gather. This can be easily visualized by a histogram. As we have a set of blocks we need to inspect each block seperately to recover the nuique set of midpoint location and the total number fo traces for this midpoint all_m = hcat(m'...) fold = [sum(all_m .== unique(all_m)[i]) for i=1:length(unique(all_m))]; all_h = hcat(h'...); figure(); bar(unique(all_m),fold ,align=\"center\", width=100); xlabel(\"midpoint [m]\"); ylabel(\"fold\"); title(\"fold\"); Can you interpret this figure? Different gathers Extract a midpoint gather. For example, a midpoint gather at m = 2550 looks like this: Im = find(all_m .== 7500.) figure() imshow(Float32.(blocks[1:97].data[:, Im]), vmin=-1, vmax=1, cmap=\"Greys\", aspect=.05) PyObject <matplotlib.image.AxesImage object at 0x7f947ac9a550> Extract an offset-gather. For example, a zero-offset section looks like: # We need to sort it in physical units as the dataset may not be Ih = find(all_h .== 0.) inds = sortperm(all_m[Ih]') figure() imshow(Float32.(blocks[1:97].data[:, Ih[inds]]), vmin=-1, vmax=1, cmap=\"Greys\", aspect=.1) PyObject <matplotlib.image.AxesImage object at 0x7f947ab7f048> What other different gathers can you think of? Extract and plot an example of all the different gathers. What are characteristic properties of the different gathers? Do not forget to label the axis and choose a reasonable colorscale. Hint: use cmap=Greys and adjust the color-axis vmin/vmax","title":"Scaning the dataset"},{"location":"Assignments/Exercise2/","text":"NMO correction The traveltime as a function of offset of a reflected event can be approximated by the NMO traveltime: $ \\tau(t_0,h) = \\sqrt{t_0 + h 2/v 2} $ where \\((t_0)\\) is the zero-offset or vertical traveltime and \\(v\\) is the effective or NMO velocity. We can now correct the data for the moveout via a simple coordinate transform: $ d_{NMO}(t_0,h) = d(\\tau(t_0,h),h) $ You can use the function nmo implemented below for this exercise. using Dierckx function nmo(cmp, t, off, v) # NMO correction and adjoint # # use: # out = nmo(in,t,h,v,flag) # # input: # in - data matrix of size [length(t) x length(h)], each column is a trace # t - time vector [s] # offsets - offset vector [m] # v - NMO velocity [m/s] as vector of size [length(t) x 1]. # flag - 1:forward, -1:adjoint # # output # out - data matrix of size [length(t) x length(h)], each column is a trace # size of data nt, nh = size(cmp) # make sure t and v are column vectors t = t[:] v = v[:] # initialize output out = zeros(nt, nh) # loop over offset for i = 1:nh # NMO traveltime tau = sqrt.(t.^2 + off[i].^2./v.^2); # interpolate, forward or adjoint spl = Spline1D(t, cmp[1e-3*T.-t.<1e-5, i]) out[:,i] = spl(tau) end return out end nmo (generic function with 1 method) using SeisIO, PyPlot # read the dataset blocks = segy_read(\"/data/mlouboutin3/Class_data/cube2.segy\"); sx = get_header(blocks, \"SourceX\";scale=false) rx = get_header(blocks, \"GroupX\";scale=false); # Get the time axis. In this case the time axis is the same for all traces so we only need to extract it from the first trace # dt needs to be corrected for the binary setup # All the times are in ms dt = get_header(blocks, \"dt\")[1]/1000 nt = get_header(blocks, \"ns\")[1] T = 0:dt:(nt-1)*dt 0.0:4.0:2000.0 # Midpoint and offset h = (sx .- rx); m = (sx .+ rx)./2; all_m = hcat(m'...)' fold = [sum(all_m .== unique(all_m)[i]) for i=1:length(unique(all_m))]; all_h = hcat(h'...)'; Pick a midpoint Im = find(all_m .== all_m[1000]) offsets = sort((all_h[Im])); inds = sortperm(all_h[Im]) cmp = Float32.(blocks.data[:, Im[inds]]); figure() imshow(cmp, vmin=-1, vmax=1, cmap=\"Greys\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time') Constant velocity NMO correction nmo_corrected1 = nmo(cmp, 1e-3.*T, offsets, 2000. + 0.*T); figure() imshow(nmo_corrected1, vmin=-1, vmax=1, cmap=\"Greys\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time') Windowing We can see a lot of `artifacts' in the NMO corrected gather above. To avoid some of the artifacts, the midpoint gathers are often windowed to select reflected data only. All events that arrive before the direct wave are removed. A typical window looks like this (Hint: the slope of the triangle is related to the veloctity of the direct wave). # grid tt = [1e-3*ti for ti in T for h in offsets] hh = [h for ti in T for h in offsets] # initialize window to zero and set times later than first arrival to 1. W=0.*tt;W[tt.>(.1+ abs.(hh)./1500)] = 1 W = reshape(W, size(cmp)[2], size(cmp)[1]) imshow(W', vmin=0, vmax=1, cmap=\"jet\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time') muted = W'.*cmp; figure() imshow(muted, vmin=-1e0, vmax=1e0, cmap=\"Greys\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time') Stack power To figure out which NMO velocity optimally flattens all the events, we can scan through a range of constant NMO velocities and see which events are flattened for which velocity. One way to judge flatness of an event is via the stackpower. The stackpower is just a sum along the offset direction of the values-squared of the NMO-corrected gather: $ S(t_0,v) = \\int!!\\mathrm{d}h\\, d(\\tau(t_0,h,v),h)^2 $ The function $ S(t_0,v) $ is called a semblance panel. The desired NMO velocity can be found by picking the maximum as a function of \\(t_0\\) and \\(v\\) from the semblance panel. An example of a semblance panel and the resulting NMO velocity is shown below. v = linspace(1000, 3000, 500) # scan over velocities S = zeros(length(T),length(v)); for k = 1:length(v) cmp_nmo = nmo(muted, 1e-3.*T, offsets, v[k] .+ 0.*T); S[:,k] = sum(cmp_nmo.^2,2); end #Plot semblance panel figure() imshow(S, vmin=0, vmax=1e3, cmap=\"jet\", aspect=1, extent=[v[1], v[end], T[end], 0]) xlabel(\"velocity\") ylabel(\"tau\") PyObject Text(24,0.5,'tau') # pick v/tau pairs tv = 1e3*[0, 0.30, 0.35, 0.46, 0.65, 1.27, 2.00]; vnmo = [1500, 1500, 1600, 1700, 2000, 2179, 3000]; spl = Spline1D(tv, vnmo; k=1) vnmo_all = spl(T); Look at the velocity profile with the picked tau/v pairs # Enable gui to have the cursor and pick v/tau pairs figure() imshow(S, vmin=0, vmax=1e3, cmap=\"jet\", aspect=1, extent=[v[1], v[end], T[end], 0]) plot(vnmo_all, T, \"-k\") xlabel(\"velocity\") ylabel(\"tau\") PyObject Text(24,0.5,'tau') nmo_corrected = nmo(muted, 1e-3.*T, offsets, vnmo_all) ; figure() imshow(nmo_corrected, vmin=-1e0, vmax=1e0, cmap=\"Greys\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time') Velocity analysis Repeat the above outline procedure for a couple of mipdoint positions xm (e.g., xm = [500 1000 2000] ). Organize the resulting NMO velocities in a matrix Vm (where column i is the NMO velocity for midpoint xm[i] ) interpolate the results to obtain a velocity for all the midpoints using Spline1D(xm, VM); spl(all_m) . Plot the velocity and discuss. Using this NMO velocity, we can produce an NMO stack. Perform an NMO correction of all the midpoint gathers using the corresponding NMO velocity derived above and sum each along the offset direction. Organize all the stacks in a matrix and plot the result. Also make a stack using a constant NMO velocity. Discuss the results.","title":"NMO correction"},{"location":"Assignments/Exercise2/#nmo-correction","text":"The traveltime as a function of offset of a reflected event can be approximated by the NMO traveltime: $ \\tau(t_0,h) = \\sqrt{t_0 + h 2/v 2} $ where \\((t_0)\\) is the zero-offset or vertical traveltime and \\(v\\) is the effective or NMO velocity. We can now correct the data for the moveout via a simple coordinate transform: $ d_{NMO}(t_0,h) = d(\\tau(t_0,h),h) $ You can use the function nmo implemented below for this exercise. using Dierckx function nmo(cmp, t, off, v) # NMO correction and adjoint # # use: # out = nmo(in,t,h,v,flag) # # input: # in - data matrix of size [length(t) x length(h)], each column is a trace # t - time vector [s] # offsets - offset vector [m] # v - NMO velocity [m/s] as vector of size [length(t) x 1]. # flag - 1:forward, -1:adjoint # # output # out - data matrix of size [length(t) x length(h)], each column is a trace # size of data nt, nh = size(cmp) # make sure t and v are column vectors t = t[:] v = v[:] # initialize output out = zeros(nt, nh) # loop over offset for i = 1:nh # NMO traveltime tau = sqrt.(t.^2 + off[i].^2./v.^2); # interpolate, forward or adjoint spl = Spline1D(t, cmp[1e-3*T.-t.<1e-5, i]) out[:,i] = spl(tau) end return out end nmo (generic function with 1 method) using SeisIO, PyPlot # read the dataset blocks = segy_read(\"/data/mlouboutin3/Class_data/cube2.segy\"); sx = get_header(blocks, \"SourceX\";scale=false) rx = get_header(blocks, \"GroupX\";scale=false); # Get the time axis. In this case the time axis is the same for all traces so we only need to extract it from the first trace # dt needs to be corrected for the binary setup # All the times are in ms dt = get_header(blocks, \"dt\")[1]/1000 nt = get_header(blocks, \"ns\")[1] T = 0:dt:(nt-1)*dt 0.0:4.0:2000.0 # Midpoint and offset h = (sx .- rx); m = (sx .+ rx)./2; all_m = hcat(m'...)' fold = [sum(all_m .== unique(all_m)[i]) for i=1:length(unique(all_m))]; all_h = hcat(h'...)';","title":"NMO correction"},{"location":"Assignments/Exercise2/#pick-a-midpoint","text":"Im = find(all_m .== all_m[1000]) offsets = sort((all_h[Im])); inds = sortperm(all_h[Im]) cmp = Float32.(blocks.data[:, Im[inds]]); figure() imshow(cmp, vmin=-1, vmax=1, cmap=\"Greys\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time')","title":"Pick a midpoint"},{"location":"Assignments/Exercise2/#constant-velocity-nmo-correction","text":"nmo_corrected1 = nmo(cmp, 1e-3.*T, offsets, 2000. + 0.*T); figure() imshow(nmo_corrected1, vmin=-1, vmax=1, cmap=\"Greys\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time')","title":"Constant velocity NMO correction"},{"location":"Assignments/Exercise2/#windowing","text":"We can see a lot of `artifacts' in the NMO corrected gather above. To avoid some of the artifacts, the midpoint gathers are often windowed to select reflected data only. All events that arrive before the direct wave are removed. A typical window looks like this (Hint: the slope of the triangle is related to the veloctity of the direct wave). # grid tt = [1e-3*ti for ti in T for h in offsets] hh = [h for ti in T for h in offsets] # initialize window to zero and set times later than first arrival to 1. W=0.*tt;W[tt.>(.1+ abs.(hh)./1500)] = 1 W = reshape(W, size(cmp)[2], size(cmp)[1]) imshow(W', vmin=0, vmax=1, cmap=\"jet\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time') muted = W'.*cmp; figure() imshow(muted, vmin=-1e0, vmax=1e0, cmap=\"Greys\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time')","title":"Windowing"},{"location":"Assignments/Exercise2/#stack-power","text":"To figure out which NMO velocity optimally flattens all the events, we can scan through a range of constant NMO velocities and see which events are flattened for which velocity. One way to judge flatness of an event is via the stackpower. The stackpower is just a sum along the offset direction of the values-squared of the NMO-corrected gather: $ S(t_0,v) = \\int!!\\mathrm{d}h\\, d(\\tau(t_0,h,v),h)^2 $ The function $ S(t_0,v) $ is called a semblance panel. The desired NMO velocity can be found by picking the maximum as a function of \\(t_0\\) and \\(v\\) from the semblance panel. An example of a semblance panel and the resulting NMO velocity is shown below. v = linspace(1000, 3000, 500) # scan over velocities S = zeros(length(T),length(v)); for k = 1:length(v) cmp_nmo = nmo(muted, 1e-3.*T, offsets, v[k] .+ 0.*T); S[:,k] = sum(cmp_nmo.^2,2); end #Plot semblance panel figure() imshow(S, vmin=0, vmax=1e3, cmap=\"jet\", aspect=1, extent=[v[1], v[end], T[end], 0]) xlabel(\"velocity\") ylabel(\"tau\") PyObject Text(24,0.5,'tau') # pick v/tau pairs tv = 1e3*[0, 0.30, 0.35, 0.46, 0.65, 1.27, 2.00]; vnmo = [1500, 1500, 1600, 1700, 2000, 2179, 3000]; spl = Spline1D(tv, vnmo; k=1) vnmo_all = spl(T);","title":"Stack power"},{"location":"Assignments/Exercise2/#look-at-the-velocity-profile-with-the-picked-tauv-pairs","text":"# Enable gui to have the cursor and pick v/tau pairs figure() imshow(S, vmin=0, vmax=1e3, cmap=\"jet\", aspect=1, extent=[v[1], v[end], T[end], 0]) plot(vnmo_all, T, \"-k\") xlabel(\"velocity\") ylabel(\"tau\") PyObject Text(24,0.5,'tau') nmo_corrected = nmo(muted, 1e-3.*T, offsets, vnmo_all) ; figure() imshow(nmo_corrected, vmin=-1e0, vmax=1e0, cmap=\"Greys\", aspect=3, extent=[offsets[1], offsets[end], T[end], 0]) xlabel(\"offset\") ylabel(\"time\") PyObject Text(24,0.5,'time')","title":"Look at the velocity profile with the picked tau/v pairs"},{"location":"Assignments/Exercise2/#velocity-analysis","text":"Repeat the above outline procedure for a couple of mipdoint positions xm (e.g., xm = [500 1000 2000] ). Organize the resulting NMO velocities in a matrix Vm (where column i is the NMO velocity for midpoint xm[i] ) interpolate the results to obtain a velocity for all the midpoints using Spline1D(xm, VM); spl(all_m) . Plot the velocity and discuss. Using this NMO velocity, we can produce an NMO stack. Perform an NMO correction of all the midpoint gathers using the corresponding NMO velocity derived above and sum each along the offset direction. Organize all the stacks in a matrix and plot the result. Also make a stack using a constant NMO velocity. Discuss the results.","title":"Velocity analysis"},{"location":"Assignments/Exercise3/","text":"Exercise 3: wavefield extrapolation and migration Contents: - Wavefield extrapolation - Zero-offset migration - Prestack migration - Wavefield extrapolation For a constant-velocity medium, we can extrapolate a wavefield at depth \\(z\\) to depth \\(z+\\Delta z\\) via a simple phase shift in the \\(f-k\\) domain: $ u(\\omega,k,z + \\Delta z) = u(\\omega,k,z)\\exp[\\imath\\Delta z\\sqrt(\\omega 2/v 2 - k^2)]$ To illustrate this, we generate a source wavefield in the \\(t-x\\) domain and extrapolate it. First, let's define an impulsive source. using PyPlot f-k domain transform function fktran function fktran(a,t,x,mode) \"\"\" f-k transform for real-values input. use: b, f, k = fktran(a,t,x,mode) input: a - matrix in t-x domain (nt x nx) t - time vector x - x vector mode - 1:forward, -1:inverse \"\"\" nt = length(t) nx = length(x) dt = t[2]-t[1] dx = x[2] - x[1] xmax = x[end] - x[1] tmax = t[end] - t[1] f = 0:1/tmax:.5/dt k = -.5/dx:1/xmax:.5/dx nf = length(f) if mode == 1 b = fft(a, 1) b = b[1:nf, :] b = ifft(b, 2) b = circshift(b,[0 ceil(Int, nx/2)-1]); elseif mode == -1 b = circshift(a,[0 floor(Int, nx/2)+1]); b = fft(b, 2) b = ifft(b, 1) b = real(b) else error(\"unknown mode\") end return b, f, k end fktran (generic function with 1 method) # time coordinate in seconds as column vector t = 0:.004:1; # spatial coordinate in meters as row vector x = 0:10:1000; # generate 2D grid: tt = [ti for ti in t, xi in x]; xx = [xi for ti in t, xi in x]; # Source wavefield is impulsive source at t=0.1 and x=500, source = (tt-.1).*exp.(-1e-3*(xx.-500).^2 .- 1e3*(tt-.1).^2); # plot it imshow(source, cmap=\"Greys\", extent=[x[1], x[end], t[end], t[1]], aspect=500) xlabel(\"x [m]\") ylabel(\"t [s]\") title(\"wavefield at z=0 m.\") PyObject Text(0.5,1,'wavefield at z=0 m.') # now, transform it to the f-k domain using fktran source_fk, f, k = fktran(source,t,x,1); Next, we define the extrapolation factor and plot it. # generate a grid for f,k ff = [fi for fi in f, ki in k] kk = [ki for fi in f, ki in k] # the extrapolation factor for a velocity v is defined as follows # (note the factor \\(2 pi\\) to go from frequency to wavenumber) v = 2000 dz = 10 kz = 2*pi*sqrt.(complex.((ff./v).^2 - kk.^2)) W = exp.(dz*im.*kz) # now plot absolute value for 10 Hz plot(k,abs.(W[ff.==10])) xlabel(\"k [1/m]\");ylabel(\"|W|\");title(\"|W| @ 10 Hz.\"); The region where the extrapolation factor is smaller than one is called the evanescent region. Waves this these wavenumbers will be damped. We have to be carefull with the sign of \\(k_z\\) in the exponentional factor and make sure that the absolute value is always smaller than one. The wavefield at z = 500 m looks like # fix sign of kz kz = -real(kz)+im*abs.(imag(kz)); W = exp.(500*im.*kz); # extrapolate and transform back to t-x source_extrap, _, _ = fktran(W.*source_fk,t,x,-1); #plot imshow(real(source_extrap), cmap=\"Greys\", vmin=-.1e-2, vmax=.1e-2, extent=[x[1], x[end], t[end], t[1]], aspect=700) xlabel(\"x [m]\") ylabel(\"t [s]\") title(\"wavefield at z=500 m.\") PyObject Text(0.5,1,'wavefield at z=500 m.') Questions What happens if the imaginary part of kz has the wrong sign? try it. same for the real part. What does the extrapolator look like in the t-x domain? How can you extraplotate the wavefield in the t-x domain directly using the extrapolator in the t-x domain? Zero-offset migration In this part of the exercise we look at zero-offset migration. This type of migration is based on the \"exploding-reflector\" concept. Zero-offset migration can be done by exptrapolating the zero-offset data with half-velocity and taking the image to be slice of the wavefield at \\(t=0\\) for each depth step: \\(I(z,x) = u(z,x,t=0)\\) The function wave_extrap.m takes in a wavefield u and the correspoding time/space vectors t,x, a velocity v, a depth step dz and a propagation direction dir and extrapolates the input wavefield. Load the zero-offset data data1_zero.segy (in Dropbox) and define the source, receiver and time coordinates. The units of the source and receiver coordinates are in meters for this file. The data looks like this using SeisIO # Dowload and adapt path shot = segy_read(\"data_zo.segy\") shot_data = Float32.(shot.data) sx = get_header(shot, \"SourceX\", scale=false) dt = get_header(shot, \"dt\")[1]/1e6 nt = get_header(shot, \"ns\")[1] T = 0:dt:(nt -1)*dt \u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mFixed length trace flag set in stream: IOBuffer(data=UInt8[...], readable=true, writable=false, seekable=true, append=false, size=253644, maxsize=Inf, ptr=3601, mark=-1)\u001b[39m 0.0:0.004:1.0 imshow(shot_data, vmin=-.1, vmax=.1, cmap=\"Greys\", extent=[sx[1], sx[end], T[end], T[1]], aspect=1000) xlabel(\"source position [m]\") ylabel(\"t [s]\") PyObject Text(24,0.5,'t [s]') Use the function wave_extrap to migrate the zero offset section. A reasonable depth axis is z = 0:5:1000. Use the source position as lateral position x. The correct velocity is v0 = 2000 km/s (but, remember this is zero-offset migration so adapt the velocity accordingly!). A zero-offset migration can done as follows: function wave_extrap(u,t,x,v,dz,dir) # wavefield extrapolation by phase shift # # use: # v = wave_extrap(u,t,x,v,dz,dir) # # input: # u - wavefield as matrix of size length(t) x length(x) # t - time coordinates in seconds as column vector # x - space coordinates in meters as row vector # v - velocity in m/s (scalar) # dz - depth step in meters # dir - 1: forward in time, -1 backward in time # # output: # v - extrapolated wavefield # # fk transform of the wavefield spec, f, k = fktran(u, t, x, 1) # define grid and kz ff = [fi for fi in f, ki in k] kk = [ki for fi in f, ki in k] kz = 2*pi*sqrt.(complex((ff/v).^2-kk.^2)) # set sign of real part of kz kz = -sign.(dir)*real(kz)+im*abs.(imag(kz)) # apply phase shift spec = exp.(im*abs.(dz).*kz).*spec # inverse fk transform v, _, _ = fktran(spec, f, k, -1) # take real part of wavefield v = real(v) return v end wave_extrap (generic function with 1 method) # depth axis z = 0:5:1000 dz = 5 # velocity v = 2000 # migrate for correct velocity migcorr = zeros(length(z),length(sx)) for k = 1:length(z) tmp = wave_extrap(shot_data, T, sx, v./2, z[k], -1) migcorr[k, :] = tmp[1, :] end # plot it imshow(migcorr, cmap=\"Greys\", vmin=-.1, vmax=.1, extent=[sx[1], sx[end], z[end], z[1]], aspect=1) xlabel(\"x [m]\") ylabel(\"z [m]\") title(\"correct velocity\") PyObject Text(0.5,1,'correct velocity') Questions Compare the migrated result to the zero-offset section. What do you notice? For easier comparison, you might want to transform the time axis into depth using the correct velocity. Do a zero-offset migration for too low and too high velocities. What do you notice? Repeat the same exercise for data2_zo.su. What do you notice here? Prestack migration We can also create an image by extrapolating the source wavefields and the data and correlating them at different depth levels. Read the data data_ex3.segy (in Dropbox) block = segy_read(\"data_ex3.segy\") sx = get_header(block, \"SourceX\", scale=false) rx = get_header(block, \"GroupX\", scale=false) dt = get_header(block, \"dt\")[1]/1e6 nt = get_header(block, \"ns\")[1] T = 0:dt:(nt -1)*dt # unique src/rec locations xs = unique(sx) xr = unique(rx); \u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mFixed length trace flag set in stream: IOBuffer(data=UInt8[...], readable=true, writable=false, seekable=true, append=false, size=1385684, maxsize=Inf, ptr=3601, mark=-1)\u001b[39m We extrapolate both source and receiver wavefields for one shot using wave_extrap (see comments in wave_extrap for documenation) and plot them side-by-side: # velocity v = 2000; # t-x grid tt = [ti for ti in T, xi in xr]; xx = [xi for ti in T, xi in xr]; # choose shot 6 is = 6 # source wavefield at z=0 source = (tt-.1).*exp.(-1e-3*(xx-xs[is]).^2 - 1e3*(tt-.1).^2); # receiver wavefield is data for corresponding shot receiver = Float32.(block.data[:, sx.==xs[is]]); imshow(wave_extrap(source,t,xr,v,500,1), cmap=\"Greys\", vmin=-.001, vmax=.001, extent=[xr[1], xr[end], T[end], T[1]], aspect=500) xlabel(\"x [m]\") ylabel(\"t [s]\") title(\"source wavefield at z=500 m.\") figure() imshow(wave_extrap(receiver,t,xr,v,500,-1), cmap=\"Greys\", vmin=-1, vmax=1, extent=[xr[1], xr[end], T[end], T[1]], aspect=500) xlabel(\"x [m]\") ylabel(\"t [s]\") title(\"receiver wavefield at z=500 m.\") PyObject Text(0.5,1,'receiver wavefield at z=500 m.') Question Extrapolate both source and receiver wavefields to differents depths. What do you notice? An image of the reflector can be constructed by correlating the two wavefields at zero time-lag (basically summing over time) # velocity v = 2e3 # depth dz = 10 z = 0:dz:1000 # initialize image image = zeros(length(z),length(xr)) # loop for iz = 1:length(z) shoti = wave_extrap(source, T, xr, v, z[iz], 1) reci = wave_extrap(receiver, T, xr, v, z[iz], -1) image[iz,:] = sum(shoti.*reci, 1) end figure() imshow(image, cmap=\"Greys\", vmin=-1e-2, vmax=1e-2, extent=[xr[1], xr[end], z[end], z[1]], aspect=1) xlabel(\"x [m]\") ylabel(\"z [m]\") title(\"image for one source\") PyObject Text(0.5,1,'image for one source') Questions Use the template mig_extrap below and implement migration of multiple shots based on the above outlined algorithm by filling in the gaps. You can call wave_extrap as subroutine. Use mig_extrap.m for the following exercises. Migrate a single shot for velocities that are too low and too high (say 10 percent). What do you see? Repeat this for all sources and sum the images for all sources, again also for too low/high velocity. What do you see? Describe how you would adapt the migration algorithm for a velocity that varies with depth. function mig_extrap(data, t, xr, xs, z, v) # # shot-receiver migration for constant velocity by wavefield extrapolation. # # use: # image = mig_extrap(data,t,xr,xs,v) # # input: # data - data cube of size length(t) x length(xr) x length(xs) # t - time coordinate in seconds as column vector # xr - receiver coordinate in meters as row vector # xs - source coordinate in meters as row vector # z - depth coordinate in meters as column vector # v - velocity in m/s (scalar) # # output: # image - image as matrix of size length(z) x length(xr) # initialize image image = zeros(length(z),length(xr)); # depth step dz = z[2] - z[1] # t-x grid tt = [ti for ti in t, xi in xr] xx = [xi for ti in t, xi in xr] # loop over shots for is = 1:length(xs) # construct impulsive source at source location source = (tt-.1).*exp.(-1e-3*(xx-xs[is]).^2 - 1e3*(tt-.1).^2); # select data beloning to source is receiver = # loop over depth levels for iz = 1:length(z) # use wave_extrap to advance both wavefields one depthlevel srci = reci = # update image image[iz,:] = image[iz,:] + end # end loop over depth levels end # end loop over shots return image end","title":"Exercise 3: wavefield extrapolation and migration"},{"location":"Assignments/Exercise3/#exercise-3-wavefield-extrapolation-and-migration","text":"Contents: - Wavefield extrapolation - Zero-offset migration - Prestack migration - Wavefield extrapolation For a constant-velocity medium, we can extrapolate a wavefield at depth \\(z\\) to depth \\(z+\\Delta z\\) via a simple phase shift in the \\(f-k\\) domain: $ u(\\omega,k,z + \\Delta z) = u(\\omega,k,z)\\exp[\\imath\\Delta z\\sqrt(\\omega 2/v 2 - k^2)]$ To illustrate this, we generate a source wavefield in the \\(t-x\\) domain and extrapolate it. First, let's define an impulsive source. using PyPlot","title":"Exercise 3: wavefield extrapolation and migration"},{"location":"Assignments/Exercise3/#f-k-domain-transform-function-fktran","text":"function fktran(a,t,x,mode) \"\"\" f-k transform for real-values input. use: b, f, k = fktran(a,t,x,mode) input: a - matrix in t-x domain (nt x nx) t - time vector x - x vector mode - 1:forward, -1:inverse \"\"\" nt = length(t) nx = length(x) dt = t[2]-t[1] dx = x[2] - x[1] xmax = x[end] - x[1] tmax = t[end] - t[1] f = 0:1/tmax:.5/dt k = -.5/dx:1/xmax:.5/dx nf = length(f) if mode == 1 b = fft(a, 1) b = b[1:nf, :] b = ifft(b, 2) b = circshift(b,[0 ceil(Int, nx/2)-1]); elseif mode == -1 b = circshift(a,[0 floor(Int, nx/2)+1]); b = fft(b, 2) b = ifft(b, 1) b = real(b) else error(\"unknown mode\") end return b, f, k end fktran (generic function with 1 method) # time coordinate in seconds as column vector t = 0:.004:1; # spatial coordinate in meters as row vector x = 0:10:1000; # generate 2D grid: tt = [ti for ti in t, xi in x]; xx = [xi for ti in t, xi in x]; # Source wavefield is impulsive source at t=0.1 and x=500, source = (tt-.1).*exp.(-1e-3*(xx.-500).^2 .- 1e3*(tt-.1).^2); # plot it imshow(source, cmap=\"Greys\", extent=[x[1], x[end], t[end], t[1]], aspect=500) xlabel(\"x [m]\") ylabel(\"t [s]\") title(\"wavefield at z=0 m.\") PyObject Text(0.5,1,'wavefield at z=0 m.') # now, transform it to the f-k domain using fktran source_fk, f, k = fktran(source,t,x,1); Next, we define the extrapolation factor and plot it. # generate a grid for f,k ff = [fi for fi in f, ki in k] kk = [ki for fi in f, ki in k] # the extrapolation factor for a velocity v is defined as follows # (note the factor \\(2 pi\\) to go from frequency to wavenumber) v = 2000 dz = 10 kz = 2*pi*sqrt.(complex.((ff./v).^2 - kk.^2)) W = exp.(dz*im.*kz) # now plot absolute value for 10 Hz plot(k,abs.(W[ff.==10])) xlabel(\"k [1/m]\");ylabel(\"|W|\");title(\"|W| @ 10 Hz.\"); The region where the extrapolation factor is smaller than one is called the evanescent region. Waves this these wavenumbers will be damped. We have to be carefull with the sign of \\(k_z\\) in the exponentional factor and make sure that the absolute value is always smaller than one. The wavefield at z = 500 m looks like # fix sign of kz kz = -real(kz)+im*abs.(imag(kz)); W = exp.(500*im.*kz); # extrapolate and transform back to t-x source_extrap, _, _ = fktran(W.*source_fk,t,x,-1); #plot imshow(real(source_extrap), cmap=\"Greys\", vmin=-.1e-2, vmax=.1e-2, extent=[x[1], x[end], t[end], t[1]], aspect=700) xlabel(\"x [m]\") ylabel(\"t [s]\") title(\"wavefield at z=500 m.\") PyObject Text(0.5,1,'wavefield at z=500 m.')","title":"f-k domain transform function fktran"},{"location":"Assignments/Exercise3/#questions","text":"What happens if the imaginary part of kz has the wrong sign? try it. same for the real part. What does the extrapolator look like in the t-x domain? How can you extraplotate the wavefield in the t-x domain directly using the extrapolator in the t-x domain?","title":"Questions"},{"location":"Assignments/Exercise3/#zero-offset-migration","text":"In this part of the exercise we look at zero-offset migration. This type of migration is based on the \"exploding-reflector\" concept. Zero-offset migration can be done by exptrapolating the zero-offset data with half-velocity and taking the image to be slice of the wavefield at \\(t=0\\) for each depth step: \\(I(z,x) = u(z,x,t=0)\\) The function wave_extrap.m takes in a wavefield u and the correspoding time/space vectors t,x, a velocity v, a depth step dz and a propagation direction dir and extrapolates the input wavefield. Load the zero-offset data data1_zero.segy (in Dropbox) and define the source, receiver and time coordinates. The units of the source and receiver coordinates are in meters for this file. The data looks like this using SeisIO # Dowload and adapt path shot = segy_read(\"data_zo.segy\") shot_data = Float32.(shot.data) sx = get_header(shot, \"SourceX\", scale=false) dt = get_header(shot, \"dt\")[1]/1e6 nt = get_header(shot, \"ns\")[1] T = 0:dt:(nt -1)*dt \u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mFixed length trace flag set in stream: IOBuffer(data=UInt8[...], readable=true, writable=false, seekable=true, append=false, size=253644, maxsize=Inf, ptr=3601, mark=-1)\u001b[39m 0.0:0.004:1.0 imshow(shot_data, vmin=-.1, vmax=.1, cmap=\"Greys\", extent=[sx[1], sx[end], T[end], T[1]], aspect=1000) xlabel(\"source position [m]\") ylabel(\"t [s]\") PyObject Text(24,0.5,'t [s]') Use the function wave_extrap to migrate the zero offset section. A reasonable depth axis is z = 0:5:1000. Use the source position as lateral position x. The correct velocity is v0 = 2000 km/s (but, remember this is zero-offset migration so adapt the velocity accordingly!). A zero-offset migration can done as follows: function wave_extrap(u,t,x,v,dz,dir) # wavefield extrapolation by phase shift # # use: # v = wave_extrap(u,t,x,v,dz,dir) # # input: # u - wavefield as matrix of size length(t) x length(x) # t - time coordinates in seconds as column vector # x - space coordinates in meters as row vector # v - velocity in m/s (scalar) # dz - depth step in meters # dir - 1: forward in time, -1 backward in time # # output: # v - extrapolated wavefield # # fk transform of the wavefield spec, f, k = fktran(u, t, x, 1) # define grid and kz ff = [fi for fi in f, ki in k] kk = [ki for fi in f, ki in k] kz = 2*pi*sqrt.(complex((ff/v).^2-kk.^2)) # set sign of real part of kz kz = -sign.(dir)*real(kz)+im*abs.(imag(kz)) # apply phase shift spec = exp.(im*abs.(dz).*kz).*spec # inverse fk transform v, _, _ = fktran(spec, f, k, -1) # take real part of wavefield v = real(v) return v end wave_extrap (generic function with 1 method) # depth axis z = 0:5:1000 dz = 5 # velocity v = 2000 # migrate for correct velocity migcorr = zeros(length(z),length(sx)) for k = 1:length(z) tmp = wave_extrap(shot_data, T, sx, v./2, z[k], -1) migcorr[k, :] = tmp[1, :] end # plot it imshow(migcorr, cmap=\"Greys\", vmin=-.1, vmax=.1, extent=[sx[1], sx[end], z[end], z[1]], aspect=1) xlabel(\"x [m]\") ylabel(\"z [m]\") title(\"correct velocity\") PyObject Text(0.5,1,'correct velocity')","title":"Zero-offset migration"},{"location":"Assignments/Exercise3/#questions_1","text":"Compare the migrated result to the zero-offset section. What do you notice? For easier comparison, you might want to transform the time axis into depth using the correct velocity. Do a zero-offset migration for too low and too high velocities. What do you notice? Repeat the same exercise for data2_zo.su. What do you notice here?","title":"Questions"},{"location":"Assignments/Exercise3/#prestack-migration","text":"We can also create an image by extrapolating the source wavefields and the data and correlating them at different depth levels. Read the data data_ex3.segy (in Dropbox) block = segy_read(\"data_ex3.segy\") sx = get_header(block, \"SourceX\", scale=false) rx = get_header(block, \"GroupX\", scale=false) dt = get_header(block, \"dt\")[1]/1e6 nt = get_header(block, \"ns\")[1] T = 0:dt:(nt -1)*dt # unique src/rec locations xs = unique(sx) xr = unique(rx); \u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mFixed length trace flag set in stream: IOBuffer(data=UInt8[...], readable=true, writable=false, seekable=true, append=false, size=1385684, maxsize=Inf, ptr=3601, mark=-1)\u001b[39m We extrapolate both source and receiver wavefields for one shot using wave_extrap (see comments in wave_extrap for documenation) and plot them side-by-side: # velocity v = 2000; # t-x grid tt = [ti for ti in T, xi in xr]; xx = [xi for ti in T, xi in xr]; # choose shot 6 is = 6 # source wavefield at z=0 source = (tt-.1).*exp.(-1e-3*(xx-xs[is]).^2 - 1e3*(tt-.1).^2); # receiver wavefield is data for corresponding shot receiver = Float32.(block.data[:, sx.==xs[is]]); imshow(wave_extrap(source,t,xr,v,500,1), cmap=\"Greys\", vmin=-.001, vmax=.001, extent=[xr[1], xr[end], T[end], T[1]], aspect=500) xlabel(\"x [m]\") ylabel(\"t [s]\") title(\"source wavefield at z=500 m.\") figure() imshow(wave_extrap(receiver,t,xr,v,500,-1), cmap=\"Greys\", vmin=-1, vmax=1, extent=[xr[1], xr[end], T[end], T[1]], aspect=500) xlabel(\"x [m]\") ylabel(\"t [s]\") title(\"receiver wavefield at z=500 m.\") PyObject Text(0.5,1,'receiver wavefield at z=500 m.')","title":"Prestack migration"},{"location":"Assignments/Exercise3/#question","text":"Extrapolate both source and receiver wavefields to differents depths. What do you notice? An image of the reflector can be constructed by correlating the two wavefields at zero time-lag (basically summing over time) # velocity v = 2e3 # depth dz = 10 z = 0:dz:1000 # initialize image image = zeros(length(z),length(xr)) # loop for iz = 1:length(z) shoti = wave_extrap(source, T, xr, v, z[iz], 1) reci = wave_extrap(receiver, T, xr, v, z[iz], -1) image[iz,:] = sum(shoti.*reci, 1) end figure() imshow(image, cmap=\"Greys\", vmin=-1e-2, vmax=1e-2, extent=[xr[1], xr[end], z[end], z[1]], aspect=1) xlabel(\"x [m]\") ylabel(\"z [m]\") title(\"image for one source\") PyObject Text(0.5,1,'image for one source')","title":"Question"},{"location":"Assignments/Exercise3/#questions_2","text":"Use the template mig_extrap below and implement migration of multiple shots based on the above outlined algorithm by filling in the gaps. You can call wave_extrap as subroutine. Use mig_extrap.m for the following exercises. Migrate a single shot for velocities that are too low and too high (say 10 percent). What do you see? Repeat this for all sources and sum the images for all sources, again also for too low/high velocity. What do you see? Describe how you would adapt the migration algorithm for a velocity that varies with depth. function mig_extrap(data, t, xr, xs, z, v) # # shot-receiver migration for constant velocity by wavefield extrapolation. # # use: # image = mig_extrap(data,t,xr,xs,v) # # input: # data - data cube of size length(t) x length(xr) x length(xs) # t - time coordinate in seconds as column vector # xr - receiver coordinate in meters as row vector # xs - source coordinate in meters as row vector # z - depth coordinate in meters as column vector # v - velocity in m/s (scalar) # # output: # image - image as matrix of size length(z) x length(xr) # initialize image image = zeros(length(z),length(xr)); # depth step dz = z[2] - z[1] # t-x grid tt = [ti for ti in t, xi in xr] xx = [xi for ti in t, xi in xr] # loop over shots for is = 1:length(xs) # construct impulsive source at source location source = (tt-.1).*exp.(-1e-3*(xx-xs[is]).^2 - 1e3*(tt-.1).^2); # select data beloning to source is receiver = # loop over depth levels for iz = 1:length(z) # use wave_extrap to advance both wavefields one depthlevel srci = reci = # update image image[iz,:] = image[iz,:] + end # end loop over depth levels end # end loop over shots return image end","title":"Questions"},{"location":"Assignments/Exercise4/","text":"Exercise 4: Fourier and Radon filtering In this exercise we will look at seismic data in different domains and investigate how we can exploit behaviour of different kinds of noise in these domains to design filters. Contents: - Data - Temporal Fourier transform - f-k filtering - Radon transform - Parabolic Radon transform using PyPlot, SeisIO Data We use a single midpoint gather of the data used in the previous exercises: shot.segy (no big endian this time). # Dowload and adapt path shot = segy_read(\"./data_segy/shot.segy\") shot_data = Float32.(shot.data) h = get_header(shot, \"SourceX\", scale=false) - get_header(shot, \"GroupX\", scale=false) dt = get_header(shot, \"dt\")[1]/1e6 nt = get_header(shot, \"ns\")[1] T = 0:dt:(nt -1)*dt BinaryFileHeader: Job: 1 Line: 1 Reel: 1 DataTracePerEnsemble: 1 AuxiliaryTracePerEnsemble: 0 dt: 4000 dtOrig: 0 ns: 1001 nsOrig: 0 DataSampleFormat: 1 EnsembleFold: 0 TraceSorting: 0 VerticalSumCode: 0 SweepFrequencyStart: 0 SweepFrequencyEnd: 0 SweepLength: 0 SweepType: 0 SweepChannel: 0 SweepTaperlengthStart: 0 SweepTaperLengthEnd: 0 TaperType: 0 CorrelatedDataTraces: 0 BinaryGain: 0 AmplitudeRecoveryMethod: 0 MeasurementSystem: 0 ImpulseSignalPolarity: 0 VibratoryPolarityCode: 0 SegyFormatRevisionNumber: 0 FixedLengthTraceFlag: 0 NumberOfExtTextualHeaders: 0 1705444 3600 1001 \u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mFixed length trace flag set in stream: IOBuffer(data=UInt8[...], readable=true, writable=false, seekable=true, append=false, size=1705444, maxsize=Inf, ptr=3601, mark=-1)\u001b[39m 0.0:0.004:4.0 imshow(shot_data, vmin=-1, vmax=1, cmap=\"Greys\", extent=[h[end], h[1], T[end], T[1]], aspect=1000) xlabel(\"offset [m]\");ylabel(\"time [s]\"); Temporal Fourier transform We can use fftrl to perform a Fourier transform along the temporal direction. The power spectrum (i.e., the absolute value of the transformed data) looks like function fftrl(a, t, mode) # fft for real-valued vectors # # Tristan van Leeuwen, 2012 # tleeuwen@eos.ubc.ca # # use: # [b,f] = fftrl(a,t,mode) # # input: # a - input data # t - time vector # mode: 1: forward, -1:inverse # # output: # b - vector nt = length(t) dt = t[2] - t[1] nf = Int(floor(nt/2)) + 1 tmax = t[end] - t[1] f = 0:1/tmax:.5/dt if mode == 1 b = fft(a,1) b = b[1:nf,:] elseif mode == -1 a = [a;conj(a[Int(ceil(nt/2)):-1:2,:])] b = ifft(a, 1) b = real(b) else error(\"Unknown mode\") end return b, f end fftrl (generic function with 1 method) Data_fh, f = fftrl(shot_data, T, 1) (Complex{Float32}[0.684434+0.0im 0.971781+0.0im \u2026 0.0969428+0.0im 0.00433278+0.0im; -0.701183-0.451787im -0.412326-0.460599im \u2026 -1.3078-0.497307im -1.40236-0.48802im; \u2026 ; -0.121274+0.000705719im -0.0863834-0.000402451im \u2026 0.157795-0.00114059im 0.110151-0.000276089im; -0.122033+0.000601768im -0.0849152-0.000236511im \u2026 0.159012-0.000580788im 0.109696-0.000192404im], 0.0:0.25:125.0) imshow(abs.(Data_fh), cmap=\"jet\", extent=[h[end], h[1], f[end], f[1]], aspect=20) xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') f-k filtering A Fourier transform along both time and offset direction is often referred to as an transform. We can use fktran. The powerspectrum looks like function fktran(a,t,x,mode) \"\"\" f-k transform for real-values input. use: b, f, k = fktran(a,t,x,mode) input: a - matrix in t-x domain (nt x nx) t - time vector x - x vector mode - 1:forward, -1:inverse \"\"\" nt = length(t) nx = length(x) dt = t[2]-t[1] dx = x[2] - x[1] xmax = x[end] - x[1] tmax = t[end] - t[1] f = 0:1/tmax:.5/dt k = -.5/dx:1/xmax:.5/dx nf = length(f) if mode == 1 b = fft(a, 1) b = b[1:nf, :] b = ifft(b, 2) b = circshift(b,[0 ceil(Int, nx/2)-1]); elseif mode == -1 b = circshift(a,[0 floor(Int, nx/2)+1]); b = fft(b, 2) b = ifft(b, 1) b = real(b) else error(\"unknown mode\") end return b, f, k end fktran (generic function with 1 method) Data_fk, fk, kx = fktran(shot_data, T, h, 1) (Complex{Float32}[0.00217381+0.375868im -0.00371527-0.375896im \u2026 -0.00371557+0.375898im 0.00217354-0.375864im; -0.0666401+0.378171im 0.0651375-0.378642im \u2026 -0.072564+0.377115im 0.0710575-0.377542im; \u2026 ; 0.00330043+0.400901im -0.00697034-0.400875im \u2026 -0.0029994+0.40092im -0.000692182-0.400906im; 0.00196619+0.400894im -0.00564895-0.400912im \u2026 -0.00433144+0.400905im 0.000641863-0.400899im], 0.0:0.25:125.0, 0.05:-0.00025:-0.05) imshow(abs.(Data_fk), cmap=\"jet\", extent=[kx[end], kx[1], f[end], f[1]], aspect=.001) xlabel(\"wavenumber [1/m\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') Questions: Subsample the data in the offset direction and look at the Fourier transform. (Hint: use Data[:,1:n:end] and h[1:n:end] where n is the number of times you want to subsample). What do you see? Why is it important to have a good receiver sampling? A filter is simply a multiplicative factor applied in some transform domain, typically \\(f-h\\) or \\(f-k\\) , followed by an inverse transform. For example, a band-pass filter in the \\(f-h\\) domain filters out higher temporal frequencies by setting them to zero. A simple band-pass filter looks like this: F_hp = ones(length(f),length(h)) F_hp[(f.<5) .| (f.>20.),:] = 0 imshow(F_hp, extent=[h[end], h[1], f[end], f[1]], aspect=20) colorbar() xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') The filtered data looks like this imshow(fftrl(F_hp.*Data_fh, f, -1)[1], cmap=\"Greys\", vmin=-1, vmax=1, extent=[h[end], h[1], T[end], T[1]], aspect=1000) xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') Do you see the artifacts? A way to reduce these artifacts is to smooth the filter. We can do this by convolving the filter with a triangular smoothing kernel. This is implemented in the function smooth_2D. The result looks like this: # Pkg.add(\"Images\") of you do not alread yhave it using Images function smooth_2D(input, n1, n2) t1 = [1:n1; n1-1:-1:1]/n1^2 t2 = [1:n2; n2-1:-1:1]/n2^2 kernel = t1 * t2' return imfilter(input, centered(kernel)) end smooth_2D (generic function with 1 method) F_hp_smooth = smooth_2D(F_hp, 5, 1) imshow(F_hp_smooth, extent=[h[end], h[1], f[end], f[1]], aspect=20) colorbar() xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') imshow(fftrl(F_hp_smooth.*Data_fh, f, -1)[1], cmap=\"Greys\", vmin=-1, vmax=1, extent=[h[end], h[1], T[end], T[1]], aspect=1000) xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') A (smoothed) filter in the \\(f-k\\) domain may look like this ff = [fi for fi in f, kxi in kx] kkx = [kxi for fi in f, kxi in kx] F_kx = zeros(length(fk),length(kx)) F_kx[(ff -1e3 * abs.(kkx) .> 5) .& (ff.<60)] = 1 F_kx = smooth_2D(F_kx, 5, 5) imshow(F_kx, cmap=\"jet\", extent=[kx[end], kx[1], f[end], f[1]], aspect=.001) xlabel(\"wavenumber [1/m\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') Questions Describe how you would design filters to clean up shot gathers shot_noise1 and shot_noise2. (hint: look the f-k transform and compare to the orinigal data) Try it and compare the result with the original shot gather. Radon transform The Radon tranform performs sums along lines with different intercepts \\(\\tau\\) ) and slopes \\(p\\) . Hence, it is sometimes refered to as the \\(\\tau-p\\) transform in geophysics. \\(\\hat{d}(\\tau,p) = \\int\\mathrm{d}h\\, d(t + ph, h)\\) The transform is implemented in the function lpradon. To get an idea of what this transform does, we consider the simple example in lines.segy. function lpradon(input, t, h, q, power, mode) # linear and parabolic Radon transform and its adjoint. # # Tristan van Leeuwen, 2012 # tleeuwen@eos.ubc.ca # # use: # out = lpradon(input,t,h,q,power,mode) # # input: # input - input matrix of size (length(t) x length(h)) for forward, (length(t) x length(q)) for adjoint) # t - time vector in seconds # h - offset vecror in meters # q - radon parameter # power - 1: linear radon, 2: parabolic radon # mode - 1: forward, -1: adjoint # # output: println(size(L)) # output matrix of size (length(t) x length(q)) for forward, (length(t) x length(h)) for adjoint) # # dt = t[2] - t[1] nt = length(t) nh = length(h) nq = length(q) nfft = 2*(nextpow2(nt)) input_padded = zeros(nfft, size(input)[2]) input_padded[1:size(input)[1], :] = input[:, :] if mode == 1 input_padded = fft(input_padded, 1) out = zeros(Complex{Float64}, nfft, nq) for k = 2:Int(floor(nfft/2)) f = 2.*pi*(k-1)/nfft/dt L = exp.(im*f*(h.^power)*q') tmp = input_padded[k,:].'*L out[k,:] = tmp out[nfft + 2 - k, :] = conj(tmp) end out = real(ifft(out, 1)) out = out[1:nt, :] else input_padded = fft(input_padded,1) out = zeros(Complex{Float64}, nfft, nh) for k = 2:Int(floor(nfft/2)) f = 2.*pi*(k-1)/nfft/dt L = exp.(im*f*(h.^power)*q') tmp = input_padded[k,:].'*L' out[k,:] = tmp out[nfft+2-k,:] = conj(tmp) end out = real(ifft(out,1)) out = out[1:nt, :] end return out end lpradon (generic function with 1 method) # Dowload and adapt path shot_radon = segy_read(\"./data_segy/lines.segy\") A = Float32.(shot_radon.data) h = get_header(shot_radon, \"SourceX\", scale=false) - get_header(shot, \"GroupX\", scale=false) dt = get_header(shot_radon, \"dt\")[1]/1e6 nt = get_header(shot_radon, \"ns\")[1] T = 0:dt:(nt -1)*dt BinaryFileHeader: Job: 1 Line: 1 Reel: 1 DataTracePerEnsemble: 1 AuxiliaryTracePerEnsemble: 0 dt: 4000 dtOrig: 0 ns: 1001 nsOrig: 0 DataSampleFormat: 1 EnsembleFold: 0 TraceSorting: 0 VerticalSumCode: 0 SweepFrequencyStart: 0 SweepFrequencyEnd: 0 SweepLength: 0 SweepType: 0 SweepChannel: 0 SweepTaperlengthStart: 0 SweepTaperLengthEnd: 0 TaperType: 0 CorrelatedDataTraces: 0 BinaryGain: 0 AmplitudeRecoveryMethod: 0 MeasurementSystem: 0 ImpulseSignalPolarity: 0 VibratoryPolarityCode: 0 SegyFormatRevisionNumber: 0 FixedLengthTraceFlag: 0 NumberOfExtTextualHeaders: 0 1705444 3600 1001 \u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mFixed length trace flag set in stream: IOBuffer(data=UInt8[...], readable=true, writable=false, seekable=true, append=false, size=1705444, maxsize=Inf, ptr=3601, mark=-1)\u001b[39m 0.0:0.004:4.0 imshow(A, vmin=-.1, vmax=.1, cmap=\"Greys\", extent=[h[end], h[1], T[end], T[1]], aspect=1000) xlabel(\"offset [m]\");ylabel(\"time [s]\"); # which p-values p = 1e-3.*(-3:.05:3) # transform A_tp = lpradon(A, T, h, p, 1, 1) 1001\u00d7121 Array{Float64,2}: 0.000378078 0.000384182 0.000384585 \u2026 0.000202505 0.000644788 0.000376368 0.000389721 0.00037549 0.000144312 0.000541559 0.000387413 0.000381872 0.000383162 0.000133913 0.000409034 0.000390602 0.000388732 0.000380008 0.000201181 0.000262995 0.00040214 0.000383436 0.000392553 0.000302437 0.000157082 0.00040122 0.000393219 0.000391394 \u2026 0.000439509 0.000100834 0.000405988 0.000390277 0.000402393 0.000551232 0.000125599 0.000398302 0.000401124 0.000397027 0.000636942 0.000208975 0.00039937 0.000397851 0.000403059 0.000648591 0.000347769 0.00039261 0.000407363 0.000394245 0.000611003 0.000491774 0.00039947 0.000402683 0.000400071 \u2026 0.000507467 0.000622865 0.000401411 0.000411663 0.000394785 0.00039216 0.000693264 0.000417296 0.000408056 0.000406892 0.000268286 0.000703196 \u22ee \u22f1 \u22ee 0.000378107 0.000381697 -0.000934809 0.000386704 0.000286472 0.000374914 0.000389452 -0.000570546 \u2026 0.000391708 5.61129e-5 0.000389898 0.000381116 -0.000301544 0.000381055 -9.33017e-5 0.000387139 0.000386579 -9.14174e-5 0.000384115 -0.000125689 0.00039709 0.000377236 4.99588e-5 0.000373351 -3.12507e-5 0.000387373 0.000383037 0.000159012 0.00037831 0.000163966 0.000389431 0.000375596 0.000224376 \u2026 0.000370853 0.000415252 0.000375596 0.000383775 0.000279658 0.000379835 0.000655951 0.000377186 0.000378578 0.00030907 0.000375911 0.0008319 0.000368403 0.00038769 0.00034119 0.000387262 0.000893315 0.000376956 0.000382018 0.000355017 0.000383702 0.000832146 0.000376036 0.000389199 0.000375041 \u2026 0.000393598 0.00065546 # plot imshow(A_tp, vmin=-.25, vmax=.25, cmap=\"Greys\", extent=[p[1], p[end], T[end], T[1]], aspect=.001) xlabel(\"slowness [s/m]\");ylabel(\"time [s]\"); Questions Can you interpret the results? Describe how you would design filters in the \\(\\tau-p\\) domain to separate the different events. Try it. Use the adjoint option of the transform to transform back to the physical domain.","title":"Exercise 4: Fourier and Radon filtering"},{"location":"Assignments/Exercise4/#exercise-4-fourier-and-radon-filtering","text":"In this exercise we will look at seismic data in different domains and investigate how we can exploit behaviour of different kinds of noise in these domains to design filters. Contents: - Data - Temporal Fourier transform - f-k filtering - Radon transform - Parabolic Radon transform using PyPlot, SeisIO Data We use a single midpoint gather of the data used in the previous exercises: shot.segy (no big endian this time). # Dowload and adapt path shot = segy_read(\"./data_segy/shot.segy\") shot_data = Float32.(shot.data) h = get_header(shot, \"SourceX\", scale=false) - get_header(shot, \"GroupX\", scale=false) dt = get_header(shot, \"dt\")[1]/1e6 nt = get_header(shot, \"ns\")[1] T = 0:dt:(nt -1)*dt BinaryFileHeader: Job: 1 Line: 1 Reel: 1 DataTracePerEnsemble: 1 AuxiliaryTracePerEnsemble: 0 dt: 4000 dtOrig: 0 ns: 1001 nsOrig: 0 DataSampleFormat: 1 EnsembleFold: 0 TraceSorting: 0 VerticalSumCode: 0 SweepFrequencyStart: 0 SweepFrequencyEnd: 0 SweepLength: 0 SweepType: 0 SweepChannel: 0 SweepTaperlengthStart: 0 SweepTaperLengthEnd: 0 TaperType: 0 CorrelatedDataTraces: 0 BinaryGain: 0 AmplitudeRecoveryMethod: 0 MeasurementSystem: 0 ImpulseSignalPolarity: 0 VibratoryPolarityCode: 0 SegyFormatRevisionNumber: 0 FixedLengthTraceFlag: 0 NumberOfExtTextualHeaders: 0 1705444 3600 1001 \u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mFixed length trace flag set in stream: IOBuffer(data=UInt8[...], readable=true, writable=false, seekable=true, append=false, size=1705444, maxsize=Inf, ptr=3601, mark=-1)\u001b[39m 0.0:0.004:4.0 imshow(shot_data, vmin=-1, vmax=1, cmap=\"Greys\", extent=[h[end], h[1], T[end], T[1]], aspect=1000) xlabel(\"offset [m]\");ylabel(\"time [s]\"); Temporal Fourier transform We can use fftrl to perform a Fourier transform along the temporal direction. The power spectrum (i.e., the absolute value of the transformed data) looks like function fftrl(a, t, mode) # fft for real-valued vectors # # Tristan van Leeuwen, 2012 # tleeuwen@eos.ubc.ca # # use: # [b,f] = fftrl(a,t,mode) # # input: # a - input data # t - time vector # mode: 1: forward, -1:inverse # # output: # b - vector nt = length(t) dt = t[2] - t[1] nf = Int(floor(nt/2)) + 1 tmax = t[end] - t[1] f = 0:1/tmax:.5/dt if mode == 1 b = fft(a,1) b = b[1:nf,:] elseif mode == -1 a = [a;conj(a[Int(ceil(nt/2)):-1:2,:])] b = ifft(a, 1) b = real(b) else error(\"Unknown mode\") end return b, f end fftrl (generic function with 1 method) Data_fh, f = fftrl(shot_data, T, 1) (Complex{Float32}[0.684434+0.0im 0.971781+0.0im \u2026 0.0969428+0.0im 0.00433278+0.0im; -0.701183-0.451787im -0.412326-0.460599im \u2026 -1.3078-0.497307im -1.40236-0.48802im; \u2026 ; -0.121274+0.000705719im -0.0863834-0.000402451im \u2026 0.157795-0.00114059im 0.110151-0.000276089im; -0.122033+0.000601768im -0.0849152-0.000236511im \u2026 0.159012-0.000580788im 0.109696-0.000192404im], 0.0:0.25:125.0) imshow(abs.(Data_fh), cmap=\"jet\", extent=[h[end], h[1], f[end], f[1]], aspect=20) xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') f-k filtering A Fourier transform along both time and offset direction is often referred to as an transform. We can use fktran. The powerspectrum looks like function fktran(a,t,x,mode) \"\"\" f-k transform for real-values input. use: b, f, k = fktran(a,t,x,mode) input: a - matrix in t-x domain (nt x nx) t - time vector x - x vector mode - 1:forward, -1:inverse \"\"\" nt = length(t) nx = length(x) dt = t[2]-t[1] dx = x[2] - x[1] xmax = x[end] - x[1] tmax = t[end] - t[1] f = 0:1/tmax:.5/dt k = -.5/dx:1/xmax:.5/dx nf = length(f) if mode == 1 b = fft(a, 1) b = b[1:nf, :] b = ifft(b, 2) b = circshift(b,[0 ceil(Int, nx/2)-1]); elseif mode == -1 b = circshift(a,[0 floor(Int, nx/2)+1]); b = fft(b, 2) b = ifft(b, 1) b = real(b) else error(\"unknown mode\") end return b, f, k end fktran (generic function with 1 method) Data_fk, fk, kx = fktran(shot_data, T, h, 1) (Complex{Float32}[0.00217381+0.375868im -0.00371527-0.375896im \u2026 -0.00371557+0.375898im 0.00217354-0.375864im; -0.0666401+0.378171im 0.0651375-0.378642im \u2026 -0.072564+0.377115im 0.0710575-0.377542im; \u2026 ; 0.00330043+0.400901im -0.00697034-0.400875im \u2026 -0.0029994+0.40092im -0.000692182-0.400906im; 0.00196619+0.400894im -0.00564895-0.400912im \u2026 -0.00433144+0.400905im 0.000641863-0.400899im], 0.0:0.25:125.0, 0.05:-0.00025:-0.05) imshow(abs.(Data_fk), cmap=\"jet\", extent=[kx[end], kx[1], f[end], f[1]], aspect=.001) xlabel(\"wavenumber [1/m\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]')","title":"Exercise 4: Fourier and Radon filtering"},{"location":"Assignments/Exercise4/#questions","text":"Subsample the data in the offset direction and look at the Fourier transform. (Hint: use Data[:,1:n:end] and h[1:n:end] where n is the number of times you want to subsample). What do you see? Why is it important to have a good receiver sampling? A filter is simply a multiplicative factor applied in some transform domain, typically \\(f-h\\) or \\(f-k\\) , followed by an inverse transform. For example, a band-pass filter in the \\(f-h\\) domain filters out higher temporal frequencies by setting them to zero. A simple band-pass filter looks like this: F_hp = ones(length(f),length(h)) F_hp[(f.<5) .| (f.>20.),:] = 0 imshow(F_hp, extent=[h[end], h[1], f[end], f[1]], aspect=20) colorbar() xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') The filtered data looks like this imshow(fftrl(F_hp.*Data_fh, f, -1)[1], cmap=\"Greys\", vmin=-1, vmax=1, extent=[h[end], h[1], T[end], T[1]], aspect=1000) xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') Do you see the artifacts? A way to reduce these artifacts is to smooth the filter. We can do this by convolving the filter with a triangular smoothing kernel. This is implemented in the function smooth_2D. The result looks like this: # Pkg.add(\"Images\") of you do not alread yhave it using Images function smooth_2D(input, n1, n2) t1 = [1:n1; n1-1:-1:1]/n1^2 t2 = [1:n2; n2-1:-1:1]/n2^2 kernel = t1 * t2' return imfilter(input, centered(kernel)) end smooth_2D (generic function with 1 method) F_hp_smooth = smooth_2D(F_hp, 5, 1) imshow(F_hp_smooth, extent=[h[end], h[1], f[end], f[1]], aspect=20) colorbar() xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') imshow(fftrl(F_hp_smooth.*Data_fh, f, -1)[1], cmap=\"Greys\", vmin=-1, vmax=1, extent=[h[end], h[1], T[end], T[1]], aspect=1000) xlabel(\"offset [m]\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]') A (smoothed) filter in the \\(f-k\\) domain may look like this ff = [fi for fi in f, kxi in kx] kkx = [kxi for fi in f, kxi in kx] F_kx = zeros(length(fk),length(kx)) F_kx[(ff -1e3 * abs.(kkx) .> 5) .& (ff.<60)] = 1 F_kx = smooth_2D(F_kx, 5, 5) imshow(F_kx, cmap=\"jet\", extent=[kx[end], kx[1], f[end], f[1]], aspect=.001) xlabel(\"wavenumber [1/m\");ylabel(\"frequency [Hz]\") PyObject Text(24,0.5,'frequency [Hz]')","title":"Questions:"},{"location":"Assignments/Exercise4/#questions_1","text":"Describe how you would design filters to clean up shot gathers shot_noise1 and shot_noise2. (hint: look the f-k transform and compare to the orinigal data) Try it and compare the result with the original shot gather.","title":"Questions"},{"location":"Assignments/Exercise4/#radon-transform","text":"The Radon tranform performs sums along lines with different intercepts \\(\\tau\\) ) and slopes \\(p\\) . Hence, it is sometimes refered to as the \\(\\tau-p\\) transform in geophysics. \\(\\hat{d}(\\tau,p) = \\int\\mathrm{d}h\\, d(t + ph, h)\\) The transform is implemented in the function lpradon. To get an idea of what this transform does, we consider the simple example in lines.segy. function lpradon(input, t, h, q, power, mode) # linear and parabolic Radon transform and its adjoint. # # Tristan van Leeuwen, 2012 # tleeuwen@eos.ubc.ca # # use: # out = lpradon(input,t,h,q,power,mode) # # input: # input - input matrix of size (length(t) x length(h)) for forward, (length(t) x length(q)) for adjoint) # t - time vector in seconds # h - offset vecror in meters # q - radon parameter # power - 1: linear radon, 2: parabolic radon # mode - 1: forward, -1: adjoint # # output: println(size(L)) # output matrix of size (length(t) x length(q)) for forward, (length(t) x length(h)) for adjoint) # # dt = t[2] - t[1] nt = length(t) nh = length(h) nq = length(q) nfft = 2*(nextpow2(nt)) input_padded = zeros(nfft, size(input)[2]) input_padded[1:size(input)[1], :] = input[:, :] if mode == 1 input_padded = fft(input_padded, 1) out = zeros(Complex{Float64}, nfft, nq) for k = 2:Int(floor(nfft/2)) f = 2.*pi*(k-1)/nfft/dt L = exp.(im*f*(h.^power)*q') tmp = input_padded[k,:].'*L out[k,:] = tmp out[nfft + 2 - k, :] = conj(tmp) end out = real(ifft(out, 1)) out = out[1:nt, :] else input_padded = fft(input_padded,1) out = zeros(Complex{Float64}, nfft, nh) for k = 2:Int(floor(nfft/2)) f = 2.*pi*(k-1)/nfft/dt L = exp.(im*f*(h.^power)*q') tmp = input_padded[k,:].'*L' out[k,:] = tmp out[nfft+2-k,:] = conj(tmp) end out = real(ifft(out,1)) out = out[1:nt, :] end return out end lpradon (generic function with 1 method) # Dowload and adapt path shot_radon = segy_read(\"./data_segy/lines.segy\") A = Float32.(shot_radon.data) h = get_header(shot_radon, \"SourceX\", scale=false) - get_header(shot, \"GroupX\", scale=false) dt = get_header(shot_radon, \"dt\")[1]/1e6 nt = get_header(shot_radon, \"ns\")[1] T = 0:dt:(nt -1)*dt BinaryFileHeader: Job: 1 Line: 1 Reel: 1 DataTracePerEnsemble: 1 AuxiliaryTracePerEnsemble: 0 dt: 4000 dtOrig: 0 ns: 1001 nsOrig: 0 DataSampleFormat: 1 EnsembleFold: 0 TraceSorting: 0 VerticalSumCode: 0 SweepFrequencyStart: 0 SweepFrequencyEnd: 0 SweepLength: 0 SweepType: 0 SweepChannel: 0 SweepTaperlengthStart: 0 SweepTaperLengthEnd: 0 TaperType: 0 CorrelatedDataTraces: 0 BinaryGain: 0 AmplitudeRecoveryMethod: 0 MeasurementSystem: 0 ImpulseSignalPolarity: 0 VibratoryPolarityCode: 0 SegyFormatRevisionNumber: 0 FixedLengthTraceFlag: 0 NumberOfExtTextualHeaders: 0 1705444 3600 1001 \u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mFixed length trace flag set in stream: IOBuffer(data=UInt8[...], readable=true, writable=false, seekable=true, append=false, size=1705444, maxsize=Inf, ptr=3601, mark=-1)\u001b[39m 0.0:0.004:4.0 imshow(A, vmin=-.1, vmax=.1, cmap=\"Greys\", extent=[h[end], h[1], T[end], T[1]], aspect=1000) xlabel(\"offset [m]\");ylabel(\"time [s]\"); # which p-values p = 1e-3.*(-3:.05:3) # transform A_tp = lpradon(A, T, h, p, 1, 1) 1001\u00d7121 Array{Float64,2}: 0.000378078 0.000384182 0.000384585 \u2026 0.000202505 0.000644788 0.000376368 0.000389721 0.00037549 0.000144312 0.000541559 0.000387413 0.000381872 0.000383162 0.000133913 0.000409034 0.000390602 0.000388732 0.000380008 0.000201181 0.000262995 0.00040214 0.000383436 0.000392553 0.000302437 0.000157082 0.00040122 0.000393219 0.000391394 \u2026 0.000439509 0.000100834 0.000405988 0.000390277 0.000402393 0.000551232 0.000125599 0.000398302 0.000401124 0.000397027 0.000636942 0.000208975 0.00039937 0.000397851 0.000403059 0.000648591 0.000347769 0.00039261 0.000407363 0.000394245 0.000611003 0.000491774 0.00039947 0.000402683 0.000400071 \u2026 0.000507467 0.000622865 0.000401411 0.000411663 0.000394785 0.00039216 0.000693264 0.000417296 0.000408056 0.000406892 0.000268286 0.000703196 \u22ee \u22f1 \u22ee 0.000378107 0.000381697 -0.000934809 0.000386704 0.000286472 0.000374914 0.000389452 -0.000570546 \u2026 0.000391708 5.61129e-5 0.000389898 0.000381116 -0.000301544 0.000381055 -9.33017e-5 0.000387139 0.000386579 -9.14174e-5 0.000384115 -0.000125689 0.00039709 0.000377236 4.99588e-5 0.000373351 -3.12507e-5 0.000387373 0.000383037 0.000159012 0.00037831 0.000163966 0.000389431 0.000375596 0.000224376 \u2026 0.000370853 0.000415252 0.000375596 0.000383775 0.000279658 0.000379835 0.000655951 0.000377186 0.000378578 0.00030907 0.000375911 0.0008319 0.000368403 0.00038769 0.00034119 0.000387262 0.000893315 0.000376956 0.000382018 0.000355017 0.000383702 0.000832146 0.000376036 0.000389199 0.000375041 \u2026 0.000393598 0.00065546 # plot imshow(A_tp, vmin=-.25, vmax=.25, cmap=\"Greys\", extent=[p[1], p[end], T[end], T[1]], aspect=.001) xlabel(\"slowness [s/m]\");ylabel(\"time [s]\");","title":"Radon transform"},{"location":"Assignments/Exercise4/#questions_2","text":"Can you interpret the results? Describe how you would design filters in the \\(\\tau-p\\) domain to separate the different events. Try it. Use the adjoint option of the transform to transform back to the physical domain.","title":"Questions"},{"location":"Assignments/Exercise5/","text":"Exercise 5: From processing to inversion I Contents Linear systems SPOT Deconvolotion Linear systems A matrix is represented in Julia as follows A = [1 2;3 -1] 2\u00d72 Array{Int64,2}: 1 2 3 -1 The transpose of a matrix is obtained via A' A' 2\u00d72 Array{Int64,2}: 1 3 2 -1 In a similar manner, we can define a column vector as follows x = [2; 2] 2-element Array{Int64,1}: 2 2 Desribe two ways to define a row vector. Now, consider the matrices A1 = [1/sqrt(2) 2/3 sqrt(2)/6;0 1/3 -2*sqrt(2)/3;-1/sqrt(2) 2/3 sqrt(2)/6]; A2 = [0 2 2;2 1 -3;1 0 -2]; A3 = [3 1;1 0;2 1]; A4 = [2 4 3; 1 3 1]; Questions Look at A1'*A1, what kind of matrix is A1? What does this mean? Look at A2 [1;2;3] and A2 [3;1;4], what can you say about the matrix A2? What do you call a linear system defined by matrix A3? What do you call a linear system defined by matrix A4? If a matrix is invertible, we can explicitly find the inverse with inv find a solution of A1*x = [6;-3;0], is there only one solution? Do you really need inv here? find a solution of A2*x = [4;0;-1], is there only one solution? What characterizes the solution you found? find a solution of A3*x = [5;2;5], is there only one solution? What characterizes the solution you found? find a solution of A4*x = [10;5], is there only one solution? What characterizes the solution you found? JOLI https://github.com/slimgroup/JOLI.jl The JOLI toolbox gives a way to represent matrices implicitly. A nice example is the Fourier transform. In julia, the Fourier transform of a vector is given by fft(x). We can explicitly construct a matrix representing the Fourier transform as follows # dimension N = 10 F1 = zeros(Complex{Float64}, N,N) for k = 1:N # construct k-th unit vector ek = zeros(N,1) ek[k] = 1 # make column of matrix F1[:, k]= fft(ek) end Look at the matrix, what do you notice? Verify that it gives the same result as fft by trying on a vector We can also define the FFT using JOLI: using JOLI F2 = joDFT(N) JOLI.joLinearFunction{Float64,Complex{Float64}}(\"joDFTp\", 10, 10, JOLI.#514, Nullable{Function}(JOLI.#278), Nullable{Function}(JOLI.#515), Nullable{Function}(JOLI.#279), false, Nullable{Function}(JOLI.#516), Nullable{Function}(JOLI.#280), Nullable{Function}(JOLI.#517), Nullable{Function}(JOLI.#281), false) whos(r\"F1\"), whos(r\"F2\"); F1 1600 bytes 10\u00d710 Array{Complex{Float64},2} F2 582 bytes JOLI.joLinearFunction{Float64,Comp\u2026 And this is only a small example! The reason why we want to have such operations behave like matrices is that we can use (some) standard algorithms that where written to work with matrices to work with large scale operations. As an example we use a Gaussian matrix: N = 10000; # NxN Gaussian matrix G1 = ones(N, N); # NxN Gaussian JOLI operator (will represent a different matrix than G1 becuase it is gerenated randomly) G2 = joOnes(N); whos(r\"G1\"), whos(r\"G2\"); G1 781250 KB 10000\u00d710000 Array{Float64,2} G2 246 bytes JOLI.joMatrix{Float64,Float64} Deconvolution We some signal \\(f(t)\\) which is a convolution of some unkown signal \\(g(t)\\) and a known filter \\(w(t)\\) . Given \\(f\\) and \\(w\\) we would like to retreive \\(g\\) . For the example we use: # time axis t = 0:.001:2'; N = length(t); # true signal g has approx k spikes with random amplitudes k = 20; g = zeros(N,1); g[rand(1:N, k)] = randn(k,1); # filter w = (1-2*1e3*(t-.2).^2).*exp.(-1e3*(t-.2).^2); # plot using PyPlot figure(); plot(t,g); xlabel(\"t [s]\");ylabel(\"g(t)\"); figure(); plot(t,w); xlabel(\"t [s]\");ylabel(\"w(t)\"); First, we consider the forward problem of convolving a signal, using JOLI. Perform the convolution using the usual julia commands fft, ifft and element-wise multiplication .*. Creat a JOLI operator to do the same. You can construct an operator to do the multiplication with the filter using joDiag. - Compare the results of both. - Compare f to g, what do you notice? - Assuming that your convolution operator is called C: Now, construct the signal f using your SPOT operator and add some noise (i.e., f = C g + 1e-1 randn(N,1)). Do you think C has a null-space? If so, describe it. (Hint: look at the filter). Use the adjoint of C as an approximation to the inverse, what does this correspond to and what does the reconstruction look like? - Describe how you would invert the system. - Use lsqr to do it. (you might need to increase the number of iterations.) - Look at the signal that is predicted by your reconstruction, do you see a difference with the true signal? lsqr will give us a solution that has a small two-norm and explains the data. Alternatively, we can use another solver that will give us a spiky solution and explains the data. This solver is spgl1. Try spgl1(C,f,0,1e-2). https://github.com/slimgroup/GenSPGL.jl Is this solution closer to the true one? Look at the predicted signal for this solution, do you see a difference with the true signal? Can we really say that this is a better solution? using GenSPGL # Pkg.clone(\"https://github.com/slimgroup/GenSPGL.jl\") # FFT convolution wf = fft(w); f1 = ifft(wf.*fft(g)); # JOLI operator to perform convolution. C = joDFT(N)'*joDiag(wf)*joDFT(N); f2 = C*g; figure(); plot(t,f1) plot(t,f2) plot(t,g); xlabel(\"t [s]\");ylabel(\"f(t)\");legend([\"normal\",\"JOLI\", \"g\"]); # true signal f = C*g + 1e-3*randn(N,1); # lsqr gt = C\\f 2001\u00d71 Array{Float64,2}: 0.00666159 0.00698098 0.00728673 0.00760021 0.00786498 0.00796295 0.00801857 0.00814685 0.00807513 0.0079503 0.00779799 0.00749169 0.00719726 \u22ee 0.00508929 0.00474104 0.00452079 0.00435027 0.00431479 0.00439437 0.00467603 0.00483907 0.00517327 0.00548942 0.00585045 0.00628071 # Solve opts = spgOptions(optTol = 1e-10, verbosity = 1) #gtt, r, grads, info = spgl1(C, vec(f), tau = 0., sigma = norm(f - C*gt)) GenSPGL.spgOptions(1, 1, 100000, 3, 1.0e-6, 1.0e-6, 1.0e-10, 0.0001, 1.0e-16, 100000.0, 2, Inf, false, Nullable{Bool}(), Inf, [1], false, 3, 1, 10000, false, GenSPGL.NormL1_project, GenSPGL.NormL1_primal, GenSPGL.NormL1_dual, GenSPGL.funLS, false, false, false)","title":"Exercise 5: From processing to inversion I"},{"location":"Assignments/Exercise5/#exercise-5-from-processing-to-inversion-i","text":"","title":"Exercise 5: From processing to inversion I"},{"location":"Assignments/Exercise5/#contents","text":"Linear systems SPOT Deconvolotion","title":"Contents"},{"location":"Assignments/Exercise5/#linear-systems","text":"A matrix is represented in Julia as follows A = [1 2;3 -1] 2\u00d72 Array{Int64,2}: 1 2 3 -1 The transpose of a matrix is obtained via A' A' 2\u00d72 Array{Int64,2}: 1 3 2 -1 In a similar manner, we can define a column vector as follows x = [2; 2] 2-element Array{Int64,1}: 2 2 Desribe two ways to define a row vector. Now, consider the matrices A1 = [1/sqrt(2) 2/3 sqrt(2)/6;0 1/3 -2*sqrt(2)/3;-1/sqrt(2) 2/3 sqrt(2)/6]; A2 = [0 2 2;2 1 -3;1 0 -2]; A3 = [3 1;1 0;2 1]; A4 = [2 4 3; 1 3 1];","title":"Linear systems"},{"location":"Assignments/Exercise5/#questions","text":"Look at A1'*A1, what kind of matrix is A1? What does this mean? Look at A2 [1;2;3] and A2 [3;1;4], what can you say about the matrix A2? What do you call a linear system defined by matrix A3? What do you call a linear system defined by matrix A4? If a matrix is invertible, we can explicitly find the inverse with inv find a solution of A1*x = [6;-3;0], is there only one solution? Do you really need inv here? find a solution of A2*x = [4;0;-1], is there only one solution? What characterizes the solution you found? find a solution of A3*x = [5;2;5], is there only one solution? What characterizes the solution you found? find a solution of A4*x = [10;5], is there only one solution? What characterizes the solution you found?","title":"Questions"},{"location":"Assignments/Exercise5/#joli","text":"https://github.com/slimgroup/JOLI.jl The JOLI toolbox gives a way to represent matrices implicitly. A nice example is the Fourier transform. In julia, the Fourier transform of a vector is given by fft(x). We can explicitly construct a matrix representing the Fourier transform as follows # dimension N = 10 F1 = zeros(Complex{Float64}, N,N) for k = 1:N # construct k-th unit vector ek = zeros(N,1) ek[k] = 1 # make column of matrix F1[:, k]= fft(ek) end Look at the matrix, what do you notice? Verify that it gives the same result as fft by trying on a vector We can also define the FFT using JOLI: using JOLI F2 = joDFT(N) JOLI.joLinearFunction{Float64,Complex{Float64}}(\"joDFTp\", 10, 10, JOLI.#514, Nullable{Function}(JOLI.#278), Nullable{Function}(JOLI.#515), Nullable{Function}(JOLI.#279), false, Nullable{Function}(JOLI.#516), Nullable{Function}(JOLI.#280), Nullable{Function}(JOLI.#517), Nullable{Function}(JOLI.#281), false) whos(r\"F1\"), whos(r\"F2\"); F1 1600 bytes 10\u00d710 Array{Complex{Float64},2} F2 582 bytes JOLI.joLinearFunction{Float64,Comp\u2026 And this is only a small example! The reason why we want to have such operations behave like matrices is that we can use (some) standard algorithms that where written to work with matrices to work with large scale operations. As an example we use a Gaussian matrix: N = 10000; # NxN Gaussian matrix G1 = ones(N, N); # NxN Gaussian JOLI operator (will represent a different matrix than G1 becuase it is gerenated randomly) G2 = joOnes(N); whos(r\"G1\"), whos(r\"G2\"); G1 781250 KB 10000\u00d710000 Array{Float64,2} G2 246 bytes JOLI.joMatrix{Float64,Float64}","title":"JOLI"},{"location":"Assignments/Exercise5/#deconvolution","text":"We some signal \\(f(t)\\) which is a convolution of some unkown signal \\(g(t)\\) and a known filter \\(w(t)\\) . Given \\(f\\) and \\(w\\) we would like to retreive \\(g\\) . For the example we use: # time axis t = 0:.001:2'; N = length(t); # true signal g has approx k spikes with random amplitudes k = 20; g = zeros(N,1); g[rand(1:N, k)] = randn(k,1); # filter w = (1-2*1e3*(t-.2).^2).*exp.(-1e3*(t-.2).^2); # plot using PyPlot figure(); plot(t,g); xlabel(\"t [s]\");ylabel(\"g(t)\"); figure(); plot(t,w); xlabel(\"t [s]\");ylabel(\"w(t)\"); First, we consider the forward problem of convolving a signal, using JOLI. Perform the convolution using the usual julia commands fft, ifft and element-wise multiplication .*. Creat a JOLI operator to do the same. You can construct an operator to do the multiplication with the filter using joDiag. - Compare the results of both. - Compare f to g, what do you notice? - Assuming that your convolution operator is called C: Now, construct the signal f using your SPOT operator and add some noise (i.e., f = C g + 1e-1 randn(N,1)). Do you think C has a null-space? If so, describe it. (Hint: look at the filter). Use the adjoint of C as an approximation to the inverse, what does this correspond to and what does the reconstruction look like? - Describe how you would invert the system. - Use lsqr to do it. (you might need to increase the number of iterations.) - Look at the signal that is predicted by your reconstruction, do you see a difference with the true signal? lsqr will give us a solution that has a small two-norm and explains the data. Alternatively, we can use another solver that will give us a spiky solution and explains the data. This solver is spgl1. Try spgl1(C,f,0,1e-2). https://github.com/slimgroup/GenSPGL.jl Is this solution closer to the true one? Look at the predicted signal for this solution, do you see a difference with the true signal? Can we really say that this is a better solution? using GenSPGL # Pkg.clone(\"https://github.com/slimgroup/GenSPGL.jl\") # FFT convolution wf = fft(w); f1 = ifft(wf.*fft(g)); # JOLI operator to perform convolution. C = joDFT(N)'*joDiag(wf)*joDFT(N); f2 = C*g; figure(); plot(t,f1) plot(t,f2) plot(t,g); xlabel(\"t [s]\");ylabel(\"f(t)\");legend([\"normal\",\"JOLI\", \"g\"]); # true signal f = C*g + 1e-3*randn(N,1); # lsqr gt = C\\f 2001\u00d71 Array{Float64,2}: 0.00666159 0.00698098 0.00728673 0.00760021 0.00786498 0.00796295 0.00801857 0.00814685 0.00807513 0.0079503 0.00779799 0.00749169 0.00719726 \u22ee 0.00508929 0.00474104 0.00452079 0.00435027 0.00431479 0.00439437 0.00467603 0.00483907 0.00517327 0.00548942 0.00585045 0.00628071 # Solve opts = spgOptions(optTol = 1e-10, verbosity = 1) #gtt, r, grads, info = spgl1(C, vec(f), tau = 0., sigma = norm(f - C*gt)) GenSPGL.spgOptions(1, 1, 100000, 3, 1.0e-6, 1.0e-6, 1.0e-10, 0.0001, 1.0e-16, 100000.0, 2, Inf, false, Nullable{Bool}(), Inf, [1], false, 3, 1, 10000, false, GenSPGL.NormL1_project, GenSPGL.NormL1_primal, GenSPGL.NormL1_dual, GenSPGL.funLS, false, false, false)","title":"Deconvolution"},{"location":"Assignments/Exercise6/","text":"Exercise 6: From processing to inversion II Contents: Kronecker NMO-Stack-deconvolution Inverting the Radon transform Kronecker Given a matrix X, we often want to apply operations along both dimensions. For example, if each column is a trace we can do a temporal fourier transform of each trace as follows using JOLI, JOLI.Seismic, GenSPGL, PyPlot # dummy matrix n1 = 10 n2 = 5 X = joComplex.(randn(n1,n2)) # fft along first dimension F1 = joDFT(n1; DDT=joComplex) Y = F1*X 10\u00d75 Array{Complex{Float64},2}: -1.25777+0.0im -0.774641+0.0im \u2026 0.769853+0.0im -0.654297+0.239707im 0.237683-0.15825im 1.79616+0.309481im 0.416353+1.54421im 0.429671-0.15162im 0.630353-0.853749im -0.820058+0.909454im 0.186228+1.00521im -0.194571+0.35528im -1.24295-0.578256im 0.476904-1.38574im 0.0477609-0.885882im -1.31471+0.0im 0.647963+0.0im \u2026 1.16376+0.0im -1.24295+0.578256im 0.476904+1.38574im 0.0477609+0.885882im -0.820058-0.909454im 0.186228-1.00521im -0.194571-0.35528im 0.416353-1.54421im 0.429671+0.15162im 0.630353+0.853749im -0.654297-0.239707im 0.237683+0.15825im 1.79616-0.309481im We can do an fft along the second dimension as follows F2 = joDFT(n2; DDT=joComplex) Y = transpose(F2*transpose(X)); Finally, we can combine both in one step as follows Y = (F2*(F1*X).').'; We can do the equivalent operation on the vectorized version of X via the Kronecker product. The formula is : $ \\mathrm{vec}(AXB) = (B^T\\otimes A)\\mathrm{vec}(X) $. where \\(\\mathrm{vec}\\) vectorizes a matrix \\(X(:)\\) . Use joKron to construct a 2D fft operator that works on a vectorized version of X, X(:). Show that the result is the same as when using the operators F1 and F2 separately. # 2D FFT operator F12 = joKron(F2,F1); # compare: F12*X(:) should be the same as Y(:) norm(F12*X[:] - Y[:]) 0.0 NMO-Stack-deconvolution We revisit the NMO and stack operations we saw a few weeks before, but we will use it backwards . Remember the conventional flow was Data -> NMO corrected data -> stack -> image We will now traverse this chain in the reverse order, each time using the adjoint of the operations. The reflectivity (image) can be represented by a convolution of a spike train with a wavelet, as we saw last week. We will build this chain of operations reflectivity -> convolved reflectivity -> NMO corrected data -> data, step-by-step. First, define a time and offset axis. # time and offset grid t = Float64.(0:.004:1); nt = length(t); h = Float64.(0.0:10.0:1000.0); nh = length(h); We make a reflectivity series with 3 spikes and define a wavelet. # reflectivity r = zeros(nt,1); r[51] = 1 r[101] = -.5 r[151] = .75 # wavelet w = (1-2*1e3*(t-.1).^2).*exp.(-1e3*(t-.1).^2) 251-element Array{Float64,1}: -0.000862599 -0.00173336 -0.00335964 -0.00627815 -0.0113054 -0.0196064 -0.0327228 -0.0525127 -0.0809414 -0.119668 -0.169407 -0.229101 -0.295059 \u22ee -8.75953e-316 -9.20212e-319 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 The convolution is done by using the FFT SPOT operators, just like in the last exercise. # convolution operator C = joDFT(nt)'*joDiag(fft(w))*joDFT(nt); Next, we need to extend the the reflectivity to be a function of time and offset. We are trying to undo the stack operation to create NMO corrected data. Let's first look at the stack. Given a matrix, we can stack the columns by multiplying with a vector of all ones: # test matrix X =[1 2; 3 4; 5 6] Y = X*[1;1] 3-element Array{Int64,1}: 3 7 11 Construct a JOLI operator that stacks a vectorized input matrix of size nt x nh along the columns. Use joDirac to define an identity operator. Apply the operators C and S to the vector r to get something that resembles NMO-corrected data. You can reshape the vector into a matrix by using reshape. Plot the result. The next step is to define the NMO operator. Use joNMO and define the operator for a constant velocity of 2000 m/s. Apply it to the result of the previous exercise and plot the result. Now, define a combined operator that predicts data given a spike train. Check that your combined operator satisfies the dottest Make data for the spike train r and add some noise. Invert the operator with both lsqr and spgl1 (see previous exercise). Inverting the Radon transform In the previous exercise we saw that the Radon transform is not unitary. This means that its adjoint is not its inverse. Here, we will set up a JOLI operator for the Radon transform and invert it using lsqr and spgl1. If the computation takes too long you can use a coarser sampling of the q axis. read the data parab.segy Set up a parabolic radon transform JOLI operator , R=joRadon(....; DDT=joFloat) Plot the data in the Radon domain, and go back to the orininal data using the adjoint. Compare to the original data. - - What do you notice? You want to obtain data in the Radon domain b for which the predicted data in the t,h domain is close to the original data. How would you do this?. Setup a damped least-squares system and invert with lsqr. Try different damping parameters and explain what you see. Hint: us lsqr(..., damp=) for a damped least square. Use the original system and invert with spgl1(A,b,0,tolerance). Describe a possible application of this technique in seismic processing Do not forget to turn your data into Float64","title":"Exercise 6: From processing to inversion II"},{"location":"Assignments/Exercise6/#exercise-6-from-processing-to-inversion-ii","text":"Contents: Kronecker NMO-Stack-deconvolution Inverting the Radon transform","title":"Exercise 6: From processing to inversion II"},{"location":"Assignments/Exercise6/#kronecker","text":"Given a matrix X, we often want to apply operations along both dimensions. For example, if each column is a trace we can do a temporal fourier transform of each trace as follows using JOLI, JOLI.Seismic, GenSPGL, PyPlot # dummy matrix n1 = 10 n2 = 5 X = joComplex.(randn(n1,n2)) # fft along first dimension F1 = joDFT(n1; DDT=joComplex) Y = F1*X 10\u00d75 Array{Complex{Float64},2}: -1.25777+0.0im -0.774641+0.0im \u2026 0.769853+0.0im -0.654297+0.239707im 0.237683-0.15825im 1.79616+0.309481im 0.416353+1.54421im 0.429671-0.15162im 0.630353-0.853749im -0.820058+0.909454im 0.186228+1.00521im -0.194571+0.35528im -1.24295-0.578256im 0.476904-1.38574im 0.0477609-0.885882im -1.31471+0.0im 0.647963+0.0im \u2026 1.16376+0.0im -1.24295+0.578256im 0.476904+1.38574im 0.0477609+0.885882im -0.820058-0.909454im 0.186228-1.00521im -0.194571-0.35528im 0.416353-1.54421im 0.429671+0.15162im 0.630353+0.853749im -0.654297-0.239707im 0.237683+0.15825im 1.79616-0.309481im We can do an fft along the second dimension as follows F2 = joDFT(n2; DDT=joComplex) Y = transpose(F2*transpose(X)); Finally, we can combine both in one step as follows Y = (F2*(F1*X).').'; We can do the equivalent operation on the vectorized version of X via the Kronecker product. The formula is : $ \\mathrm{vec}(AXB) = (B^T\\otimes A)\\mathrm{vec}(X) $. where \\(\\mathrm{vec}\\) vectorizes a matrix \\(X(:)\\) . Use joKron to construct a 2D fft operator that works on a vectorized version of X, X(:). Show that the result is the same as when using the operators F1 and F2 separately. # 2D FFT operator F12 = joKron(F2,F1); # compare: F12*X(:) should be the same as Y(:) norm(F12*X[:] - Y[:]) 0.0","title":"Kronecker"},{"location":"Assignments/Exercise6/#nmo-stack-deconvolution","text":"We revisit the NMO and stack operations we saw a few weeks before, but we will use it backwards . Remember the conventional flow was Data -> NMO corrected data -> stack -> image We will now traverse this chain in the reverse order, each time using the adjoint of the operations. The reflectivity (image) can be represented by a convolution of a spike train with a wavelet, as we saw last week. We will build this chain of operations reflectivity -> convolved reflectivity -> NMO corrected data -> data, step-by-step. First, define a time and offset axis. # time and offset grid t = Float64.(0:.004:1); nt = length(t); h = Float64.(0.0:10.0:1000.0); nh = length(h); We make a reflectivity series with 3 spikes and define a wavelet. # reflectivity r = zeros(nt,1); r[51] = 1 r[101] = -.5 r[151] = .75 # wavelet w = (1-2*1e3*(t-.1).^2).*exp.(-1e3*(t-.1).^2) 251-element Array{Float64,1}: -0.000862599 -0.00173336 -0.00335964 -0.00627815 -0.0113054 -0.0196064 -0.0327228 -0.0525127 -0.0809414 -0.119668 -0.169407 -0.229101 -0.295059 \u22ee -8.75953e-316 -9.20212e-319 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 The convolution is done by using the FFT SPOT operators, just like in the last exercise. # convolution operator C = joDFT(nt)'*joDiag(fft(w))*joDFT(nt); Next, we need to extend the the reflectivity to be a function of time and offset. We are trying to undo the stack operation to create NMO corrected data. Let's first look at the stack. Given a matrix, we can stack the columns by multiplying with a vector of all ones: # test matrix X =[1 2; 3 4; 5 6] Y = X*[1;1] 3-element Array{Int64,1}: 3 7 11 Construct a JOLI operator that stacks a vectorized input matrix of size nt x nh along the columns. Use joDirac to define an identity operator. Apply the operators C and S to the vector r to get something that resembles NMO-corrected data. You can reshape the vector into a matrix by using reshape. Plot the result. The next step is to define the NMO operator. Use joNMO and define the operator for a constant velocity of 2000 m/s. Apply it to the result of the previous exercise and plot the result. Now, define a combined operator that predicts data given a spike train. Check that your combined operator satisfies the dottest Make data for the spike train r and add some noise. Invert the operator with both lsqr and spgl1 (see previous exercise).","title":"NMO-Stack-deconvolution"},{"location":"Assignments/Exercise6/#inverting-the-radon-transform","text":"In the previous exercise we saw that the Radon transform is not unitary. This means that its adjoint is not its inverse. Here, we will set up a JOLI operator for the Radon transform and invert it using lsqr and spgl1. If the computation takes too long you can use a coarser sampling of the q axis. read the data parab.segy Set up a parabolic radon transform JOLI operator , R=joRadon(....; DDT=joFloat) Plot the data in the Radon domain, and go back to the orininal data using the adjoint. Compare to the original data. - - What do you notice? You want to obtain data in the Radon domain b for which the predicted data in the t,h domain is close to the original data. How would you do this?. Setup a damped least-squares system and invert with lsqr. Try different damping parameters and explain what you see. Hint: us lsqr(..., damp=) for a damped least square. Use the original system and invert with spgl1(A,b,0,tolerance). Describe a possible application of this technique in seismic processing Do not forget to turn your data into Float64","title":"Inverting the Radon transform"},{"location":"Assignments/Exercise7/","text":"Exercise 7 : Waveform inversion With waveform inversion we try to find the velocity model for which the modeled data optimally fits the observed data in a least-squares sense. Mathematically, we try to solve the following optimization problem: where is the modeling operator and is the observed data. Contents: - Camambert model - Modeling - Optimization - Inversion To illustrate some key properties of the waveform inversion problem, we are going to conduct some experiments on the famous 'Camambert' model. Camambert model: The Camambert model consists of a circular perturbation, , superimposed on a homogeneous medium, , with velocity 2500 m/s. using JUDI.TimeModeling, JUDI.SLIM_optim, PyPlot, SeisIO # Velocity model # number of gridpoints n = (101, 101) # Grid spacing d = (10.0, 10.0) # Origin o = (0., 0.) x = zeros(n) z = zeros(n) for i in 0:100 x[i+1, :] = i*10 z[:, i+1] = i*10 end # vp = 2.5f0 * ones(Float32, n) vp[find(sqrt.((x-500).^2 +(z-500).^2) .<=250)]=3.0f0 m = 1f0./vp.^2f0 # v0 = 2.5f0 * ones(Float32, n) m0 = 1f0./v0.^2f0 imshow(m) PyObject <matplotlib.image.AxesImage object at 0x7fee6c4dca20> # Set up model structure w/ squared slowness model0 = Model(n, d, o, m0) model = Model(n, d, o, m) JUDI.TimeModeling.Model((101, 101), (10.0, 10.0), (0.0, 0.0), 40, Float32[0.16 0.16 \u2026 0.16 0.16; 0.16 0.16 \u2026 0.16 0.16; \u2026 ; 0.16 0.16 \u2026 0.16 0.16; 0.16 0.16 \u2026 0.16 0.16], 1) Source geometry # Sources nsrc = 10 xsrc = convertToCell(linspace(10f0, 990f0, nsrc)) ysrc = convertToCell(linspace(0f0, 0f0, nsrc)) zsrc = convertToCell(linspace(10f0, 10f0, nsrc)) # source sampling and number of time steps timeS = 1000f0 dtS = 2f0 # Set up source structure srcGeometry = Geometry(xsrc,ysrc,zsrc; dt=dtS, t=timeS) JUDI.TimeModeling.GeometryIC(Any[10.0, 118.889, 227.778, 336.667, 445.556, 554.444, 663.333, 772.222, 881.111, 990.0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]) Receiver geometry # Receievers reflection nrec = 50f0 xrec = linspace(10f0, 990f0, nrec) yrec = 0f0 zrec = linspace(10f0, 10f0, nrec) # source sampling and number of time steps timeR = 1000f0 dtR = 2f0 # Set up receiver structure recGeometry_reflection = Geometry(xrec,yrec,zrec;dt=dtR,t=timeR, nsrc=nsrc) # Receievers transmission nrec = 50f0 xrec = linspace(10f0, 990f0, nrec) yrec = 0f0 zrec = linspace(990f0, 990f0, nrec) # source sampling and number of time steps timeR = 1000f0 dtR = 2f0 # Set up receiver structure recGeometry_transmission = Geometry(xrec,yrec,zrec;dt=dtR,t=timeR, nsrc=nsrc) JUDI.TimeModeling.GeometryIC(Any[10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]) Optimization lbfgs (minConf_PQN here) can be used to solve optimization problems of the form: \\(\\min_{\\mathbf{m}}\\quad \\phi(\\mathbf{m})\\) The method needs a function that calculates the misfit and gradient. The gradient of the LS misfit: \\(\\phi(\\mathbf{m}) = \\frac{1}{2}|F(\\mathbf{m}) {-} \\mathbf{d}|_2^2\\) is given by \\(\\nabla\\phi(\\mathbf{m}) = J(\\mathbf{m})^*(F(\\mathbf{m}) {-} \\mathbf{d})\\) where \\(J(\\mathbf{m})\\) is the Jacobian matrix of \\(F\\) and $^*# denotes the complex-conjugate-transpose (' in Julia). The Jacobian is provided by the modeling operator: J = judiJacobian(F, q) Write a julia function misfit(m) that returns the value of the misfit and the gradient for the given model m . minConf_SQP that function as an input Inversion In the following experiments we will vary acquisition setup to emulatate a reflection and a transmission experiment: Reflection setup: reflection_data.segy . Transmission setup: transmission_data.segy . define the function-handle as described above. define an initial model m0 by converting v0 to the proper units. use lbfgs| for a small amount of iterations (10, say). Compare the results of both experiments in terms of: reconstruction data-fit In order to obtain nice conergence use the following bound constraint Bound projection ProjBound(x) = boundproject(x, maximum(m), .9*minimum(m)) Setup # To setup the operator in for example the reflection case # setup wavelet f0 = 0.01f0 # 5 Hz wavelet wavelet = ricker_wavelet(timeS, dtS, f0) q = judiVector(srcGeometry, wavelet) # Set up info structure for linear operators ntComp = get_computational_nt(srcGeometry, recGeometry_reflection, model) info = Info(prod(n), nsrc, ntComp) JUDI.TimeModeling.Info(10201, 10, Any[596, 596, 596, 596, 596, 596, 596, 596, 596, 596]) F_r = judiModeling(info, model, srcGeometry, recGeometry_reflection) F_t = judiModeling(info, model, srcGeometry, recGeometry_transmission) JUDI.TimeModeling.judiPDEfull{Float32,Float32}(\"Proj*F*Proj'\", 250500, 5010, JUDI.TimeModeling.Info(10201, 10, Any[596, 596, 596, 596, 596, 596, 596, 596, 596, 596]), JUDI.TimeModeling.Model((101, 101), (10.0, 10.0), (0.0, 0.0), 40, Float32[0.16 0.16 \u2026 0.16 0.16; 0.16 0.16 \u2026 0.16 0.16; \u2026 ; 0.16 0.16 \u2026 0.16 0.16; 0.16 0.16 \u2026 0.16 0.16], 1), JUDI.TimeModeling.GeometryIC(Any[10.0, 118.889, 227.778, 336.667, 445.556, 554.444, 663.333, 772.222, 881.111, 990.0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]), JUDI.TimeModeling.GeometryIC(Any[10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]), JUDI.TimeModeling.Options(8, false, false, 1000.0, false, false, \"\", \"shot\", false, false, nothing, nothing, Any[], 1, false), JUDI.TimeModeling.#85, Nullable{Function}(JUDI.TimeModeling.#86)) d_trans = F_t * q JUDI.TimeModeling.judiVector{Float32}(\"Seismic data vector\", 250500, 1, 10, JUDI.TimeModeling.GeometryIC(Any[10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]), Array[Float32[0.0 0.0 \u2026 0.0 -0.0; -0.0 -0.0 \u2026 -0.0 0.0; \u2026 ; -0.264154 -0.289299 \u2026 0.226348 0.220771; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 0.0 \u2026 0.0 -0.0; 0.0 -0.0 \u2026 -0.0 0.0; \u2026 ; -0.149297 -0.0876982 \u2026 0.289633 0.307329; 0.0 0.0 \u2026 0.0 0.0], Float32[0.0 -0.0 \u2026 -0.0 -0.0; -0.0 0.0 \u2026 0.0 0.0; \u2026 ; 0.0364218 0.0267914 \u2026 0.200437 0.193765; 0.0 0.0 \u2026 0.0 0.0], Float32[0.0 0.0 \u2026 -0.0 -0.0; -0.0 -0.0 \u2026 0.0 0.0; \u2026 ; 0.133302 0.14125 \u2026 -0.0362351 -0.0663129; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 -0.0 \u2026 -0.0 0.0; 0.0 0.0 \u2026 0.0 -0.0; \u2026 ; 0.162256 0.161237 \u2026 0.0194431 0.0264048; 0.0 0.0 \u2026 0.0 0.0], Float32[0.0 -0.0 \u2026 -0.0 -0.0; -0.0 0.0 \u2026 0.0 0.0; \u2026 ; 0.0264062 0.0194453 \u2026 0.161238 0.162256; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 -0.0 \u2026 0.0 0.0; 0.0 0.0 \u2026 -0.0 -0.0; \u2026 ; -0.0663133 -0.0362352 \u2026 0.14125 0.133301; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 -0.0 \u2026 -0.0 0.0; 0.0 0.0 \u2026 0.0 -0.0; \u2026 ; 0.193767 0.200438 \u2026 0.0267931 0.0364229; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 0.0 \u2026 0.0 -0.0; 0.0 -0.0 \u2026 -0.0 0.0; \u2026 ; 0.307329 0.289633 \u2026 -0.0877006 -0.1493; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 0.0 \u2026 0.0 0.0; 0.0 -0.0 \u2026 -0.0 -0.0; \u2026 ; 0.22077 0.226348 \u2026 -0.2893 -0.264157; 0.0 0.0 \u2026 0.0 0.0]]) imshow(d_trans.data[10], vmin=-1, vmax=1, cmap=\"seismic\") PyObject <matplotlib.image.AxesImage object at 0x7fee6a3370b8> function f(x) # Update model model0.m = convert(Array{Float32, 2}, reshape(x, model0.n)) F0_t = judiModeling(info, model0, srcGeometry, recGeometry_transmission) J = judiJacobian(F0_t, q) # Synthetic data d_syn = F0_t*q # residual residual = d_syn - d_trans # Misfit f = .5*norm(residual)^2 # gradient grad = J'*residual return f, vec(grad) end f (generic function with 1 method) F0_t = judiModeling(info, model0, srcGeometry, recGeometry_transmission) J = judiJacobian(F0_t, q); dm = J'*d_trans 10201-element Array{Float32,1}: 4.39141 0.676352 0.361971 0.610117 -0.039682 -1.55511 -3.5738 -5.58581 -6.85017 -6.44537 -3.72911 1.01751 5.95766 \u22ee -3.40292 -2.88018 -1.61019 0.176336 1.71073 3.28438 3.77501 4.08856 3.4023 2.94257 2.24424 2.51696 imshow(d_trans.data[1], vmin=-1, vmax=1) PyObject <matplotlib.image.AxesImage object at 0x7fee68e88748> # invert options = pqn_options(verbose=3, maxIter=10, corrections=10) # Bound projection ProjBound(x) = boundproject(x, maximum(m), .9*minimum(m)) x, fsave, funEvals= minConf_PQN(f, vec(m0), ProjBound, options) Running PQN... Number of L-BFGS Corrections to store: 10 Spectral initialization of SPG: 0 Maximum number of SPG iterations: 10 SPG optimality tolerance: 1.00e-06 SPG progress tolerance: 1.00e-07 PQN optimality tolerance: 1.00e-05 PQN progress tolerance: 1.00e-07 Quadratic initialization of line search: 0 Maximum number of function evaluations: 10 Maximum number of projections: 100000 Iteration FunEvals Projections Step Length Function Val Opt Cond 1 2 4 5.91692e-04 2.33499e+05 3.00267e-01 Cubic Backtracking Interpolated value too small, Adjusting Cubic Backtracking Interpolated value too small, Adjusting Cubic Backtracking Interpolated value too small, Adjusting 2 6 11 1.00000e-09 2.33499e+05 3.00267e-01 Step size below progTol (Float32[0.444444, 0.444267, 0.444267, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444 \u2026 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444], [0.0, 2.33499e5, 2.33499e5], 6)","title":"Exercise 7 : Waveform inversion"},{"location":"Assignments/Exercise7/#exercise-7-waveform-inversion","text":"With waveform inversion we try to find the velocity model for which the modeled data optimally fits the observed data in a least-squares sense. Mathematically, we try to solve the following optimization problem: where is the modeling operator and is the observed data. Contents: - Camambert model - Modeling - Optimization - Inversion To illustrate some key properties of the waveform inversion problem, we are going to conduct some experiments on the famous 'Camambert' model.","title":"Exercise 7 : Waveform inversion"},{"location":"Assignments/Exercise7/#camambert-model","text":"The Camambert model consists of a circular perturbation, , superimposed on a homogeneous medium, , with velocity 2500 m/s. using JUDI.TimeModeling, JUDI.SLIM_optim, PyPlot, SeisIO # Velocity model # number of gridpoints n = (101, 101) # Grid spacing d = (10.0, 10.0) # Origin o = (0., 0.) x = zeros(n) z = zeros(n) for i in 0:100 x[i+1, :] = i*10 z[:, i+1] = i*10 end # vp = 2.5f0 * ones(Float32, n) vp[find(sqrt.((x-500).^2 +(z-500).^2) .<=250)]=3.0f0 m = 1f0./vp.^2f0 # v0 = 2.5f0 * ones(Float32, n) m0 = 1f0./v0.^2f0 imshow(m) PyObject <matplotlib.image.AxesImage object at 0x7fee6c4dca20> # Set up model structure w/ squared slowness model0 = Model(n, d, o, m0) model = Model(n, d, o, m) JUDI.TimeModeling.Model((101, 101), (10.0, 10.0), (0.0, 0.0), 40, Float32[0.16 0.16 \u2026 0.16 0.16; 0.16 0.16 \u2026 0.16 0.16; \u2026 ; 0.16 0.16 \u2026 0.16 0.16; 0.16 0.16 \u2026 0.16 0.16], 1)","title":"Camambert model:"},{"location":"Assignments/Exercise7/#source-geometry","text":"# Sources nsrc = 10 xsrc = convertToCell(linspace(10f0, 990f0, nsrc)) ysrc = convertToCell(linspace(0f0, 0f0, nsrc)) zsrc = convertToCell(linspace(10f0, 10f0, nsrc)) # source sampling and number of time steps timeS = 1000f0 dtS = 2f0 # Set up source structure srcGeometry = Geometry(xsrc,ysrc,zsrc; dt=dtS, t=timeS) JUDI.TimeModeling.GeometryIC(Any[10.0, 118.889, 227.778, 336.667, 445.556, 554.444, 663.333, 772.222, 881.111, 990.0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0])","title":"Source geometry"},{"location":"Assignments/Exercise7/#receiver-geometry","text":"# Receievers reflection nrec = 50f0 xrec = linspace(10f0, 990f0, nrec) yrec = 0f0 zrec = linspace(10f0, 10f0, nrec) # source sampling and number of time steps timeR = 1000f0 dtR = 2f0 # Set up receiver structure recGeometry_reflection = Geometry(xrec,yrec,zrec;dt=dtR,t=timeR, nsrc=nsrc) # Receievers transmission nrec = 50f0 xrec = linspace(10f0, 990f0, nrec) yrec = 0f0 zrec = linspace(990f0, 990f0, nrec) # source sampling and number of time steps timeR = 1000f0 dtR = 2f0 # Set up receiver structure recGeometry_transmission = Geometry(xrec,yrec,zrec;dt=dtR,t=timeR, nsrc=nsrc) JUDI.TimeModeling.GeometryIC(Any[10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0])","title":"Receiver geometry"},{"location":"Assignments/Exercise7/#optimization","text":"lbfgs (minConf_PQN here) can be used to solve optimization problems of the form: \\(\\min_{\\mathbf{m}}\\quad \\phi(\\mathbf{m})\\) The method needs a function that calculates the misfit and gradient. The gradient of the LS misfit: \\(\\phi(\\mathbf{m}) = \\frac{1}{2}|F(\\mathbf{m}) {-} \\mathbf{d}|_2^2\\) is given by \\(\\nabla\\phi(\\mathbf{m}) = J(\\mathbf{m})^*(F(\\mathbf{m}) {-} \\mathbf{d})\\) where \\(J(\\mathbf{m})\\) is the Jacobian matrix of \\(F\\) and $^*# denotes the complex-conjugate-transpose (' in Julia). The Jacobian is provided by the modeling operator: J = judiJacobian(F, q) Write a julia function misfit(m) that returns the value of the misfit and the gradient for the given model m . minConf_SQP that function as an input","title":"Optimization"},{"location":"Assignments/Exercise7/#inversion","text":"In the following experiments we will vary acquisition setup to emulatate a reflection and a transmission experiment: Reflection setup: reflection_data.segy . Transmission setup: transmission_data.segy . define the function-handle as described above. define an initial model m0 by converting v0 to the proper units. use lbfgs| for a small amount of iterations (10, say). Compare the results of both experiments in terms of: reconstruction data-fit In order to obtain nice conergence use the following bound constraint","title":"Inversion"},{"location":"Assignments/Exercise7/#bound-projection","text":"ProjBound(x) = boundproject(x, maximum(m), .9*minimum(m))","title":"Bound projection"},{"location":"Assignments/Exercise7/#setup","text":"# To setup the operator in for example the reflection case # setup wavelet f0 = 0.01f0 # 5 Hz wavelet wavelet = ricker_wavelet(timeS, dtS, f0) q = judiVector(srcGeometry, wavelet) # Set up info structure for linear operators ntComp = get_computational_nt(srcGeometry, recGeometry_reflection, model) info = Info(prod(n), nsrc, ntComp) JUDI.TimeModeling.Info(10201, 10, Any[596, 596, 596, 596, 596, 596, 596, 596, 596, 596]) F_r = judiModeling(info, model, srcGeometry, recGeometry_reflection) F_t = judiModeling(info, model, srcGeometry, recGeometry_transmission) JUDI.TimeModeling.judiPDEfull{Float32,Float32}(\"Proj*F*Proj'\", 250500, 5010, JUDI.TimeModeling.Info(10201, 10, Any[596, 596, 596, 596, 596, 596, 596, 596, 596, 596]), JUDI.TimeModeling.Model((101, 101), (10.0, 10.0), (0.0, 0.0), 40, Float32[0.16 0.16 \u2026 0.16 0.16; 0.16 0.16 \u2026 0.16 0.16; \u2026 ; 0.16 0.16 \u2026 0.16 0.16; 0.16 0.16 \u2026 0.16 0.16], 1), JUDI.TimeModeling.GeometryIC(Any[10.0, 118.889, 227.778, 336.667, 445.556, 554.444, 663.333, 772.222, 881.111, 990.0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]), JUDI.TimeModeling.GeometryIC(Any[10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]), JUDI.TimeModeling.Options(8, false, false, 1000.0, false, false, \"\", \"shot\", false, false, nothing, nothing, Any[], 1, false), JUDI.TimeModeling.#85, Nullable{Function}(JUDI.TimeModeling.#86)) d_trans = F_t * q JUDI.TimeModeling.judiVector{Float32}(\"Seismic data vector\", 250500, 1, 10, JUDI.TimeModeling.GeometryIC(Any[10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0, 10.0f0:20.0f0:990.0f0], Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Any[990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0, 990.0f0:0.0f0:990.0f0], Any[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Any[501, 501, 501, 501, 501, 501, 501, 501, 501, 501], Any[1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]), Array[Float32[0.0 0.0 \u2026 0.0 -0.0; -0.0 -0.0 \u2026 -0.0 0.0; \u2026 ; -0.264154 -0.289299 \u2026 0.226348 0.220771; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 0.0 \u2026 0.0 -0.0; 0.0 -0.0 \u2026 -0.0 0.0; \u2026 ; -0.149297 -0.0876982 \u2026 0.289633 0.307329; 0.0 0.0 \u2026 0.0 0.0], Float32[0.0 -0.0 \u2026 -0.0 -0.0; -0.0 0.0 \u2026 0.0 0.0; \u2026 ; 0.0364218 0.0267914 \u2026 0.200437 0.193765; 0.0 0.0 \u2026 0.0 0.0], Float32[0.0 0.0 \u2026 -0.0 -0.0; -0.0 -0.0 \u2026 0.0 0.0; \u2026 ; 0.133302 0.14125 \u2026 -0.0362351 -0.0663129; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 -0.0 \u2026 -0.0 0.0; 0.0 0.0 \u2026 0.0 -0.0; \u2026 ; 0.162256 0.161237 \u2026 0.0194431 0.0264048; 0.0 0.0 \u2026 0.0 0.0], Float32[0.0 -0.0 \u2026 -0.0 -0.0; -0.0 0.0 \u2026 0.0 0.0; \u2026 ; 0.0264062 0.0194453 \u2026 0.161238 0.162256; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 -0.0 \u2026 0.0 0.0; 0.0 0.0 \u2026 -0.0 -0.0; \u2026 ; -0.0663133 -0.0362352 \u2026 0.14125 0.133301; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 -0.0 \u2026 -0.0 0.0; 0.0 0.0 \u2026 0.0 -0.0; \u2026 ; 0.193767 0.200438 \u2026 0.0267931 0.0364229; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 0.0 \u2026 0.0 -0.0; 0.0 -0.0 \u2026 -0.0 0.0; \u2026 ; 0.307329 0.289633 \u2026 -0.0877006 -0.1493; 0.0 0.0 \u2026 0.0 0.0], Float32[-0.0 0.0 \u2026 0.0 0.0; 0.0 -0.0 \u2026 -0.0 -0.0; \u2026 ; 0.22077 0.226348 \u2026 -0.2893 -0.264157; 0.0 0.0 \u2026 0.0 0.0]]) imshow(d_trans.data[10], vmin=-1, vmax=1, cmap=\"seismic\") PyObject <matplotlib.image.AxesImage object at 0x7fee6a3370b8> function f(x) # Update model model0.m = convert(Array{Float32, 2}, reshape(x, model0.n)) F0_t = judiModeling(info, model0, srcGeometry, recGeometry_transmission) J = judiJacobian(F0_t, q) # Synthetic data d_syn = F0_t*q # residual residual = d_syn - d_trans # Misfit f = .5*norm(residual)^2 # gradient grad = J'*residual return f, vec(grad) end f (generic function with 1 method) F0_t = judiModeling(info, model0, srcGeometry, recGeometry_transmission) J = judiJacobian(F0_t, q); dm = J'*d_trans 10201-element Array{Float32,1}: 4.39141 0.676352 0.361971 0.610117 -0.039682 -1.55511 -3.5738 -5.58581 -6.85017 -6.44537 -3.72911 1.01751 5.95766 \u22ee -3.40292 -2.88018 -1.61019 0.176336 1.71073 3.28438 3.77501 4.08856 3.4023 2.94257 2.24424 2.51696 imshow(d_trans.data[1], vmin=-1, vmax=1) PyObject <matplotlib.image.AxesImage object at 0x7fee68e88748> # invert options = pqn_options(verbose=3, maxIter=10, corrections=10) # Bound projection ProjBound(x) = boundproject(x, maximum(m), .9*minimum(m)) x, fsave, funEvals= minConf_PQN(f, vec(m0), ProjBound, options) Running PQN... Number of L-BFGS Corrections to store: 10 Spectral initialization of SPG: 0 Maximum number of SPG iterations: 10 SPG optimality tolerance: 1.00e-06 SPG progress tolerance: 1.00e-07 PQN optimality tolerance: 1.00e-05 PQN progress tolerance: 1.00e-07 Quadratic initialization of line search: 0 Maximum number of function evaluations: 10 Maximum number of projections: 100000 Iteration FunEvals Projections Step Length Function Val Opt Cond 1 2 4 5.91692e-04 2.33499e+05 3.00267e-01 Cubic Backtracking Interpolated value too small, Adjusting Cubic Backtracking Interpolated value too small, Adjusting Cubic Backtracking Interpolated value too small, Adjusting 2 6 11 1.00000e-09 2.33499e+05 3.00267e-01 Step size below progTol (Float32[0.444444, 0.444267, 0.444267, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444 \u2026 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444, 0.444444], [0.0, 2.33499e5, 2.33499e5], 6)","title":"Setup"},{"location":"Assignments/introduction_to_julia/","text":"A quick introduction to the Julia language Getting started Start an interactive Julia session by running julia from the command line. You can quit the session with quit() . Generally, all functions in Julia are run using parenthesis, even if there are no input arguments. pwd() \"/home/philipp\" whos() Base Module Compat 19502 KB Module Core Module IJulia 19567 KB Module JSON 19384 KB Module Main Module MbedTLS 19412 KB Module Nullables 1120 bytes Module ZMQ 19357 KB Module You can define Julia scripts as regular text files that end with .jl and use your favourite text editor to code. Once you have your script, e.g.: hello-world.jl println(\"Hello world\") you can run the script with include(\"hello-world.jl\") . The Julia REPL REPL stands for Read/Evaluate/Print/Loop and refers to the interactive Julia session (it's just like a Matlab session). It's good for experimenting, but any serious coding should be done using scripts instead. 42 42 4 + 5 9 100 / 5; Unlike Matlab, you can access Julia's help functions by typing the question mark, followed by the function that you want the documention of: ? quit search: \u001b[1mq\u001b[22m\u001b[1mu\u001b[22m\u001b[1mi\u001b[22m\u001b[1mt\u001b[22m \u001b[1mQ\u001b[22m\u001b[1mu\u001b[22m\u001b[1mi\u001b[22mckSor\u001b[1mt\u001b[22m Partial\u001b[1mQ\u001b[22m\u001b[1mu\u001b[22m\u001b[1mi\u001b[22mckSor\u001b[1mt\u001b[22m \u001b[1mq\u001b[22m\u001b[1mu\u001b[22mant\u001b[1mi\u001b[22mle \u001b[1mq\u001b[22m\u001b[1mu\u001b[22mant\u001b[1mi\u001b[22mle! quit() Quit the program indicating that the processes completed successfully. This function calls exit(0) (see exit ). Similarly, you can enter the shell mode by typing ; , which gives you access to a full bash terminal. ; pwd /home/philipp In contrast to Matlab, Julia treats all operators as functions. This means you can add two numbers in either of the two ways: a = 4 + 5 9 a = +(4, 5) 9 The same applies for any other operations, such as subtraction, multiplications etc. Some math constants are defined in Julia by default, such as: print(pi) \u03c0 = 3.1415926535897... Julia was designed with the intend to write code that resembles mathematics as close as possible. For example, you can omit the multiplication operator when working with variables: x = 5 2x + 4 # which is the same as 2*x + 4 14 Just as Matlab, but different than Python, Julia comes with many built-in math functions that you would need for everyday use: sin(pi / 2) 1.0 log(100) 4.605170185988092 exp(4.3) 73.69979369959579 rand() 0.5282624241978122 Packages and Plotting Packages provide additional functionalities, that are not included in core Julia. Packages are written both by official Julia programmers, as well as anyone else who programs in Julia. Since native Julia does not include any plotting tools, we have to download a third-party package, such as PyPlot or Plots : Pkg.add(\"PyPlot\") \u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mInstalling JUDI v0.1.0 \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding Dierckx \u001b[39m make: Nothing to be done for `all'. \u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding Conda \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding PyCall \u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mPyCall is using /home/philipp/GATechBundle/Miniconda3/bin/python3 (Python 3.6.6) at /home/philipp/GATechBundle/Miniconda3/bin/python3, libpython = /home/philipp/GATechBundle/Miniconda3/lib/libpython3.6m \u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36m/home/philipp/.julia/v0.6/PyCall/deps/deps.jl has been updated \u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36m/home/philipp/.julia/v0.6/PyCall/deps/PYTHON has been updated \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPackage database updated \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mMETADATA is out-of-date \u2014 you may not have the latest version of PyPlot \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUse `Pkg.update()` to get the latest versions of your packages \u001b[39m Once you have downloaded a package, you can use it by typing: using PyPlot This plotting package is based off Python's Matplotlib package and therefore shares much of the Syntax. Some common plotting commands include: x = 1:100; f = x .^ 2; plot(x, f) 1-element Array{PyCall.PyObject,1}: PyObject <matplotlib.lines.Line2D object at 0x7f4b10781d30> A = randn(20,30); imshow(A, extent=[0,30,20,40]) PyObject <matplotlib.image.AxesImage object at 0x7f4b105585c0> Arrays and tuples Arrays are defined in a similar fashion to Matlab: x = [1, 2, 3, 4, 5] 5-element Array{Int64,1}: 1 2 3 4 5 As you can see from the output on the screen, Julia actually cares about types of variables and arrays. Since we defined our array as a collection of integers, the type of our array is `{Int64,1} y = [1., 2., 3., 4., 5.] 5-element Array{Float64,1}: 1.0 2.0 3.0 4.0 5.0 You can make a vector out of anything, not just numbers. For example, you can collect strings in a vector like this: s = [\"This\", \"is\", \"a\", \"string\", \"vector\"] 5-element Array{String,1}: \"This\" \"is\" \"a\" \"string\" \"vector\" s = [\"string\", 4.0, sin, pi] 4-element Array{Any,1}: \"string\" 4.0 sin \u03c0 = 3.1415926535897... Multi-dimensional arrays are formed as follows: A = [1 2 3 4; 5 6 7 8] 2\u00d74 Array{Int64,2}: 1 2 3 4 5 6 7 8 Note that entries of the same row are separated by spaces and rows are separated by ; You can also initialize vectors/matrices of a given dimension in various ways: B = zeros(4,5) 4\u00d75 Array{Float64,2}: 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 C = rand(2,3) 2\u00d73 Array{Float64,2}: 0.189405 0.938612 0.359612 0.553322 0.868266 0.102811 D = ones(4,2) 4\u00d72 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 Unlike Matlab, entries of matrices are accessed with square brackets, rather than parenthesis. Index counting starts at 1 (not 0). C[1,1] 0.1894051459813404 C[1,:] 3-element Array{Float64,1}: 0.189405 0.938612 0.359612 C[1,2:end] 2-element Array{Float64,1}: 0.938612 0.359612 Another useful structure, e.g. for plotting and loops, are range and linspace : r = 1:2:10 print(typeof(r)) StepRange{Int64,Int64} l = linspace(4,8.5, 7) print(typeof(l)) StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}} You can convert the vectors r and l to regular Julia arrays using the collect function: collect(r) 5-element Array{Int64,1}: 1 3 5 7 9 collect(l) 7-element Array{Float64,1}: 4.0 4.75 5.5 6.25 7.0 7.75 8.5 Similar to Matlab, it is possible to reshape arrays or stack multiple arrays to form new matrices: A = randn(3,4) 3\u00d74 Array{Float64,2}: 0.509555 -1.79653 0.842718 -0.713901 -0.0580305 0.609266 1.72787 -0.731359 0.10706 2.91134 -1.26744 -0.0453605 reshape(A, 4, 3) 4\u00d73 Array{Float64,2}: 0.509555 0.609266 -1.26744 -0.0580305 2.91134 -0.713901 0.10706 0.842718 -0.731359 -1.79653 1.72787 -0.0453605 vec(A) 12-element Array{Float64,1}: 0.509555 -0.0580305 0.10706 -1.79653 0.609266 2.91134 0.842718 1.72787 -1.26744 -0.713901 -0.731359 -0.0453605 B = [A; A] 6\u00d74 Array{Float64,2}: 0.509555 -1.79653 0.842718 -0.713901 -0.0580305 0.609266 1.72787 -0.731359 0.10706 2.91134 -1.26744 -0.0453605 0.509555 -1.79653 0.842718 -0.713901 -0.0580305 0.609266 1.72787 -0.731359 0.10706 2.91134 -1.26744 -0.0453605 One of the pitfalls of Julia is that assigning an array with the equal sign, does not copy the array, but creates a referece. A = ones(2,3) 2\u00d73 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 B = A 2\u00d73 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 A[1,:] = 2 println(A) [2.0 2.0 2.0; 1.0 1.0 1.0] show(B) [2.0 2.0 2.0; 1.0 1.0 1.0] To copy an array, use the copy function A = ones(2,3) 2\u00d73 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 B = copy(A) 2\u00d73 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 A[1,:] = 2 println(A) [2.0 2.0 2.0; 1.0 1.0 1.0] println(B) [1.0 1.0 1.0; 1.0 1.0 1.0] We see that B has not been changed! Some other differences between Matlab and Julia are min and max functions. These functions only return the min/max of two input variables: min(5,100) 5 To obtain the smallest/largest entry of a vector, use the minimum and maximum functions: x = [1,2,3,4,5,6] println(minimum(x)) println(maximum(x)) 1 6 Controll Flow Control flow in Julia, i.e. if/else statements, for loops or while loops, are similar to other programming languages. Here are some examples of different ways of controlling the flow: for j=1:2:8 println(j) end 1 3 5 7 for color in [\"red\", \"green\", \"blue\"] # an array print(color, \" \") end red green blue x = 10 while x > 1 x -= 1 println(x) end 9 8 7 6 5 4 3 2 1 name = \"Julia\" if name == \"Julia\" println(\"I like Julia\") elseif name == \"Python\" println(\"I like Python.\") println(\"But I prefer Julia.\") else println(\"I don't know what I like\") end I like Julia Functions Functions are a useful building block to structure your code and build subroutines etc. The most generic way to define functions in Julia is like this: function my_function(arg1, arg2) # do some work end my_function (generic function with 1 method) Functions can have any number of input arguments, including none: function breakfast() maketoast() brewcoffee() end breakfast (generic function with 1 method) By default, Julia functions always return the output from the last line of function. By using the return keyword, you can indicate a specific value that should be returned. function my_func(x, y) x_new = 2x y_new = 2y end z = my_func(3,4) 8 function my_func(x, y) return x_new = 2x y_new = 2y end z = my_func(3,4) 6 By grouping results as tuples, it is possible to return multiple variables: function my_func(x, y) x_new = 2x y_new = 2y return (x_new, y_new) end z = my_func(3,4) (6, 8)","title":"Introduction to julia"},{"location":"Assignments/introduction_to_julia/#a-quick-introduction-to-the-julia-language","text":"","title":"A quick introduction to the Julia language"},{"location":"Assignments/introduction_to_julia/#getting-started","text":"Start an interactive Julia session by running julia from the command line. You can quit the session with quit() . Generally, all functions in Julia are run using parenthesis, even if there are no input arguments. pwd() \"/home/philipp\" whos() Base Module Compat 19502 KB Module Core Module IJulia 19567 KB Module JSON 19384 KB Module Main Module MbedTLS 19412 KB Module Nullables 1120 bytes Module ZMQ 19357 KB Module You can define Julia scripts as regular text files that end with .jl and use your favourite text editor to code. Once you have your script, e.g.: hello-world.jl println(\"Hello world\") you can run the script with include(\"hello-world.jl\") .","title":"Getting started"},{"location":"Assignments/introduction_to_julia/#the-julia-repl","text":"REPL stands for Read/Evaluate/Print/Loop and refers to the interactive Julia session (it's just like a Matlab session). It's good for experimenting, but any serious coding should be done using scripts instead. 42 42 4 + 5 9 100 / 5; Unlike Matlab, you can access Julia's help functions by typing the question mark, followed by the function that you want the documention of: ? quit search: \u001b[1mq\u001b[22m\u001b[1mu\u001b[22m\u001b[1mi\u001b[22m\u001b[1mt\u001b[22m \u001b[1mQ\u001b[22m\u001b[1mu\u001b[22m\u001b[1mi\u001b[22mckSor\u001b[1mt\u001b[22m Partial\u001b[1mQ\u001b[22m\u001b[1mu\u001b[22m\u001b[1mi\u001b[22mckSor\u001b[1mt\u001b[22m \u001b[1mq\u001b[22m\u001b[1mu\u001b[22mant\u001b[1mi\u001b[22mle \u001b[1mq\u001b[22m\u001b[1mu\u001b[22mant\u001b[1mi\u001b[22mle! quit() Quit the program indicating that the processes completed successfully. This function calls exit(0) (see exit ). Similarly, you can enter the shell mode by typing ; , which gives you access to a full bash terminal. ; pwd /home/philipp In contrast to Matlab, Julia treats all operators as functions. This means you can add two numbers in either of the two ways: a = 4 + 5 9 a = +(4, 5) 9 The same applies for any other operations, such as subtraction, multiplications etc. Some math constants are defined in Julia by default, such as: print(pi) \u03c0 = 3.1415926535897... Julia was designed with the intend to write code that resembles mathematics as close as possible. For example, you can omit the multiplication operator when working with variables: x = 5 2x + 4 # which is the same as 2*x + 4 14 Just as Matlab, but different than Python, Julia comes with many built-in math functions that you would need for everyday use: sin(pi / 2) 1.0 log(100) 4.605170185988092 exp(4.3) 73.69979369959579 rand() 0.5282624241978122","title":"The Julia REPL"},{"location":"Assignments/introduction_to_julia/#packages-and-plotting","text":"Packages provide additional functionalities, that are not included in core Julia. Packages are written both by official Julia programmers, as well as anyone else who programs in Julia. Since native Julia does not include any plotting tools, we have to download a third-party package, such as PyPlot or Plots : Pkg.add(\"PyPlot\") \u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mInstalling JUDI v0.1.0 \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding Dierckx \u001b[39m make: Nothing to be done for `all'. \u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding Conda \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding PyCall \u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mPyCall is using /home/philipp/GATechBundle/Miniconda3/bin/python3 (Python 3.6.6) at /home/philipp/GATechBundle/Miniconda3/bin/python3, libpython = /home/philipp/GATechBundle/Miniconda3/lib/libpython3.6m \u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36m/home/philipp/.julia/v0.6/PyCall/deps/deps.jl has been updated \u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36m/home/philipp/.julia/v0.6/PyCall/deps/PYTHON has been updated \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPackage database updated \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mMETADATA is out-of-date \u2014 you may not have the latest version of PyPlot \u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUse `Pkg.update()` to get the latest versions of your packages \u001b[39m Once you have downloaded a package, you can use it by typing: using PyPlot This plotting package is based off Python's Matplotlib package and therefore shares much of the Syntax. Some common plotting commands include: x = 1:100; f = x .^ 2; plot(x, f) 1-element Array{PyCall.PyObject,1}: PyObject <matplotlib.lines.Line2D object at 0x7f4b10781d30> A = randn(20,30); imshow(A, extent=[0,30,20,40]) PyObject <matplotlib.image.AxesImage object at 0x7f4b105585c0>","title":"Packages and Plotting"},{"location":"Assignments/introduction_to_julia/#arrays-and-tuples","text":"Arrays are defined in a similar fashion to Matlab: x = [1, 2, 3, 4, 5] 5-element Array{Int64,1}: 1 2 3 4 5 As you can see from the output on the screen, Julia actually cares about types of variables and arrays. Since we defined our array as a collection of integers, the type of our array is `{Int64,1} y = [1., 2., 3., 4., 5.] 5-element Array{Float64,1}: 1.0 2.0 3.0 4.0 5.0 You can make a vector out of anything, not just numbers. For example, you can collect strings in a vector like this: s = [\"This\", \"is\", \"a\", \"string\", \"vector\"] 5-element Array{String,1}: \"This\" \"is\" \"a\" \"string\" \"vector\" s = [\"string\", 4.0, sin, pi] 4-element Array{Any,1}: \"string\" 4.0 sin \u03c0 = 3.1415926535897... Multi-dimensional arrays are formed as follows: A = [1 2 3 4; 5 6 7 8] 2\u00d74 Array{Int64,2}: 1 2 3 4 5 6 7 8 Note that entries of the same row are separated by spaces and rows are separated by ; You can also initialize vectors/matrices of a given dimension in various ways: B = zeros(4,5) 4\u00d75 Array{Float64,2}: 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 C = rand(2,3) 2\u00d73 Array{Float64,2}: 0.189405 0.938612 0.359612 0.553322 0.868266 0.102811 D = ones(4,2) 4\u00d72 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 Unlike Matlab, entries of matrices are accessed with square brackets, rather than parenthesis. Index counting starts at 1 (not 0). C[1,1] 0.1894051459813404 C[1,:] 3-element Array{Float64,1}: 0.189405 0.938612 0.359612 C[1,2:end] 2-element Array{Float64,1}: 0.938612 0.359612 Another useful structure, e.g. for plotting and loops, are range and linspace : r = 1:2:10 print(typeof(r)) StepRange{Int64,Int64} l = linspace(4,8.5, 7) print(typeof(l)) StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}} You can convert the vectors r and l to regular Julia arrays using the collect function: collect(r) 5-element Array{Int64,1}: 1 3 5 7 9 collect(l) 7-element Array{Float64,1}: 4.0 4.75 5.5 6.25 7.0 7.75 8.5 Similar to Matlab, it is possible to reshape arrays or stack multiple arrays to form new matrices: A = randn(3,4) 3\u00d74 Array{Float64,2}: 0.509555 -1.79653 0.842718 -0.713901 -0.0580305 0.609266 1.72787 -0.731359 0.10706 2.91134 -1.26744 -0.0453605 reshape(A, 4, 3) 4\u00d73 Array{Float64,2}: 0.509555 0.609266 -1.26744 -0.0580305 2.91134 -0.713901 0.10706 0.842718 -0.731359 -1.79653 1.72787 -0.0453605 vec(A) 12-element Array{Float64,1}: 0.509555 -0.0580305 0.10706 -1.79653 0.609266 2.91134 0.842718 1.72787 -1.26744 -0.713901 -0.731359 -0.0453605 B = [A; A] 6\u00d74 Array{Float64,2}: 0.509555 -1.79653 0.842718 -0.713901 -0.0580305 0.609266 1.72787 -0.731359 0.10706 2.91134 -1.26744 -0.0453605 0.509555 -1.79653 0.842718 -0.713901 -0.0580305 0.609266 1.72787 -0.731359 0.10706 2.91134 -1.26744 -0.0453605 One of the pitfalls of Julia is that assigning an array with the equal sign, does not copy the array, but creates a referece. A = ones(2,3) 2\u00d73 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 B = A 2\u00d73 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 A[1,:] = 2 println(A) [2.0 2.0 2.0; 1.0 1.0 1.0] show(B) [2.0 2.0 2.0; 1.0 1.0 1.0] To copy an array, use the copy function A = ones(2,3) 2\u00d73 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 B = copy(A) 2\u00d73 Array{Float64,2}: 1.0 1.0 1.0 1.0 1.0 1.0 A[1,:] = 2 println(A) [2.0 2.0 2.0; 1.0 1.0 1.0] println(B) [1.0 1.0 1.0; 1.0 1.0 1.0] We see that B has not been changed! Some other differences between Matlab and Julia are min and max functions. These functions only return the min/max of two input variables: min(5,100) 5 To obtain the smallest/largest entry of a vector, use the minimum and maximum functions: x = [1,2,3,4,5,6] println(minimum(x)) println(maximum(x)) 1 6","title":"Arrays and tuples"},{"location":"Assignments/introduction_to_julia/#controll-flow","text":"Control flow in Julia, i.e. if/else statements, for loops or while loops, are similar to other programming languages. Here are some examples of different ways of controlling the flow: for j=1:2:8 println(j) end 1 3 5 7 for color in [\"red\", \"green\", \"blue\"] # an array print(color, \" \") end red green blue x = 10 while x > 1 x -= 1 println(x) end 9 8 7 6 5 4 3 2 1 name = \"Julia\" if name == \"Julia\" println(\"I like Julia\") elseif name == \"Python\" println(\"I like Python.\") println(\"But I prefer Julia.\") else println(\"I don't know what I like\") end I like Julia","title":"Controll Flow"},{"location":"Assignments/introduction_to_julia/#functions","text":"Functions are a useful building block to structure your code and build subroutines etc. The most generic way to define functions in Julia is like this: function my_function(arg1, arg2) # do some work end my_function (generic function with 1 method) Functions can have any number of input arguments, including none: function breakfast() maketoast() brewcoffee() end breakfast (generic function with 1 method) By default, Julia functions always return the output from the last line of function. By using the return keyword, you can indicate a specific value that should be returned. function my_func(x, y) x_new = 2x y_new = 2y end z = my_func(3,4) 8 function my_func(x, y) return x_new = 2x y_new = 2y end z = my_func(3,4) 6 By grouping results as tuples, it is possible to return multiple variables: function my_func(x, y) x_new = 2x y_new = 2y return (x_new, y_new) end z = my_func(3,4) (6, 8)","title":"Functions"}]}